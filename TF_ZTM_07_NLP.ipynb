{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPU3yDO1sf7zduCsre4nDYV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshitgosain/Tensorflow-ZTM/blob/main/TF_ZTM_07_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Fundamentals in TF"
      ],
      "metadata": {
        "id": "CKP8rK-46aDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence-to-sequence\n",
        "* One to one- Image Captioning\n",
        "* Many to one- Sentiment analysis\n",
        "* Many to one- time series forecasting\n",
        "* many- to-many- Machine translation\n"
      ],
      "metadata": {
        "id": "UEIfyi-r8kcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfEm1Kes8lgu",
        "outputId": "b6c2dc88-6a35-451e-a54d-05b3c6d54cfc"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3FIIV0NRezo",
        "outputId": "fc206816-a7b9-4154-b13e-cfcf76971d42"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-16 03:12:50--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-16 03:12:50 (66.8 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "FZdua_xCR3nj"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu1aEiChSBoa",
        "outputId": "ef6a4a3b-98b1-41ce-bc68-21c20bed86af"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-16 03:12:50--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.107.128, 74.125.196.128, 74.125.134.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.107.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip.1’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2023-06-16 03:12:51 (102 MB/s) - ‘nlp_getting_started.zip.1’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "id": "ZwhaaRJFSXGF"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the dataset\n",
        "\n",
        "To visualize the sample data, we need to read the in. On way is to use python.\n",
        "\n",
        "Another way to do this is use pandas\n",
        "\n"
      ],
      "metadata": {
        "id": "FnODZX-2SZtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df=pd.read_csv(\"train.csv\")\n",
        "test_df=pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "OA7Fu5nwKZJE"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yECy1rYFLgUa",
        "outputId": "0eab2909-3132-40c3-bbe5-5689b806b3d7"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a50684a8-c985-45c6-8a50-b92d9091ec28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a50684a8-c985-45c6-8a50-b92d9091ec28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a50684a8-c985-45c6-8a50-b92d9091ec28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a50684a8-c985-45c6-8a50-b92d9091ec28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_shuffled=train_df.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "6mcpKv3ULfok"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_shuffled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "rheeFHeLMEPe",
        "outputId": "796d4221-07e9-4f92-94c3-6044ada3b0e5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id       keyword                        location  \\\n",
              "2644   3796   destruction                             NaN   \n",
              "2227   3185        deluge                             NaN   \n",
              "5448   7769        police                              UK   \n",
              "132     191    aftershock                             NaN   \n",
              "6845   9810        trauma           Montgomery County, MD   \n",
              "...     ...           ...                             ...   \n",
              "5226   7470  obliteration                         Merica!   \n",
              "5390   7691         panic                             NaN   \n",
              "860    1242         blood                             NaN   \n",
              "7603  10862           NaN                             NaN   \n",
              "7270  10409     whirlwind  Stamford & Cork (& Shropshire)   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  \n",
              "...                                                 ...     ...  \n",
              "5226  @Eganator2000 There aren't many Obliteration s...       0  \n",
              "5390  just had a panic attack bc I don't have enough...       0  \n",
              "860   Omron HEM-712C Automatic Blood Pressure Monito...       0  \n",
              "7603  Officials say a quarantine is in place at an A...       1  \n",
              "7270  I moved to England five years ago today. What ...       1  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95bbafc7-cbe2-4079-8c53-b39a1d47e8eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5226</th>\n",
              "      <td>7470</td>\n",
              "      <td>obliteration</td>\n",
              "      <td>Merica!</td>\n",
              "      <td>@Eganator2000 There aren't many Obliteration s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>7691</td>\n",
              "      <td>panic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>just had a panic attack bc I don't have enough...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>1242</td>\n",
              "      <td>blood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Omron HEM-712C Automatic Blood Pressure Monito...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7603</th>\n",
              "      <td>10862</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Officials say a quarantine is in place at an A...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>10409</td>\n",
              "      <td>whirlwind</td>\n",
              "      <td>Stamford &amp; Cork (&amp; Shropshire)</td>\n",
              "      <td>I moved to England five years ago today. What ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95bbafc7-cbe2-4079-8c53-b39a1d47e8eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95bbafc7-cbe2-4079-8c53-b39a1d47e8eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95bbafc7-cbe2-4079-8c53-b39a1d47e8eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test dataframe looks like:\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EOKnKXMgMLmz",
        "outputId": "33dcad65-a2e2-4bb4-94e3-07d285ab9b43"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9781ae02-2ed8-42f8-b470-1fabec2776e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9781ae02-2ed8-42f8-b470-1fabec2776e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9781ae02-2ed8-42f8-b470-1fabec2776e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9781ae02-2ed8-42f8-b470-1fabec2776e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVroyArwMSAd",
        "outputId": "6395cbd2-c27c-49a8-beb4-9d3d59fea2bf"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How many total number of samples\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJwjZWDvMbP0",
        "outputId": "352c578a-4953-40aa-b89b-f5b516e5537e"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's visualize some random training samples\n",
        "import random\n",
        "random_index = random.randint(0,len(train_df)-5)\n",
        "for row in train_data_shuffled[['text','target']][random_index:random_index+5].itertuples():\n",
        "  _,text, target=row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target >0 else \"(not real disaster)\")\n",
        "  print(f\"text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDoIh77fM8xb",
        "outputId": "98ae59ab-a953-496d-97b9-df9010c2fbb2"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (real disaster)\n",
            "text:\n",
            "Wreckage 'Conclusively Confirmed' as From MH370: Malaysia PM: Investigators and the families of those who were... http://t.co/MSsq0sVnBM\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "text:\n",
            "Russian 'food crematoria' provoke outrage amid crisis famine memories - Yahoo News http://t.co/6siiRlnV6z\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "text:\n",
            "The ol' meltdown victory for the Mets.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "text:\n",
            "More Natural Disaster Research Urgent http://t.co/5Cm0LfZhxn via #JakartaPost\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "text:\n",
            "I have been bleeding into this typewriter all day but so far all I've written is a bunch of gunk.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and validation sets\n",
        "\n"
      ],
      "metadata": {
        "id": "Q3_KYNkVORfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "K-_DDtcAeap3"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels=train_test_split(train_data_shuffled['text'].to_numpy(),\n",
        "                                                                          train_data_shuffled['target'].to_numpy(),\n",
        "                                                                          test_size=0.1,\n",
        "                                                                          random_state=42)"
      ],
      "metadata": {
        "id": "rFRtXZeded8h"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvV1nQX6fD8S",
        "outputId": "ca3ee263-9311-4451-fc9d-957977a8bb40"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting words into numbers\n",
        "\n",
        "First thing while building a model is to convert your text into numbers\n"
      ],
      "metadata": {
        "id": "xQJN3MYYktnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization VS Embedding\n",
        "Tkenization - word level and character level. Direct apping of a token.\n",
        "\n",
        "Embedding - every word gets turned into a vector and we can define size of the vector. Embeddings can learn as our model trains\n",
        "\n"
      ],
      "metadata": {
        "id": "6GOhJ-mcfRFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text vectorization(tokenization)"
      ],
      "metadata": {
        "id": "CZ_FBHbwjhjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "metadata": {
        "id": "otEJGiTzJmNX"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the default text vectorization parameters\n",
        "text_vectoizer= TextVectorization(max_tokens=None, #Defines how many words in our vocab\n",
        "                               standardize= \"lower_and_strip_punctuation\",\n",
        "                               split=\"whitespace\",\n",
        "                               ngrams=None,\n",
        "                               output_mode='int',\n",
        "                               output_sequence_length=None) #how long do you want your sequences to be\n",
        "                               #pad_to_max_tokens=True)"
      ],
      "metadata": {
        "id": "1iQnXkkeJvaQ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[0].split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7P5w8FmXiRk",
        "outputId": "6689b01f-f8ef-4800-c051-91bbc32ef9a2"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet']"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the average number of tokens(words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUNdYmJ9WjZY",
        "outputId": "f6e33307-e604-4dc0-adc0-7976b24e6708"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length= 10000 #max no of words to have in our vocab\n",
        "max_length=15 #Max length our sequences will be (e.g. how many words from a Tweet does a model see)\n",
        "\n",
        "text_vectorizer=TextVectorization(max_tokens=max_vocab_length,\n",
        "                                     output_mode=\"int\",\n",
        "                                     output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "LMx1h8VWX4uS"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)\n"
      ],
      "metadata": {
        "id": "yo-nO5JSYXiy"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIUXVbetZ-sI",
        "outputId": "5b33a77f-817a-47fa-ee0e-d94655f9351e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "       '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "       'destroy the free fandom honestly',\n",
              "       'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "       '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "       'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a sample sentence and tokenize it\n",
        "sample_sentence=\"There is a floow in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfFwEaKYaAoe",
        "outputId": "f23b6155-7bab-4084-83a6-e5fcd347de41"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 74,   9,   3,   1,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence=random.choice(train_sentences)\n",
        "print(random_sentence)\n",
        "vectorized_random_sentence=text_vectorizer([random_sentence])\n",
        "print(f\"Random Sentence: {random_sentence}\\nVectoized Random Sentence: {vectorized_random_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfpgC8tgaN4z",
        "outputId": "c278e6e3-7bd1-41be-8f6d-22ab0a5800e9"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedEx no longer will ship potential bioterror pathogens - FedEx Corp. (NYSE: FDX) will no longer deliver packages ... http://t.co/2kdq56xTWs\n",
            "Random Sentence: FedEx no longer will ship potential bioterror pathogens - FedEx Corp. (NYSE: FDX) will no longer deliver packages ... http://t.co/2kdq56xTWs\n",
            "Vectoized Random Sentence: [[ 577   40  600   38  810 1615  609 1801  577 5912    1    1   38   40\n",
            "   600]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_vocab=text_vectorizer.get_vocabulary()\n",
        "top_5_words=words_in_vocab[:5]\n",
        "botton_5_words=words_in_vocab[-5:]"
      ],
      "metadata": {
        "id": "ijV2vvTqbNLm"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_vocab,top_5_words,botton_5_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WMshKSybv4a",
        "outputId": "313f64b7-0b68-4067-8b90-82cd360bba51"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['',\n",
              "  '[UNK]',\n",
              "  'the',\n",
              "  'a',\n",
              "  'in',\n",
              "  'to',\n",
              "  'of',\n",
              "  'and',\n",
              "  'i',\n",
              "  'is',\n",
              "  'for',\n",
              "  'on',\n",
              "  'you',\n",
              "  'my',\n",
              "  'with',\n",
              "  'it',\n",
              "  'that',\n",
              "  'at',\n",
              "  'by',\n",
              "  'this',\n",
              "  'from',\n",
              "  'be',\n",
              "  'are',\n",
              "  'was',\n",
              "  'have',\n",
              "  'like',\n",
              "  'as',\n",
              "  'up',\n",
              "  'so',\n",
              "  'just',\n",
              "  'but',\n",
              "  'me',\n",
              "  'im',\n",
              "  'your',\n",
              "  'not',\n",
              "  'amp',\n",
              "  'out',\n",
              "  'its',\n",
              "  'will',\n",
              "  'an',\n",
              "  'no',\n",
              "  'has',\n",
              "  'fire',\n",
              "  'after',\n",
              "  'all',\n",
              "  'when',\n",
              "  'we',\n",
              "  'if',\n",
              "  'now',\n",
              "  'via',\n",
              "  'new',\n",
              "  'more',\n",
              "  'get',\n",
              "  'or',\n",
              "  'about',\n",
              "  'what',\n",
              "  'he',\n",
              "  'people',\n",
              "  'news',\n",
              "  'been',\n",
              "  'over',\n",
              "  'one',\n",
              "  'how',\n",
              "  'dont',\n",
              "  'they',\n",
              "  'who',\n",
              "  'into',\n",
              "  'were',\n",
              "  'do',\n",
              "  'us',\n",
              "  '2',\n",
              "  'can',\n",
              "  'video',\n",
              "  'emergency',\n",
              "  'there',\n",
              "  'disaster',\n",
              "  'than',\n",
              "  'police',\n",
              "  'would',\n",
              "  'his',\n",
              "  'still',\n",
              "  'her',\n",
              "  'some',\n",
              "  'body',\n",
              "  'storm',\n",
              "  'crash',\n",
              "  'burning',\n",
              "  'suicide',\n",
              "  'back',\n",
              "  'man',\n",
              "  'california',\n",
              "  'why',\n",
              "  'time',\n",
              "  'them',\n",
              "  'had',\n",
              "  'buildings',\n",
              "  'rt',\n",
              "  'first',\n",
              "  'cant',\n",
              "  'see',\n",
              "  'got',\n",
              "  'day',\n",
              "  'off',\n",
              "  'our',\n",
              "  'going',\n",
              "  'nuclear',\n",
              "  'know',\n",
              "  'world',\n",
              "  'bomb',\n",
              "  'fires',\n",
              "  'love',\n",
              "  'killed',\n",
              "  'go',\n",
              "  'attack',\n",
              "  'youtube',\n",
              "  'dead',\n",
              "  'two',\n",
              "  'families',\n",
              "  '3',\n",
              "  'train',\n",
              "  'full',\n",
              "  'being',\n",
              "  'war',\n",
              "  'many',\n",
              "  'today',\n",
              "  'think',\n",
              "  'only',\n",
              "  'car',\n",
              "  'accident',\n",
              "  'life',\n",
              "  'hiroshima',\n",
              "  'their',\n",
              "  'say',\n",
              "  'may',\n",
              "  'down',\n",
              "  'watch',\n",
              "  'good',\n",
              "  'could',\n",
              "  'want',\n",
              "  'last',\n",
              "  'here',\n",
              "  'years',\n",
              "  'u',\n",
              "  'then',\n",
              "  'make',\n",
              "  'did',\n",
              "  'wildfire',\n",
              "  'way',\n",
              "  'help',\n",
              "  'best',\n",
              "  'too',\n",
              "  'even',\n",
              "  'because',\n",
              "  'home',\n",
              "  'death',\n",
              "  'collapse',\n",
              "  'bombing',\n",
              "  'mass',\n",
              "  'him',\n",
              "  'black',\n",
              "  'am',\n",
              "  'those',\n",
              "  'need',\n",
              "  'fatal',\n",
              "  'army',\n",
              "  'another',\n",
              "  'work',\n",
              "  'take',\n",
              "  'should',\n",
              "  'really',\n",
              "  'please',\n",
              "  'mh370',\n",
              "  'youre',\n",
              "  'look',\n",
              "  'lol',\n",
              "  'hot',\n",
              "  'pm',\n",
              "  'legionnaires',\n",
              "  '4',\n",
              "  'right',\n",
              "  '5',\n",
              "  'let',\n",
              "  'city',\n",
              "  'year',\n",
              "  'wreck',\n",
              "  'school',\n",
              "  'northern',\n",
              "  'much',\n",
              "  'forest',\n",
              "  'bomber',\n",
              "  'water',\n",
              "  'she',\n",
              "  'never',\n",
              "  'read',\n",
              "  'latest',\n",
              "  'homes',\n",
              "  'great',\n",
              "  'every',\n",
              "  '1',\n",
              "  'live',\n",
              "  'god',\n",
              "  'fear',\n",
              "  'any',\n",
              "  '\\x89Û',\n",
              "  'under',\n",
              "  'said',\n",
              "  'old',\n",
              "  'floods',\n",
              "  '2015',\n",
              "  'getting',\n",
              "  'atomic',\n",
              "  'while',\n",
              "  'top',\n",
              "  'obama',\n",
              "  'feel',\n",
              "  'thats',\n",
              "  'since',\n",
              "  'near',\n",
              "  'flames',\n",
              "  'ever',\n",
              "  'come',\n",
              "  'where',\n",
              "  'these',\n",
              "  'military',\n",
              "  'japan',\n",
              "  'found',\n",
              "  'content',\n",
              "  'ass',\n",
              "  'without',\n",
              "  'weather',\n",
              "  'most',\n",
              "  'flooding',\n",
              "  'flood',\n",
              "  'damage',\n",
              "  'which',\n",
              "  'shit',\n",
              "  's',\n",
              "  'hope',\n",
              "  'everyone',\n",
              "  'before',\n",
              "  'stop',\n",
              "  'plan',\n",
              "  'malaysia',\n",
              "  'injured',\n",
              "  'hit',\n",
              "  'evacuation',\n",
              "  'during',\n",
              "  'debris',\n",
              "  'cross',\n",
              "  'coming',\n",
              "  'wild',\n",
              "  'well',\n",
              "  'times',\n",
              "  'sinking',\n",
              "  'oil',\n",
              "  'fucking',\n",
              "  'check',\n",
              "  'cause',\n",
              "  'weapons',\n",
              "  'truck',\n",
              "  'food',\n",
              "  'bloody',\n",
              "  'always',\n",
              "  'weapon',\n",
              "  'theres',\n",
              "  'state',\n",
              "  'little',\n",
              "  'injuries',\n",
              "  'free',\n",
              "  'wounded',\n",
              "  'summer',\n",
              "  'smoke',\n",
              "  'severe',\n",
              "  'reddit',\n",
              "  'next',\n",
              "  'movie',\n",
              "  'ive',\n",
              "  'hes',\n",
              "  'fall',\n",
              "  'evacuate',\n",
              "  'confirmed',\n",
              "  'bad',\n",
              "  'again',\n",
              "  'thunderstorm',\n",
              "  'set',\n",
              "  'night',\n",
              "  'natural',\n",
              "  'looks',\n",
              "  'heat',\n",
              "  'face',\n",
              "  'earthquake',\n",
              "  'boy',\n",
              "  'whole',\n",
              "  'until',\n",
              "  'thunder',\n",
              "  'through',\n",
              "  'says',\n",
              "  'panic',\n",
              "  'outbreak',\n",
              "  'made',\n",
              "  'lightning',\n",
              "  'fatalities',\n",
              "  'family',\n",
              "  'explosion',\n",
              "  'end',\n",
              "  'destroy',\n",
              "  'derailment',\n",
              "  'air',\n",
              "  'w',\n",
              "  'terrorist',\n",
              "  'survive',\n",
              "  'screaming',\n",
              "  'saudi',\n",
              "  'refugees',\n",
              "  'rain',\n",
              "  'murder',\n",
              "  'loud',\n",
              "  'liked',\n",
              "  'house',\n",
              "  'gonna',\n",
              "  'failure',\n",
              "  'collided',\n",
              "  'bag',\n",
              "  'attacked',\n",
              "  'ambulance',\n",
              "  '70',\n",
              "  'wind',\n",
              "  'services',\n",
              "  'save',\n",
              "  'report',\n",
              "  'migrants',\n",
              "  'head',\n",
              "  'explode',\n",
              "  'charged',\n",
              "  'change',\n",
              "  'big',\n",
              "  'also',\n",
              "  'wrecked',\n",
              "  'warning',\n",
              "  'update',\n",
              "  'run',\n",
              "  'rescuers',\n",
              "  'released',\n",
              "  'photo',\n",
              "  'massacre',\n",
              "  'injury',\n",
              "  'hurricane',\n",
              "  'high',\n",
              "  'hail',\n",
              "  'fuck',\n",
              "  'does',\n",
              "  'destroyed',\n",
              "  'bus',\n",
              "  'blood',\n",
              "  '40',\n",
              "  '\\x89ÛÒ',\n",
              "  'wreckage',\n",
              "  'violent',\n",
              "  'twister',\n",
              "  'trauma',\n",
              "  'tragedy',\n",
              "  'terrorism',\n",
              "  'survivors',\n",
              "  'survived',\n",
              "  'sinkhole',\n",
              "  'sandstorm',\n",
              "  'road',\n",
              "  'rioting',\n",
              "  'red',\n",
              "  'real',\n",
              "  'put',\n",
              "  'post',\n",
              "  'national',\n",
              "  'missing',\n",
              "  'landslide',\n",
              "  'keep',\n",
              "  'girl',\n",
              "  'drought',\n",
              "  'curfew',\n",
              "  'breaking',\n",
              "  'bags',\n",
              "  'white',\n",
              "  'twitter',\n",
              "  'tonight',\n",
              "  'structural',\n",
              "  'spill',\n",
              "  'service',\n",
              "  'screamed',\n",
              "  'rescued',\n",
              "  'rescue',\n",
              "  'phone',\n",
              "  'ok',\n",
              "  'oh',\n",
              "  'mosque',\n",
              "  'lives',\n",
              "  'horrible',\n",
              "  'harm',\n",
              "  'game',\n",
              "  'dust',\n",
              "  'destruction',\n",
              "  'deluge',\n",
              "  'deaths',\n",
              "  'crashed',\n",
              "  'cliff',\n",
              "  'catastrophe',\n",
              "  'boat',\n",
              "  'away',\n",
              "  'august',\n",
              "  'area',\n",
              "  'apocalypse',\n",
              "  'woman',\n",
              "  'whirlwind',\n",
              "  'traumatised',\n",
              "  'stock',\n",
              "  'saw',\n",
              "  'ruin',\n",
              "  'riot',\n",
              "  'quarantine',\n",
              "  'kills',\n",
              "  'island',\n",
              "  'investigators',\n",
              "  'ill',\n",
              "  'hostages',\n",
              "  'hazard',\n",
              "  'danger',\n",
              "  'call',\n",
              "  '15',\n",
              "  'women',\n",
              "  'windstorm',\n",
              "  'things',\n",
              "  'suspect',\n",
              "  'show',\n",
              "  'reunion',\n",
              "  'quarantined',\n",
              "  'lava',\n",
              "  'heart',\n",
              "  'engulfed',\n",
              "  'detonate',\n",
              "  'crush',\n",
              "  'collapsed',\n",
              "  'came',\n",
              "  'better',\n",
              "  'battle',\n",
              "  'armageddon',\n",
              "  'airplane',\n",
              "  'against',\n",
              "  'affected',\n",
              "  'use',\n",
              "  'trapped',\n",
              "  'thank',\n",
              "  'sunk',\n",
              "  'story',\n",
              "  'send',\n",
              "  'part',\n",
              "  'other',\n",
              "  'must',\n",
              "  'mudslide',\n",
              "  'market',\n",
              "  'iran',\n",
              "  'famine',\n",
              "  'exploded',\n",
              "  'electrocuted',\n",
              "  'ebay',\n",
              "  'displaced',\n",
              "  'derailed',\n",
              "  'derail',\n",
              "  'burned',\n",
              "  'bombed',\n",
              "  'blown',\n",
              "  'baby',\n",
              "  'around',\n",
              "  'zone',\n",
              "  'wave',\n",
              "  'wanna',\n",
              "  'sure',\n",
              "  'someone',\n",
              "  'screams',\n",
              "  'razed',\n",
              "  'power',\n",
              "  'obliterated',\n",
              "  'long',\n",
              "  'land',\n",
              "  'hundreds',\n",
              "  'heard',\n",
              "  'group',\n",
              "  'flattened',\n",
              "  'drown',\n",
              "  'doing',\n",
              "  'care',\n",
              "  'bridge',\n",
              "  'bagging',\n",
              "  '9',\n",
              "  'went',\n",
              "  'used',\n",
              "  'typhoon',\n",
              "  'trouble',\n",
              "  'tornado',\n",
              "  'thought',\n",
              "  'thing',\n",
              "  'river',\n",
              "  'responders',\n",
              "  'past',\n",
              "  'pandemonium',\n",
              "  'officials',\n",
              "  'meltdown',\n",
              "  'lot',\n",
              "  'least',\n",
              "  'inundated',\n",
              "  'id',\n",
              "  'hostage',\n",
              "  'hijacking',\n",
              "  'hazardous',\n",
              "  'goes',\n",
              "  'drowning',\n",
              "  'didnt',\n",
              "  'devastation',\n",
              "  'demolish',\n",
              "  'collide',\n",
              "  'casualties',\n",
              "  'calgary',\n",
              "  'bang',\n",
              "  'anniversary',\n",
              "  'yet',\n",
              "  'wounds',\n",
              "  'volcano',\n",
              "  'tsunami',\n",
              "  'sue',\n",
              "  'st',\n",
              "  'song',\n",
              "  'something',\n",
              "  'shoulder',\n",
              "  'security',\n",
              "  'prebreak',\n",
              "  'possible',\n",
              "  'pkk',\n",
              "  'panicking',\n",
              "  'obliteration',\n",
              "  'obliterate',\n",
              "  'murderer',\n",
              "  'minute',\n",
              "  'light',\n",
              "  'lets',\n",
              "  'kill',\n",
              "  'isis',\n",
              "  'india',\n",
              "  'hijacker',\n",
              "  'hellfire',\n",
              "  'government',\n",
              "  'few',\n",
              "  'evacuated',\n",
              "  'due',\n",
              "  'detonated',\n",
              "  'desolation',\n",
              "  'crushed',\n",
              "  'chemical',\n",
              "  'blew',\n",
              "  'blazing',\n",
              "  'blast',\n",
              "  'annihilated',\n",
              "  'airport',\n",
              "  '6',\n",
              "  'week',\n",
              "  'upheaval',\n",
              "  'trying',\n",
              "  'three',\n",
              "  'thanks',\n",
              "  'sound',\n",
              "  'soon',\n",
              "  'sirens',\n",
              "  'rainstorm',\n",
              "  'plane',\n",
              "  'music',\n",
              "  'making',\n",
              "  'kids',\n",
              "  'issues',\n",
              "  'half',\n",
              "  'guys',\n",
              "  'fedex',\n",
              "  'done',\n",
              "  'died',\n",
              "  'detonation',\n",
              "  'days',\n",
              "  'cyclone',\n",
              "  'county',\n",
              "  'collision',\n",
              "  'caused',\n",
              "  'catastrophic',\n",
              "  'bleeding',\n",
              "  'beautiful',\n",
              "  '8',\n",
              "  'words',\n",
              "  'very',\n",
              "  'traffic',\n",
              "  'south',\n",
              "  'remember',\n",
              "  'policy',\n",
              "  'place',\n",
              "  'nothing',\n",
              "  'north',\n",
              "  'mp',\n",
              "  'longer',\n",
              "  'left',\n",
              "  'israeli',\n",
              "  'hell',\n",
              "  'fun',\n",
              "  'drowned',\n",
              "  'demolished',\n",
              "  'cool',\n",
              "  'both',\n",
              "  'bioterror',\n",
              "  'believe',\n",
              "  'avalanche',\n",
              "  'arson',\n",
              "  'turkey',\n",
              "  'snowstorm',\n",
              "  'site',\n",
              "  'shot',\n",
              "  'shooting',\n",
              "  'pic',\n",
              "  'nowplaying',\n",
              "  'media',\n",
              "  'islam',\n",
              "  'inside',\n",
              "  'hijack',\n",
              "  'helicopter',\n",
              "  'fight',\n",
              "  'fatality',\n",
              "  'fan',\n",
              "  'electrocute',\n",
              "  'doesnt',\n",
              "  'building',\n",
              "  'brown',\n",
              "  'bc',\n",
              "  'actually',\n",
              "  '16yr',\n",
              "  'yes',\n",
              "  'watching',\n",
              "  'wait',\n",
              "  'ur',\n",
              "  'tell',\n",
              "  'swallowed',\n",
              "  'seismic',\n",
              "  'second',\n",
              "  'rubble',\n",
              "  're\\x89Û',\n",
              "  'plans',\n",
              "  'men',\n",
              "  'memories',\n",
              "  'line',\n",
              "  'la',\n",
              "  'horror',\n",
              "  'health',\n",
              "  'having',\n",
              "  'find',\n",
              "  'eyewitness',\n",
              "  'deluged',\n",
              "  'children',\n",
              "  'bush',\n",
              "  'anything',\n",
              "  'already',\n",
              "  'almost',\n",
              "  'aircraft',\n",
              "  'yourself',\n",
              "  'yeah',\n",
              "  'whats',\n",
              "  'tomorrow',\n",
              "  'such',\n",
              "  'start',\n",
              "  'side',\n",
              "  'searching',\n",
              "  'saved',\n",
              "  'reactor',\n",
              "  'probably',\n",
              "  'play',\n",
              "  'person',\n",
              "  'peace',\n",
              "  'outside',\n",
              "  'officer',\n",
              "  'nearby',\n",
              "  'n',\n",
              "  'maybe',\n",
              "  'lost',\n",
              "  'literally',\n",
              "  'hours',\n",
              "  'hear',\n",
              "  'far',\n",
              "  'die',\n",
              "  'demolition',\n",
              "  'data',\n",
              "  'crews',\n",
              "  'conclusively',\n",
              "  'business',\n",
              "  'american',\n",
              "  '20',\n",
              "  '\\x89ÛÓ',\n",
              "  'west',\n",
              "  'waves',\n",
              "  'team',\n",
              "  'street',\n",
              "  'stay',\n",
              "  'soudelor',\n",
              "  'reuters',\n",
              "  'manslaughter',\n",
              "  'leather',\n",
              "  'job',\n",
              "  'history',\n",
              "  'hey',\n",
              "  'feeling',\n",
              "  'eyes',\n",
              "  'everything',\n",
              "  'declares',\n",
              "  'deal',\n",
              "  'casualty',\n",
              "  'bodies',\n",
              "  'amid',\n",
              "  'ablaze',\n",
              "  '7',\n",
              "  '50',\n",
              "  '30',\n",
              "  '12',\n",
              "  'youth',\n",
              "  'wont',\n",
              "  'wake',\n",
              "  'theyre',\n",
              "  'support',\n",
              "  'stretcher',\n",
              "  'same',\n",
              "  'rise',\n",
              "  'picking',\n",
              "  'photos',\n",
              "  'own',\n",
              "  'others',\n",
              "  'order',\n",
              "  'omg',\n",
              "  'okay',\n",
              "  'name',\n",
              "  'myself',\n",
              "  'money',\n",
              "  'makes',\n",
              "  'leave',\n",
              "  'lab',\n",
              "  'gt',\n",
              "  'gets',\n",
              "  'flag',\n",
              "  'desolate',\n",
              "  'crisis',\n",
              "  'center',\n",
              "  'book',\n",
              "  'blight',\n",
              "  'blaze',\n",
              "  'ago',\n",
              "  'abc',\n",
              "  '11yearold',\n",
              "  'womens',\n",
              "  'typhoondevastated',\n",
              "  'tv',\n",
              "  'trench',\n",
              "  'trains',\n",
              "  'texas',\n",
              "  'space',\n",
              "  'siren',\n",
              "  'shes',\n",
              "  'self',\n",
              "  'saipan',\n",
              "  'reason',\n",
              "  'rd',\n",
              "  'pretty',\n",
              "  'pick',\n",
              "  'offensive',\n",
              "  'move',\n",
              "  'meek',\n",
              "  'major',\n",
              "  'm',\n",
              "  'low',\n",
              "  'lord',\n",
              "  'huge',\n",
              "  'hat',\n",
              "  'flash',\n",
              "  'feared',\n",
              "  'fast',\n",
              "  'effect',\n",
              "  'course',\n",
              "  'country',\n",
              "  'control',\n",
              "  'class',\n",
              "  'child',\n",
              "  'chance',\n",
              "  'caught',\n",
              "  'called',\n",
              "  'bioterrorism',\n",
              "  'bestnaijamade',\n",
              "  'become',\n",
              "  'bar',\n",
              "  'banned',\n",
              "  'ball',\n",
              "  'aug',\n",
              "  'annihilation',\n",
              "  'wrong',\n",
              "  'win',\n",
              "  'usa',\n",
              "  'united',\n",
              "  'town',\n",
              "  'totally',\n",
              "  'toddler',\n",
              "  'though',\n",
              "  'temple',\n",
              "  'taken',\n",
              "  'stand',\n",
              "  'spot',\n",
              "  'signs',\n",
              "  'ship',\n",
              "  'pakistan',\n",
              "  'online',\n",
              "  'level',\n",
              "  'ladies',\n",
              "  'jobs',\n",
              "  'isnt',\n",
              "  'happy',\n",
              "  'hailstorm',\n",
              "  'friends',\n",
              "  'disea',\n",
              "  'damn',\n",
              "  'couple',\n",
              "  'case',\n",
              "  'blue',\n",
              "  'bigger',\n",
              "  'america',\n",
              "  'across',\n",
              "  '10',\n",
              "  'yours',\n",
              "  'village',\n",
              "  'try',\n",
              "  'transport',\n",
              "  'talk',\n",
              "  'seen',\n",
              "  'russian',\n",
              "  'radio',\n",
              "  'projected',\n",
              "  'once',\n",
              "  'official',\n",
              "  'needs',\n",
              "  'nearly',\n",
              "  'mount',\n",
              "  'might',\n",
              "  'mayhem',\n",
              "  'instead',\n",
              "  'hollywood',\n",
              "  'haha',\n",
              "  'guy',\n",
              "  'gun',\n",
              "  'green',\n",
              "  'front',\n",
              "  'finally',\n",
              "  'favorite',\n",
              "  'experts',\n",
              "  'entire',\n",
              "  'east',\n",
              "  'daily',\n",
              "  'crazy',\n",
              "  'computers',\n",
              "  'coaches',\n",
              "  'christian',\n",
              "  'china',\n",
              "  'blizzard',\n",
              "  'anyone',\n",
              "  'aint',\n",
              "  'action',\n",
              "  '25',\n",
              "  'virgin',\n",
              "  'vehicle',\n",
              "  'truth',\n",
              "  'trust',\n",
              "  'takes',\n",
              "  't',\n",
              "  'star',\n",
              "  'sorry',\n",
              "  'running',\n",
              "  'refugio',\n",
              "  'reddits',\n",
              "  'poor',\n",
              "  'pain',\n",
              "  'mom',\n",
              "  'miners',\n",
              "  'marks',\n",
              "  'looking',\n",
              "  'knock',\n",
              "  'issued',\n",
              "  'insurance',\n",
              "  'ignition',\n",
              "  'houses',\n",
              "  'heavy',\n",
              "  'hate',\n",
              "  'hard',\n",
              "  'happened',\n",
              "  'global',\n",
              "  'giant',\n",
              "  'gbbo',\n",
              "  'flight',\n",
              "  'eye',\n",
              "  'emmerdale',\n",
              "  'driver',\n",
              "  'devastated',\n",
              "  'd',\n",
              "  'costlier',\n",
              "  'cnn',\n",
              "  'cars',\n",
              "  'camp',\n",
              "  'beach',\n",
              "  'arsonist',\n",
              "  'angry',\n",
              "  'alone',\n",
              "  'added',\n",
              "  '05',\n",
              "  'york',\n",
              "  'wonder',\n",
              "  'uk',\n",
              "  'turn',\n",
              "  'taking',\n",
              "  'subreddits',\n",
              "  'sounds',\n",
              "  'scared',\n",
              "  'russia',\n",
              "  'rly',\n",
              "  'reports',\n",
              "  'ready',\n",
              "  'quiz',\n",
              "  'public',\n",
              "  'property',\n",
              "  'pradesh',\n",
              "  'ppl',\n",
              "  'playing',\n",
              "  'pay',\n",
              "  'parole',\n",
              "  'pamela',\n",
              "  'pakistani',\n",
              "  'outrage',\n",
              "  'niggas',\n",
              "  'nagasaki',\n",
              "  'myanmar',\n",
              "  'muslims',\n",
              "  'mop',\n",
              "  'madhya',\n",
              "  'mad',\n",
              "  'lmao',\n",
              "  'learn',\n",
              "  'large',\n",
              "  'govt',\n",
              "  'give',\n",
              "  'gems',\n",
              "  'gave',\n",
              "  'funtenna',\n",
              "  'fukushima',\n",
              "  'former',\n",
              "  'film',\n",
              "  'earth',\n",
              "  'drive',\n",
              "  'downtown',\n",
              "  'dog',\n",
              "  'comes',\n",
              "  'closed',\n",
              "  'cake',\n",
              "  'british',\n",
              "  'bring',\n",
              "  'bbc',\n",
              "  'b',\n",
              "  'appears',\n",
              "  'aftershock',\n",
              "  '13',\n",
              "  '11',\n",
              "  'young',\n",
              "  'wow',\n",
              "  'worst',\n",
              "  'waving',\n",
              "  'washington',\n",
              "  'wanted',\n",
              "  'vs',\n",
              "  'view',\n",
              "  'upon',\n",
              "  'tweet',\n",
              "  'tree',\n",
              "  'tote',\n",
              "  'thousands',\n",
              "  'thinking',\n",
              "  'theater',\n",
              "  'soul',\n",
              "  'sky',\n",
              "  'sign',\n",
              "  'shows',\n",
              "  'shift',\n",
              "  'seeing',\n",
              "  'sea',\n",
              "  'scene',\n",
              "  'safety',\n",
              "  'rules',\n",
              "  'rock',\n",
              "  'reported',\n",
              "  'r',\n",
              "  'pray',\n",
              "  'playlist',\n",
              "  'patience',\n",
              "  ...],\n",
              " ['', '[UNK]', 'the', 'a', 'in'],\n",
              " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an embedding using an embedding layer\n",
        "\n",
        "To make our embedding, we're going to use the TF's embedding layer.\n",
        "\n",
        "The parameters we care the most about our embedding layers are:\n",
        "* input_dim= sie of our vocab\n",
        "* output_dim= size of the output embedding vector. A value of a 100 will mean that each token will be represented as a vector of 100 long length\n",
        "* input_length= length of sequences being passed to the embedding layer\n",
        "*"
      ],
      "metadata": {
        "id": "UscIzRK9b6M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "05ZNG325d5QR"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding=layers.Embedding(input_dim=max_vocab_length,\n",
        "                           output_dim=128,\n",
        "                           input_length=max_length)"
      ],
      "metadata": {
        "id": "sQrtz6UzEDid"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFptstOWEVJj",
        "outputId": "e439025b-2722-4132-ce98-8cbfd12714bb"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f204e61c1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a random sentence from the training set\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"Original Sentence:{random_sentence}\\\n",
        "      \\nEmbedded Sentence\")\n",
        "\n",
        "sample_embedding=embedding(text_vectorizer([random_sentence]))\n",
        "sample_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0XRCbb8EYo0",
        "outputId": "a24d690e-5a69-4288-debf-89ef0662bd50"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence:Ancient Mayan Tablet Found in Jungle Temple http://t.co/qp6q8RS8ON      \n",
            "Embedded Sentence\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.03305274,  0.03334713, -0.0422186 , ..., -0.0002015 ,\n",
              "         -0.02461776, -0.03663777],\n",
              "        [-0.03749834,  0.04993585,  0.0281971 , ..., -0.01925508,\n",
              "          0.00739387, -0.04485953],\n",
              "        [ 0.02407706, -0.0220372 , -0.00616293, ..., -0.00148871,\n",
              "          0.00904542,  0.00793977],\n",
              "        ...,\n",
              "        [ 0.01678229, -0.04126339,  0.04923167, ..., -0.01411662,\n",
              "         -0.02210027, -0.00361538],\n",
              "        [ 0.01678229, -0.04126339,  0.04923167, ..., -0.01411662,\n",
              "         -0.02210027, -0.00361538],\n",
              "        [ 0.01678229, -0.04126339,  0.04923167, ..., -0.01411662,\n",
              "         -0.02210027, -0.00361538]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check out a single token's embedding\n",
        "sample_embedding[0][0], sample_embedding[0][0].shape, random_sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12ur4eOWE9w1",
        "outputId": "70e01c14-f8bc-4b4f-982c-90acb72d732d"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.03305274,  0.03334713, -0.0422186 , -0.01651434, -0.01004869,\n",
              "         0.00807239,  0.02143629,  0.04050611, -0.0488528 ,  0.04384295,\n",
              "        -0.04994569, -0.02975096, -0.04748983,  0.03848847,  0.014861  ,\n",
              "        -0.03664464,  0.02235797, -0.01168202, -0.00961262, -0.02008259,\n",
              "         0.04554153,  0.04856726,  0.000729  ,  0.015517  ,  0.02172233,\n",
              "         0.01956419, -0.00673329, -0.01454289, -0.02853456, -0.01421569,\n",
              "        -0.03547049, -0.04265514,  0.04614327, -0.02024713,  0.0492197 ,\n",
              "         0.01474769, -0.03769908, -0.04338888,  0.00069172,  0.03630065,\n",
              "         0.01816435,  0.01300832, -0.01224078,  0.04164369, -0.03761123,\n",
              "        -0.03906231, -0.02251348,  0.01014551, -0.01259303,  0.01133149,\n",
              "         0.02600336,  0.02457358, -0.03501425,  0.04379206,  0.04179703,\n",
              "        -0.01283264,  0.02588114, -0.03014401, -0.0332365 , -0.00388657,\n",
              "         0.03525729,  0.01430574, -0.03992382,  0.01723776,  0.0177853 ,\n",
              "         0.0351144 , -0.00222255, -0.00097043, -0.03175728, -0.04309038,\n",
              "        -0.00272411, -0.03843832,  0.01778043, -0.03887849,  0.04332442,\n",
              "         0.0238304 ,  0.03619076,  0.02008159, -0.00306481,  0.01373894,\n",
              "         0.03334594, -0.04497937, -0.04185056, -0.0051312 ,  0.03231495,\n",
              "        -0.0305539 ,  0.02324258,  0.00124577,  0.01512993, -0.00121844,\n",
              "        -0.04031797, -0.03849963,  0.01569856, -0.02698064, -0.04436159,\n",
              "         0.01982918, -0.03604371, -0.04102348, -0.01662046,  0.00302916,\n",
              "         0.00992193,  0.02913162,  0.014605  ,  0.04935087, -0.03856333,\n",
              "         0.04460001,  0.01986302,  0.03709714, -0.00930188,  0.03951855,\n",
              "         0.02944975, -0.00949049,  0.00062913,  0.01739619, -0.0043362 ,\n",
              "        -0.02397143, -0.03394495,  0.02427847,  0.02030287,  0.02982292,\n",
              "        -0.00758438,  0.03660227, -0.01473581, -0.0185643 ,  0.02060458,\n",
              "        -0.0002015 , -0.02461776, -0.03663777], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'A')"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelling a text dataset(running a series of experiments)\n",
        "\n",
        "* Model 0: Naive Bayes with Tokenization\n",
        "* Model 1: Feed-forward Neural Network(Dense Model)\n",
        "* Model 2: LSTM Model(RNN)\n",
        "* Model 3: GRU Model\n",
        "* Moel 4: Bidirectional LSTM\n",
        "* Model 5 : 1D Convolutional Layer\n",
        "* model 6: Tensorflow hub pretrained feature extraction (using transfer learning)\n",
        "* Model 7 : Same as model 6 with 10% of data\n",
        "\n",
        "How are we going to approach all of these:\n",
        "Use the standard steps in modelling with tensorflow\n",
        "\n",
        "* Create->build->fit->Evaluate\n",
        "\n"
      ],
      "metadata": {
        "id": "FhiG7RYnF6Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0\n",
        "\n",
        "To create a baseline, we'll use sklearn's Naive Bayes using Tf-IDF to convert our words to numbers\n",
        "\n",
        "It is a good practice to use non-DL Algos as a baseline because of their speed and then later use DL to see if you can improve upon them"
      ],
      "metadata": {
        "id": "aXUkwxQcI759"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "SgYwLWoxZ-rB"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0=Pipeline([\n",
        "    (\"tfidf\",TfidfVectorizer()),\n",
        "    (\"clf\",MultinomialNB())\n",
        "])\n",
        "\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "c2zhqUaGZ_un",
        "outputId": "392ce67c-cf39-49e1-a927-2f5763b1da1f"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the baseline Model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"our baseline model achieves an accuracy of : {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqpo7Zw4cuEp",
        "outputId": "70ca6643-38c8-4f8e-cd7e-5b8204131625"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "our baseline model achieves an accuracy of : 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK5L1LTydGik",
        "outputId": "1eb1846d-3676-4b57-f0d7-994e04f2910a"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method IndexOpsMixin.value_counts of 0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "7608    1\n",
              "7609    1\n",
              "7610    1\n",
              "7611    1\n",
              "7612    1\n",
              "Name: target, Length: 7613, dtype: int64>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions\n",
        "baseline_preds= model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSf0XjLidIru",
        "outputId": "33c42a62-f890-48b4-a2dd-9389e2f431e3"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an evaluation function for our model experiments"
      ],
      "metadata": {
        "id": "f7C2BDI1dUx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could evaluate all of our model's predictions with different metrics every time.\n",
        "Calculate:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1 score\n"
      ],
      "metadata": {
        "id": "fsfPdfPdeBYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to evaluate the above metrics\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculated model accuracy, precision, recall and f1 score of a binary classification model\n",
        "  \"\"\"\n",
        "  #Calculate model accuracy\n",
        "  model_accuracy=accuracy_score(y_true, y_pred) * 100\n",
        "  #Calculate model precision, recall and f1 score using the\"weighted average\"\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred,average=\"weighted\" )\n",
        "  model_results={'accuracy':model_accuracy,\n",
        "                 'precision': model_precision,\n",
        "                 'recall': model_recall,\n",
        "                 'f1-score':model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "w3KO2bNCeH9x"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get baseline results\n",
        "baseline_results=calculate_results(y_true=val_labels,\n",
        "                                   y_pred=baseline_preds)"
      ],
      "metadata": {
        "id": "ZRhBrZUceYKk"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results['accuracy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5u_ypVpggRH",
        "outputId": "dab587d1-4cf4-4541-d929-16dc10fd1b6a"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79.26509186351706"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgSLKFUigjOp",
        "outputId": "ace667e9-789a-4ad5-a277-7e86d520ef7c"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: A simple Dense Model"
      ],
      "metadata": {
        "id": "GkA8wqsZgkFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensorflow callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "#Create a directory to save tensorboard logs\n",
        "SAVE_DIR=\"model_logs\"\n"
      ],
      "metadata": {
        "id": "4UMvTAO0lRnx"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build model with functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs=layers.Input(shape=(1,), dtype=tf.string) #Inputs are 1 dimensional\n",
        "x= text_vectorizer(inputs) #Turn the input text into numbers\n",
        "x= embedding(x) #Create an embedding of vctorized embeddings\n",
        "x=layers.GlobalAveragePooling1D()(x)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_1=tf.keras.Model(inputs, outputs, name=\"Model_1_dense\")"
      ],
      "metadata": {
        "id": "v-YXqNhHlXFp"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGntW8rbmRG_",
        "outputId": "91adcc2f-aea2-4658-ea93-ff3a570769fb"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_3 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile model\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AtH4W9MamYbc"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_history=model_1.fit(x=train_sentences,\n",
        "                            y=train_labels,\n",
        "                            epochs=5,\n",
        "                            validation_data=(val_sentences,val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                   experiment_name=\"model_1_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG4M-QjhnJEQ",
        "outputId": "1be19ba3-47c7-4bf9-f747-9f7408c0d555"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20230616-031253\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 31ms/step - loss: 0.6107 - accuracy: 0.6949 - val_loss: 0.5365 - val_accuracy: 0.7598\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.4408 - accuracy: 0.8203 - val_loss: 0.4684 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.3470 - accuracy: 0.8619 - val_loss: 0.4617 - val_accuracy: 0.7940\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 10s 47ms/step - loss: 0.2837 - accuracy: 0.8917 - val_loss: 0.4646 - val_accuracy: 0.7861\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.2377 - accuracy: 0.9115 - val_loss: 0.4793 - val_accuracy: 0.7822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWArT8vcnekL",
        "outputId": "3c92c11a-df40-4fea-a20f-6bfd5fa0754d"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4793274998664856, 0.7821522355079651]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_pred_probs=model_1.predict(val_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QoASaI1nn5Y",
        "outputId": "079f05fc-dfb4-476e-9e5c-9dd381cc5b0d"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_pred_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYMwZRAMntde",
        "outputId": "2f0390f0-0a3a-46af-ee92-04d5034fcdc0"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate_results(val_labels, model_1_pred_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "x3zF16Kjon-Y",
        "outputId": "c993c456-a630-40be-a2bf-822e3c436b70"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-29ba58bcbd72>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1_pred_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-127-bf803e99326d>\u001b[0m in \u001b[0;36mcalculate_results\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \"\"\"\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#Calculate model accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mmodel_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;31m#Calculate model precision, recall and f1 score using the\"weighted average\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mmodel_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weighted\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DefvW6HlpEhM",
        "outputId": "94aa980e-99fe-463a-95fe-0d89dac1957a"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Model_prediction Probabs into label formats\n",
        "model_1_preds=tf.squeeze(tf.round(model_1_pred_probs))"
      ],
      "metadata": {
        "id": "Siu3N9yupHrE"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5_rn_dtpMSZ",
        "outputId": "56133799-ead2-426f-9943-65d29a18d922"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results=calculate_results(y_true=val_labels,\n",
        "                                  y_pred=model_1_preds)"
      ],
      "metadata": {
        "id": "e4LzOiRYqp97"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbsaMJeNq0-H",
        "outputId": "5829569e-4997-4f83-8afd-05e9aa98fdfd"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.21522309711287,\n",
              " 'precision': 0.7864332425219001,\n",
              " 'recall': 0.7821522309711286,\n",
              " 'f1-score': 0.7792361147360404}"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS3Y8aGrq2r3",
        "outputId": "5ffaa661-bc11-418b-c4d2-cdbb320c4267"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values()))> np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pSLUJ6Zq4a8",
        "outputId": "84496982-b2b9-4146-acf7-24aa12bedf33"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the learned embeddings\n"
      ],
      "metadata": {
        "id": "xYmbF71CrAkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()"
      ],
      "metadata": {
        "id": "3jyHcUrWtyhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "id": "DjOpoiLUt4T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "3iZQmS3ouAsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the weight matrix of the embedding layers\n",
        "#These are numerical representation of our numerical datawhich are trained for 5 epochs\n",
        "\n",
        "embed_weights=model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights"
      ],
      "metadata": {
        "id": "cY5xpTiVuHbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed_weights.shape)"
      ],
      "metadata": {
        "id": "_IDMc9ssuec6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got the embedding matrix our model has learned to represent tokens, let's see how we can visualize it\n",
        "\n",
        "To do so, tensorflow has a tool called Projector"
      ],
      "metadata": {
        "id": "lxSNxbJPusKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "import io\n",
        "\n",
        "# Create output writers\n",
        "out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# Write embedding vectors and words to file\n",
        "for num, word in enumerate(words_in_vocab):\n",
        "  if num == 0:\n",
        "     continue # skip padding token\n",
        "  vec = embed_weights[num]\n",
        "  out_m.write(word + \"\\n\") # write words to file\n",
        "  out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "AWIx-3ehvLck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files locally to upload to Embedding Projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(\"embedding_vectors.tsv\")\n",
        "  files.download(\"embedding_metadata.tsv\")"
      ],
      "metadata": {
        "id": "5RPlhbYAwOBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks(RNNs)\n",
        "\n",
        "the premise of the Recurrent Neural Networs is to use the representation of the previous input to aid the representation of the later input\n",
        "\n",
        "RNNs are used for sequence data (this example is a sequence of text)"
      ],
      "metadata": {
        "id": "CrZT_hGHyOfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 📖 Resources:\n",
        "\n",
        "MIT Deep Learning Lecture on Recurrent Neural Networks - explains the background of recurrent neural networks and introduces LSTMs.\n",
        "The Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences.\n",
        "Understanding LSTMs by Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block."
      ],
      "metadata": {
        "id": "K_J8CWsiCbyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM= long short term memory\n",
        "\n",
        "Our structure of an RNN Looks like this\n",
        "\n",
        "Input(text)-> Tokenize -> Embedding -> Layers(RNNs/Dense)->output(label probability)"
      ],
      "metadata": {
        "id": "JIpS5KdMDdhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an LSTM Model\n",
        "from tensorflow.keras import layers\n",
        "inputs= layers.Input(shape=(1,), dtype=tf.string)\n",
        "x=text_vectorizer(inputs)\n",
        "x= embedding(x)\n",
        "print(x.shape)\n",
        "x=layers.LSTM(64, return_sequences=True)(x) #64 is hidden units\n",
        "#When you a stacking RNN Cells together, you need to return sequences=true\n",
        "print(x.shape)\n",
        "x= layers.LSTM(64)(x)\n",
        "print(x.shape)\n",
        "x= layers.Dense(64, activation='relu')(x)\n",
        "print(x.shape)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_2= tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n"
      ],
      "metadata": {
        "id": "hA922aKJASoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an LSTM Model\n",
        "from tensorflow.keras import layers\n",
        "inputs= layers.Input(shape=(1,), dtype=tf.string)\n",
        "x=text_vectorizer(inputs)\n",
        "x= embedding(x)\n",
        "#print(x.shape)\n",
        "#x=layers.LSTM(64, return_sequences=True)(x) #64 is hidden units\n",
        "#When you a stacking RNN Cells together, you need to return sequences=true\n",
        "#print(x.shape)\n",
        "x= layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "#x= layers.Dense(64, activation='relu')(x)\n",
        "#print(x.shape)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_2= tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n"
      ],
      "metadata": {
        "id": "7nHB-E4PBuQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "id": "FzlIZIY8Dm7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The default activation function for RNNs is TanH"
      ],
      "metadata": {
        "id": "QxsN2GykDo_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complie the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rf9WWNf9D1xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_2_LSTM=model_2.fit(train_sentences,\n",
        "                                 train_labels,\n",
        "                                 epochs=5,\n",
        "                                 validation_data=(val_sentences, val_labels),\n",
        "                                 callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                        experiment_name=\"model_2_LSTM\")])"
      ],
      "metadata": {
        "id": "qfH-KOfKEI_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_pred_probs=model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "id": "n5qVJNf2EY7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the probabs to pred\n",
        "model_2_preds=tf.squeeze(tf.round(model_2_pred_probs))"
      ],
      "metadata": {
        "id": "ZSymwXH5EjXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_preds\n"
      ],
      "metadata": {
        "id": "xfA-YNydEuin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results=calculate_results(y_true=val_labels,\n",
        "                                  y_pred=model_2_preds)"
      ],
      "metadata": {
        "id": "F4Nt6h5PEwPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "kRUgB8tnE2Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results\n"
      ],
      "metadata": {
        "id": "_y-bd5d6E3Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Similar to LSTM but has less params"
      ],
      "metadata": {
        "id": "UXF740ofE4nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs= tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "\n",
        "x=embedding(x)\n",
        "\n",
        "x = tf.keras.layers.GRU(64, return_sequences=True)(x) #if you want to stack recurrent layers on top of each other, you need to use return_sequences=True\n",
        "x=layers.LSTM(64, return_sequences=True)(x)\n",
        "x=layers.GRU(64)(x)\n",
        "\n",
        "x=layers.Dense(64, activation='relu')(x)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3=tf.keras.Model(inputs, outputs, name=\"Model_3_GRU\")\n"
      ],
      "metadata": {
        "id": "co1zgceRGAbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs= tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "\n",
        "x=embedding(x)\n",
        "\n",
        "x = tf.keras.layers.GRU(64)(x) #if you want to stack recurrent layers on top of each other, you need to use return_sequences=True\n",
        "#x=layers.LSTM(64, return_sequences=True)(x)\n",
        "#x=layers.GRU(64)(x)\n",
        "\n",
        "x=layers.Dense(64, activation='relu')(x)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3=tf.keras.Model(inputs, outputs, name=\"Model_3_GRU\")\n"
      ],
      "metadata": {
        "id": "DY1pSYYhIGWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "id": "4KKTktRsHIl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "j-bjh1F5HkL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_3_GRU=model_3.fit(train_sentences,\n",
        "                                train_labels,\n",
        "                                validation_data=(val_sentences, val_labels),\n",
        "                                epochs=5,\n",
        "                                callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                      experiment_name='model_name_GRU')])"
      ],
      "metadata": {
        "id": "xCnE4GUYIBBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_pred_probs=model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "metadata": {
        "id": "2bOgGL-qJHvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79caed18-f959-4eee-a231-be0710f97715"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.2693977e-03],\n",
              "       [5.5768818e-01],\n",
              "       [9.9999583e-01],\n",
              "       [1.0364279e-01],\n",
              "       [1.1872800e-05],\n",
              "       [9.9975604e-01],\n",
              "       [8.8811561e-02],\n",
              "       [9.9999785e-01],\n",
              "       [9.9999595e-01],\n",
              "       [6.8013978e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_preds=tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_pNU9DZMcnG",
        "outputId": "79a82ce9-00b6-42ea-c666-28c626658501"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(y_true=val_labels,\n",
        "                  y_pred=model_3_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYGuZrfxMnza",
        "outputId": "437e5e79-c001-449d-8fe3-505cab44fcb6"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.24671916010499,\n",
              " 'precision': 0.7639905060800456,\n",
              " 'recall': 0.7624671916010499,\n",
              " 'f1-score': 0.7602456873168202}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYltXXH5MuZe",
        "outputId": "13618939-b5c3-4d97-f548-8d297c836b7f"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model_4 : Bidirectional LSTM\n",
        "\n",
        "Normal RNNs go from left to right..\n",
        "Bidirectional RNNs go from left to right as well as right to left\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "45Q_Fz5nMwZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs=layers.Input(shape=(1,), dtype=tf.string)\n",
        "x= text_vectorizer(inputs)\n",
        "\n",
        "x= embedding(x)\n",
        "\n",
        "x=layers.Bidirectional(layers.LSTM(64))(x)\n",
        "#print(x.shape) #Doubles the value of the shape...as the cell is bidirectional\n",
        "#x=layers.Bidirectional(layers.GRU(64))(x)\n",
        "\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_4=tf.keras.Model(inputs, outputs, name='model_4_bidirectional')"
      ],
      "metadata": {
        "id": "yExqxgfRP-sq"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df9ldRCqR3to",
        "outputId": "7cd2235d-fb77-453a-ed49-58229a8e05a7"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_22 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_3 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss='binary_crossentropy',\n",
        "                metrics=['accuracy'],\n",
        "                optimizer=tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "eo_029tXSGlh"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_4_bidirectional=model_4.fit(train_sentences,\n",
        "                                    train_labels,\n",
        "                                    validation_data=(val_sentences, val_labels),\n",
        "                                    epochs=5,\n",
        "                                    callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                           experiment_name='model_4_bidirectional')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv1JVDxMS-Bd",
        "outputId": "48e6bbe0-be62-48a4-f06e-ee7276f67f98"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20230616-034334\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 17s 54ms/step - loss: 0.2152 - accuracy: 0.9225 - val_loss: 0.5480 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 11s 49ms/step - loss: 0.1549 - accuracy: 0.9429 - val_loss: 0.6283 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 10s 48ms/step - loss: 0.1271 - accuracy: 0.9514 - val_loss: 0.7197 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 9s 43ms/step - loss: 0.1084 - accuracy: 0.9574 - val_loss: 0.7231 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 14s 64ms/step - loss: 0.0892 - accuracy: 0.9654 - val_loss: 0.9359 - val_accuracy: 0.7677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_pred_probs=model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnbBSNVWTRI_",
        "outputId": "985973ca-488c-4322-f51b-d8dbcecf2cb8"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 4s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.1251854e-01],\n",
              "       [9.0274268e-01],\n",
              "       [9.9991882e-01],\n",
              "       [5.6247890e-02],\n",
              "       [1.3182372e-04],\n",
              "       [9.9746835e-01],\n",
              "       [9.1958749e-01],\n",
              "       [9.9996579e-01],\n",
              "       [9.9990803e-01],\n",
              "       [5.2167481e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_preds=tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W5brRHbTmU1",
        "outputId": "1189fa55-025a-44b5-a8ae-584897e94eb3"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results=calculate_results(y_true=val_labels,\n",
        "                y_pred=model_4_preds)"
      ],
      "metadata": {
        "id": "05u_VmVITt6m"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja-R9v37T7eS",
        "outputId": "d3f8c474-e6c6-4aa5-b098-3ad01b03cd87"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'precision': 0.7681410880728078,\n",
              " 'recall': 0.7677165354330708,\n",
              " 'f1-score': 0.7662770891654436}"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgK46Tz_Tx7P",
        "outputId": "4f72f8b9-a1ac-449a-af76-20bbbdd79926"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks for text and other types of sequences\n",
        "\n",
        "We've used CNN for images bit typically images are 2D(HxW)...however the text data is 1D\n",
        "\n",
        "previously we used Conv2D for our image data...but now we will use conv1d\n",
        "\n",
        "Typical structure of Conv1D model for sequences :\n",
        "\n",
        "Inputs(text)-> tokenization-> embedding-> layers(Conv1D)->Pooling-> Output(class Probabs)"
      ],
      "metadata": {
        "id": "KioDZiajT8gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Conv1D"
      ],
      "metadata": {
        "id": "pN65cQneVa7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_test=embedding(text_vectorizer([\"THis is a test sentence\"]))\n",
        "conv1d= layers.Conv1D(filters=32,\n",
        "                      kernel_size=5,\n",
        "                      activation='relu',\n",
        "                      padding='valid') #Default=valid, the outpus is smaller than the 'same' shape than the input\n",
        "\n",
        "conv_1d_output=conv1d(embedding_test)\n",
        "max_pool=layers.GlobalMaxPool1D()\n",
        "max_pool_output=max_pool(conv_1d_output) #Get the mot imporetant features...get the feature with hightest value\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-3K2iKzWKav",
        "outputId": "cd1861c6-4be1-42e2-d198-8f12b262bf44"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Where is the 11 coming from. THis is because we are using padding as valid and kernel size as 5"
      ],
      "metadata": {
        "id": "o9iVMctHXWIn"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD983IgpYCN5",
        "outputId": "aa53feab-33f6-49a8-db0c-57c650e7fdfd"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.00657184, -0.06535109,  0.01560264, ...,  0.02140128,\n",
              "          0.00618981, -0.01930427],\n",
              "        [ 0.00916248, -0.03951672, -0.00012985, ...,  0.04411504,\n",
              "         -0.02060145, -0.00520738],\n",
              "        [ 0.05060086, -0.00938471, -0.0006804 , ..., -0.00180441,\n",
              "          0.00540061, -0.01756253],\n",
              "        ...,\n",
              "        [ 0.02859491, -0.04157931,  0.02600376, ..., -0.00904637,\n",
              "         -0.0216876 , -0.02038047],\n",
              "        [ 0.02859491, -0.04157931,  0.02600376, ..., -0.00904637,\n",
              "         -0.0216876 , -0.02038047],\n",
              "        [ 0.02859491, -0.04157931,  0.02600376, ..., -0.00904637,\n",
              "         -0.0216876 , -0.02038047]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_1d_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ium20hlVZdHi",
        "outputId": "31e95cb5-f1ea-473b-f208-ebdc0e750f21"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              "array([[[0.        , 0.        , 0.03284881, 0.        , 0.01117422,\n",
              "         0.        , 0.        , 0.        , 0.01953866, 0.        ,\n",
              "         0.05711921, 0.00162833, 0.05206185, 0.        , 0.        ,\n",
              "         0.02032651, 0.04092628, 0.        , 0.        , 0.        ,\n",
              "         0.0633163 , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.00527028, 0.02214666, 0.05921314, 0.03058301, 0.00192783,\n",
              "         0.        , 0.10612602],\n",
              "        [0.        , 0.04462915, 0.        , 0.04470368, 0.02211461,\n",
              "         0.02406022, 0.04909075, 0.01351929, 0.        , 0.        ,\n",
              "         0.01432387, 0.04530457, 0.0125358 , 0.06134007, 0.00450303,\n",
              "         0.        , 0.07006411, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.00089449, 0.00475501, 0.        , 0.        ,\n",
              "         0.0323413 , 0.        , 0.01594213, 0.        , 0.02559575,\n",
              "         0.        , 0.08820157],\n",
              "        [0.        , 0.02307468, 0.03304613, 0.06121598, 0.        ,\n",
              "         0.        , 0.08851391, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.00038857, 0.07157265, 0.        , 0.        ,\n",
              "         0.05923818, 0.        , 0.        , 0.02295003, 0.        ,\n",
              "         0.09346423, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.02899135, 0.07279582, 0.        , 0.01860004, 0.02910609,\n",
              "         0.02802909, 0.01809765],\n",
              "        [0.        , 0.0764298 , 0.00053234, 0.03623027, 0.        ,\n",
              "         0.        , 0.01568774, 0.        , 0.00047023, 0.        ,\n",
              "         0.        , 0.        , 0.03191053, 0.03926238, 0.        ,\n",
              "         0.0236649 , 0.04599176, 0.        , 0.        , 0.        ,\n",
              "         0.05021457, 0.0125852 , 0.        , 0.        , 0.        ,\n",
              "         0.0412284 , 0.        , 0.        , 0.04464867, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.02127084, 0.        , 0.        , 0.07097452, 0.        ,\n",
              "         0.        , 0.01360233, 0.        , 0.05630821, 0.        ,\n",
              "         0.        , 0.09230591, 0.06329087, 0.02220194, 0.02651228,\n",
              "         0.02610146, 0.01416278, 0.        , 0.0157066 , 0.00624085,\n",
              "         0.01821876, 0.        , 0.00784606, 0.03471003, 0.00034138,\n",
              "         0.0238005 , 0.04982641, 0.        , 0.        , 0.00932884,\n",
              "         0.00027255, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.04739674, 0.        ,\n",
              "         0.        , 0.02827165, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.05222943, 0.09395298, 0.0326547 , 0.02764263,\n",
              "         0.05439073, 0.05050679, 0.        , 0.        , 0.00917987,\n",
              "         0.03756544, 0.01964616, 0.        , 0.02721049, 0.        ,\n",
              "         0.05131255, 0.06019967, 0.        , 0.        , 0.01855273,\n",
              "         0.01008845, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.04739674, 0.        ,\n",
              "         0.        , 0.02827165, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.05222943, 0.09395298, 0.0326547 , 0.02764263,\n",
              "         0.05439073, 0.05050679, 0.        , 0.        , 0.00917987,\n",
              "         0.03756544, 0.01964616, 0.        , 0.02721049, 0.        ,\n",
              "         0.05131255, 0.06019967, 0.        , 0.        , 0.01855273,\n",
              "         0.01008845, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.04739674, 0.        ,\n",
              "         0.        , 0.02827165, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.05222943, 0.09395298, 0.0326547 , 0.02764263,\n",
              "         0.05439073, 0.05050679, 0.        , 0.        , 0.00917987,\n",
              "         0.03756544, 0.01964616, 0.        , 0.02721049, 0.        ,\n",
              "         0.05131255, 0.06019967, 0.        , 0.        , 0.01855273,\n",
              "         0.01008845, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.04739674, 0.        ,\n",
              "         0.        , 0.02827165, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.05222943, 0.09395298, 0.0326547 , 0.02764263,\n",
              "         0.05439073, 0.05050679, 0.        , 0.        , 0.00917987,\n",
              "         0.03756544, 0.01964616, 0.        , 0.02721049, 0.        ,\n",
              "         0.05131255, 0.06019967, 0.        , 0.        , 0.01855273,\n",
              "         0.01008845, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.04739674, 0.        ,\n",
              "         0.        , 0.02827165, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.05222943, 0.09395298, 0.0326547 , 0.02764263,\n",
              "         0.05439073, 0.05050679, 0.        , 0.        , 0.00917987,\n",
              "         0.03756544, 0.01964616, 0.        , 0.02721049, 0.        ,\n",
              "         0.05131255, 0.06019967, 0.        , 0.        , 0.01855273,\n",
              "         0.01008845, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.04739674, 0.        ,\n",
              "         0.        , 0.02827165, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.05222943, 0.09395298, 0.0326547 , 0.02764263,\n",
              "         0.05439073, 0.05050679, 0.        , 0.        , 0.00917987,\n",
              "         0.03756544, 0.01964616, 0.        , 0.02721049, 0.        ,\n",
              "         0.05131255, 0.06019967, 0.        , 0.        , 0.01855273,\n",
              "         0.01008845, 0.        ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_pool_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQGdhT2cZgA8",
        "outputId": "99e006b4-767d-44d2-a200-ab86710d3e8d"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              "array([[0.02127084, 0.0764298 , 0.03304613, 0.07097452, 0.02211461,\n",
              "        0.02406022, 0.08851391, 0.01351929, 0.05630821, 0.        ,\n",
              "        0.05711921, 0.09230591, 0.09395298, 0.06134007, 0.02764263,\n",
              "        0.05923818, 0.07006411, 0.        , 0.02295003, 0.00917987,\n",
              "        0.09346423, 0.01964616, 0.00784606, 0.03471003, 0.00034138,\n",
              "        0.05131255, 0.07279582, 0.05921314, 0.04464867, 0.02910609,\n",
              "        0.02802909, 0.10612602]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs= layers.Input(shape=(1,),dtype=tf.string)\n",
        "x= text_vectorizer(inputs)\n",
        "x= embedding(x)\n",
        "\n",
        "x= layers.Conv1D(filters=64,\n",
        "                 kernel_size=5,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 padding='valid')(x)\n",
        "\n",
        "x= layers.GlobalMaxPool1D()(x)\n",
        "\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "model_5=tf.keras.Model(inputs, outputs,name='model_5_conv_1_d')"
      ],
      "metadata": {
        "id": "F8UkWImoZznJ"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP8-VeDDbDfx",
        "outputId": "f28521eb-368b-44d7-cced-99f9e15ee479"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_conv_1_d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_26 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_3 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gM8IgcekbXqi"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_history_Conv1D=model_5.fit(train_sentences,\n",
        "                                   train_labels,\n",
        "                                   validation_data=(val_sentences, val_labels),\n",
        "                                   epochs=5,\n",
        "                                   callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                          experiment_name=\"model_5_Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMdmNRFPbf1y",
        "outputId": "ae8cfb5b-f107-46f6-f0a8-4c8a3b63b5ff"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_Conv1D/20230616-042051\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 43ms/step - loss: 0.1539 - accuracy: 0.9475 - val_loss: 0.7620 - val_accuracy: 0.7874\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0991 - accuracy: 0.9622 - val_loss: 0.9322 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 10s 48ms/step - loss: 0.0797 - accuracy: 0.9686 - val_loss: 0.9887 - val_accuracy: 0.7756\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0710 - accuracy: 0.9737 - val_loss: 1.0264 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0608 - accuracy: 0.9765 - val_loss: 1.0954 - val_accuracy: 0.7559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_pred_probs=model_5.predict(val_sentences)\n",
        "model_5_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-42G2nw1bz3k",
        "outputId": "3946c09a-e39a-498f-e9fd-7e8b9f145e03"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.35339475e-01],\n",
              "       [9.45296705e-01],\n",
              "       [9.99912858e-01],\n",
              "       [3.07707358e-02],\n",
              "       [2.74930380e-06],\n",
              "       [9.97653365e-01],\n",
              "       [9.95280623e-01],\n",
              "       [9.99791980e-01],\n",
              "       [9.99997795e-01],\n",
              "       [7.12915719e-01],\n",
              "       [1.83202886e-07],\n",
              "       [8.84876192e-01],\n",
              "       [4.92535000e-05],\n",
              "       [3.29502553e-01],\n",
              "       [1.14479315e-06],\n",
              "       [1.76029466e-03],\n",
              "       [4.56018955e-04],\n",
              "       [7.32105036e-05],\n",
              "       [8.97629466e-03],\n",
              "       [9.87701893e-01],\n",
              "       [9.26538348e-01],\n",
              "       [1.29179507e-05],\n",
              "       [9.99353051e-01],\n",
              "       [1.63346238e-03],\n",
              "       [9.99997556e-01],\n",
              "       [1.00000000e+00],\n",
              "       [8.14487401e-04],\n",
              "       [1.10710898e-04],\n",
              "       [1.01419271e-03],\n",
              "       [8.37844491e-01],\n",
              "       [4.41846512e-02],\n",
              "       [1.26846935e-04],\n",
              "       [1.84090540e-01],\n",
              "       [4.46463143e-03],\n",
              "       [5.05934022e-02],\n",
              "       [4.98154283e-01],\n",
              "       [9.99995708e-01],\n",
              "       [1.04664445e-01],\n",
              "       [1.23588955e-02],\n",
              "       [9.99995887e-01],\n",
              "       [8.10995251e-02],\n",
              "       [1.46149287e-05],\n",
              "       [7.10433871e-02],\n",
              "       [1.46540391e-04],\n",
              "       [9.89894927e-01],\n",
              "       [9.99675274e-01],\n",
              "       [9.10119414e-01],\n",
              "       [9.73806679e-01],\n",
              "       [1.46442652e-03],\n",
              "       [6.58992767e-01],\n",
              "       [2.69529549e-03],\n",
              "       [2.53317237e-01],\n",
              "       [8.26775003e-03],\n",
              "       [1.31584946e-02],\n",
              "       [8.45262587e-01],\n",
              "       [3.04413233e-02],\n",
              "       [5.77524211e-03],\n",
              "       [9.99930978e-01],\n",
              "       [4.64525947e-05],\n",
              "       [1.69248585e-06],\n",
              "       [1.90091245e-02],\n",
              "       [9.99992728e-01],\n",
              "       [9.61724699e-01],\n",
              "       [2.28462946e-02],\n",
              "       [9.87255692e-01],\n",
              "       [9.99736071e-01],\n",
              "       [9.95553195e-01],\n",
              "       [4.70512919e-03],\n",
              "       [9.81120646e-01],\n",
              "       [1.20461220e-02],\n",
              "       [9.74744733e-04],\n",
              "       [1.27179250e-01],\n",
              "       [9.97323275e-01],\n",
              "       [2.03737966e-03],\n",
              "       [8.90874982e-01],\n",
              "       [9.62767601e-01],\n",
              "       [3.35926488e-02],\n",
              "       [9.84355271e-01],\n",
              "       [1.23706363e-01],\n",
              "       [1.19875220e-03],\n",
              "       [1.20120026e-01],\n",
              "       [1.84068680e-01],\n",
              "       [1.00000000e+00],\n",
              "       [6.75381860e-04],\n",
              "       [3.19150765e-03],\n",
              "       [1.21070270e-03],\n",
              "       [9.48938105e-05],\n",
              "       [1.15926948e-03],\n",
              "       [7.80046105e-01],\n",
              "       [9.99969721e-01],\n",
              "       [9.99999940e-01],\n",
              "       [1.15523580e-05],\n",
              "       [9.86156166e-01],\n",
              "       [6.09675655e-04],\n",
              "       [9.99999702e-01],\n",
              "       [9.45296705e-01],\n",
              "       [9.80101407e-01],\n",
              "       [9.99126077e-01],\n",
              "       [9.97905850e-01],\n",
              "       [9.99278307e-01],\n",
              "       [9.99999940e-01],\n",
              "       [1.41522626e-03],\n",
              "       [1.99063061e-06],\n",
              "       [9.98028457e-01],\n",
              "       [9.99930024e-01],\n",
              "       [1.18139215e-01],\n",
              "       [9.93187428e-01],\n",
              "       [9.99946237e-01],\n",
              "       [5.47401487e-06],\n",
              "       [9.69537079e-01],\n",
              "       [4.44265693e-01],\n",
              "       [5.45662999e-07],\n",
              "       [4.37144600e-02],\n",
              "       [1.35260387e-04],\n",
              "       [2.25982559e-03],\n",
              "       [2.38562405e-01],\n",
              "       [4.49766457e-01],\n",
              "       [9.90772247e-01],\n",
              "       [8.63317907e-01],\n",
              "       [1.35977834e-03],\n",
              "       [1.00000000e+00],\n",
              "       [3.13729106e-06],\n",
              "       [2.24170703e-02],\n",
              "       [7.36529350e-01],\n",
              "       [7.38495171e-01],\n",
              "       [9.61962808e-03],\n",
              "       [9.41157162e-01],\n",
              "       [5.13904379e-05],\n",
              "       [4.26065264e-04],\n",
              "       [9.64377046e-01],\n",
              "       [9.74427821e-05],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [9.99942780e-01],\n",
              "       [2.31817961e-01],\n",
              "       [9.99987900e-01],\n",
              "       [5.55818260e-01],\n",
              "       [8.27564043e-04],\n",
              "       [9.11345531e-04],\n",
              "       [9.99999940e-01],\n",
              "       [5.52844942e-01],\n",
              "       [3.29502553e-01],\n",
              "       [9.99990702e-01],\n",
              "       [4.21756692e-02],\n",
              "       [4.90428731e-02],\n",
              "       [1.03882607e-02],\n",
              "       [2.71720282e-08],\n",
              "       [4.33187792e-03],\n",
              "       [9.85387146e-01],\n",
              "       [1.13745977e-03],\n",
              "       [8.28688312e-03],\n",
              "       [6.26911595e-02],\n",
              "       [3.27067255e-07],\n",
              "       [7.13712396e-03],\n",
              "       [9.99991298e-01],\n",
              "       [9.98298585e-01],\n",
              "       [1.39937410e-02],\n",
              "       [9.81938064e-01],\n",
              "       [4.98039157e-08],\n",
              "       [9.85681951e-01],\n",
              "       [1.66916013e-01],\n",
              "       [1.54003069e-01],\n",
              "       [9.99987364e-01],\n",
              "       [1.79600026e-02],\n",
              "       [2.80109234e-04],\n",
              "       [9.99999940e-01],\n",
              "       [2.67329901e-01],\n",
              "       [9.99975502e-01],\n",
              "       [7.75069475e-01],\n",
              "       [9.99987900e-01],\n",
              "       [9.97157156e-01],\n",
              "       [9.87943113e-01],\n",
              "       [3.58029356e-05],\n",
              "       [9.99998212e-01],\n",
              "       [7.64588825e-03],\n",
              "       [2.97329575e-01],\n",
              "       [2.93132905e-02],\n",
              "       [9.42665398e-01],\n",
              "       [9.99990702e-01],\n",
              "       [4.98983718e-04],\n",
              "       [9.46228981e-01],\n",
              "       [9.95015860e-01],\n",
              "       [9.99998987e-01],\n",
              "       [9.93613124e-01],\n",
              "       [9.68944805e-04],\n",
              "       [3.73271578e-05],\n",
              "       [1.00000000e+00],\n",
              "       [1.25933084e-07],\n",
              "       [2.87243545e-08],\n",
              "       [4.61876392e-02],\n",
              "       [4.16911811e-01],\n",
              "       [1.75271798e-05],\n",
              "       [9.10129602e-05],\n",
              "       [3.90611348e-08],\n",
              "       [2.46524374e-04],\n",
              "       [3.00169522e-05],\n",
              "       [3.39011215e-02],\n",
              "       [9.94321525e-01],\n",
              "       [7.82918243e-04],\n",
              "       [2.69065779e-02],\n",
              "       [9.98939335e-01],\n",
              "       [9.99912381e-01],\n",
              "       [9.34247393e-03],\n",
              "       [4.99162183e-04],\n",
              "       [1.00000000e+00],\n",
              "       [9.99856234e-01],\n",
              "       [9.99890685e-01],\n",
              "       [8.83588433e-01],\n",
              "       [9.65177774e-01],\n",
              "       [5.26369393e-01],\n",
              "       [9.99999762e-01],\n",
              "       [1.25551869e-05],\n",
              "       [7.12762470e-04],\n",
              "       [5.39370603e-07],\n",
              "       [7.60133432e-08],\n",
              "       [9.99979556e-01],\n",
              "       [9.93466616e-01],\n",
              "       [9.83711362e-01],\n",
              "       [8.20912838e-01],\n",
              "       [3.68642174e-02],\n",
              "       [6.10304996e-05],\n",
              "       [7.98924128e-04],\n",
              "       [6.67776447e-04],\n",
              "       [9.99990702e-01],\n",
              "       [3.81841511e-01],\n",
              "       [1.22169957e-01],\n",
              "       [1.00000000e+00],\n",
              "       [8.65611732e-01],\n",
              "       [4.31387633e-01],\n",
              "       [7.08240914e-05],\n",
              "       [7.84533750e-03],\n",
              "       [9.90044236e-01],\n",
              "       [4.42749530e-01],\n",
              "       [2.39043027e-01],\n",
              "       [2.86457613e-02],\n",
              "       [6.08393431e-01],\n",
              "       [1.30210102e-01],\n",
              "       [3.30816535e-03],\n",
              "       [5.67630283e-04],\n",
              "       [5.84252596e-01],\n",
              "       [1.84185728e-02],\n",
              "       [1.00000000e+00],\n",
              "       [9.99939322e-01],\n",
              "       [2.07423756e-04],\n",
              "       [2.27525788e-06],\n",
              "       [9.99993563e-01],\n",
              "       [8.17760301e-05],\n",
              "       [3.08313384e-03],\n",
              "       [3.09821993e-01],\n",
              "       [7.87862427e-06],\n",
              "       [9.86295640e-01],\n",
              "       [2.72578715e-09],\n",
              "       [1.90768420e-04],\n",
              "       [9.99948800e-01],\n",
              "       [1.04944840e-01],\n",
              "       [9.99511302e-01],\n",
              "       [9.99999702e-01],\n",
              "       [7.47173503e-02],\n",
              "       [1.74902659e-03],\n",
              "       [2.54348014e-02],\n",
              "       [1.24592534e-05],\n",
              "       [5.36414461e-07],\n",
              "       [9.99998808e-01],\n",
              "       [9.99957085e-01],\n",
              "       [6.59773409e-01],\n",
              "       [9.99936759e-01],\n",
              "       [3.73697840e-04],\n",
              "       [5.82247116e-02],\n",
              "       [3.46117606e-03],\n",
              "       [4.27794503e-03],\n",
              "       [2.62621743e-05],\n",
              "       [9.99997139e-01],\n",
              "       [8.82562157e-03],\n",
              "       [2.57957169e-07],\n",
              "       [9.99991834e-01],\n",
              "       [3.91979156e-05],\n",
              "       [9.54756688e-04],\n",
              "       [9.99893546e-01],\n",
              "       [7.44053032e-05],\n",
              "       [7.53066987e-02],\n",
              "       [5.70341013e-04],\n",
              "       [9.99985039e-01],\n",
              "       [9.83517766e-01],\n",
              "       [8.61680210e-01],\n",
              "       [1.78936526e-01],\n",
              "       [9.97976780e-01],\n",
              "       [3.09013762e-04],\n",
              "       [9.99706447e-01],\n",
              "       [2.24194000e-03],\n",
              "       [7.38199890e-01],\n",
              "       [9.99200642e-01],\n",
              "       [9.81145278e-02],\n",
              "       [5.14104404e-02],\n",
              "       [9.48414308e-05],\n",
              "       [7.25079834e-01],\n",
              "       [8.47027230e-04],\n",
              "       [3.97429802e-02],\n",
              "       [2.46277582e-02],\n",
              "       [5.73919564e-02],\n",
              "       [1.56456488e-04],\n",
              "       [3.04842507e-03],\n",
              "       [5.56182675e-02],\n",
              "       [9.99925256e-01],\n",
              "       [9.58481990e-03],\n",
              "       [1.15561532e-04],\n",
              "       [3.91514152e-01],\n",
              "       [1.09040439e-01],\n",
              "       [4.44599241e-03],\n",
              "       [1.01850519e-05],\n",
              "       [3.40350380e-05],\n",
              "       [9.99857962e-01],\n",
              "       [1.50713205e-01],\n",
              "       [1.82992846e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.41358105e-02],\n",
              "       [9.99089777e-01],\n",
              "       [2.59605292e-02],\n",
              "       [1.70911066e-04],\n",
              "       [4.30671237e-02],\n",
              "       [1.88342208e-04],\n",
              "       [1.39303254e-02],\n",
              "       [9.99791980e-01],\n",
              "       [3.57666552e-01],\n",
              "       [9.99998569e-01],\n",
              "       [2.93228716e-01],\n",
              "       [1.51502572e-05],\n",
              "       [9.99997675e-01],\n",
              "       [1.53323184e-04],\n",
              "       [1.00000000e+00],\n",
              "       [7.92677340e-04],\n",
              "       [1.97639420e-05],\n",
              "       [9.99999940e-01],\n",
              "       [4.25215767e-05],\n",
              "       [3.31917799e-05],\n",
              "       [9.99971092e-01],\n",
              "       [3.03783099e-06],\n",
              "       [7.77969661e-04],\n",
              "       [9.96556640e-01],\n",
              "       [9.85167563e-01],\n",
              "       [1.28909085e-06],\n",
              "       [9.95623413e-03],\n",
              "       [9.99991894e-01],\n",
              "       [9.92659152e-01],\n",
              "       [9.91986573e-01],\n",
              "       [2.16119975e-01],\n",
              "       [8.62139881e-01],\n",
              "       [9.86720264e-01],\n",
              "       [3.56303714e-03],\n",
              "       [3.16352147e-04],\n",
              "       [3.21916235e-03],\n",
              "       [9.05808061e-03],\n",
              "       [1.85707413e-05],\n",
              "       [3.77971262e-01],\n",
              "       [1.82769999e-01],\n",
              "       [6.45344198e-06],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.17580232e-04],\n",
              "       [2.16889217e-01],\n",
              "       [1.07961930e-02],\n",
              "       [3.12960327e-01],\n",
              "       [9.65287447e-01],\n",
              "       [2.10290313e-01],\n",
              "       [8.01379720e-05],\n",
              "       [6.25395728e-07],\n",
              "       [3.94521980e-03],\n",
              "       [9.62893844e-01],\n",
              "       [4.20454307e-04],\n",
              "       [7.94876739e-02],\n",
              "       [1.76237718e-05],\n",
              "       [2.01053210e-02],\n",
              "       [5.64528368e-02],\n",
              "       [9.76598799e-01],\n",
              "       [3.52490619e-02],\n",
              "       [1.12031712e-05],\n",
              "       [2.17520017e-02],\n",
              "       [3.22611369e-02],\n",
              "       [9.99999881e-01],\n",
              "       [9.97007132e-01],\n",
              "       [7.20301986e-01],\n",
              "       [9.95405972e-01],\n",
              "       [4.50984583e-09],\n",
              "       [6.10549092e-01],\n",
              "       [9.99997973e-01],\n",
              "       [7.11696386e-01],\n",
              "       [3.72922152e-01],\n",
              "       [9.99979377e-01],\n",
              "       [5.20858429e-02],\n",
              "       [9.99977171e-01],\n",
              "       [3.04082478e-03],\n",
              "       [2.25589518e-02],\n",
              "       [8.81073654e-01],\n",
              "       [9.27096978e-02],\n",
              "       [1.00000000e+00],\n",
              "       [1.17942486e-02],\n",
              "       [1.64598809e-04],\n",
              "       [9.17690631e-05],\n",
              "       [2.10290313e-01],\n",
              "       [1.00000000e+00],\n",
              "       [7.46077683e-04],\n",
              "       [1.11271165e-01],\n",
              "       [9.99917150e-01],\n",
              "       [1.28780986e-04],\n",
              "       [1.00000000e+00],\n",
              "       [1.45717547e-03],\n",
              "       [2.20924412e-04],\n",
              "       [4.27306676e-03],\n",
              "       [9.82920527e-01],\n",
              "       [9.98775780e-01],\n",
              "       [1.10833044e-03],\n",
              "       [2.00961540e-06],\n",
              "       [1.18247956e-01],\n",
              "       [9.99981940e-01],\n",
              "       [1.64557502e-01],\n",
              "       [5.24737220e-03],\n",
              "       [1.51902974e-01],\n",
              "       [2.82427549e-01],\n",
              "       [6.27806094e-06],\n",
              "       [9.99993622e-01],\n",
              "       [4.54210013e-01],\n",
              "       [9.99999881e-01],\n",
              "       [9.99900699e-01],\n",
              "       [5.49162552e-02],\n",
              "       [9.12269413e-01],\n",
              "       [4.95735265e-04],\n",
              "       [9.99488652e-01],\n",
              "       [9.98893499e-01],\n",
              "       [9.84674096e-01],\n",
              "       [1.56537525e-03],\n",
              "       [2.56366450e-02],\n",
              "       [5.47004274e-05],\n",
              "       [3.96447635e-04],\n",
              "       [2.26441931e-04],\n",
              "       [2.80872424e-04],\n",
              "       [8.58641684e-01],\n",
              "       [9.48684663e-03],\n",
              "       [1.00000000e+00],\n",
              "       [9.99925256e-01],\n",
              "       [2.67925620e-01],\n",
              "       [9.45296705e-01],\n",
              "       [1.71004282e-03],\n",
              "       [4.43817291e-04],\n",
              "       [1.28746644e-01],\n",
              "       [4.54822838e-01],\n",
              "       [6.69885129e-02],\n",
              "       [4.77307811e-02],\n",
              "       [2.76598803e-06],\n",
              "       [1.53651496e-03],\n",
              "       [2.32946192e-07],\n",
              "       [9.99933898e-01],\n",
              "       [9.99419808e-01],\n",
              "       [9.99994934e-01],\n",
              "       [5.42349219e-01],\n",
              "       [7.37200737e-01],\n",
              "       [2.42518842e-01],\n",
              "       [4.26374697e-07],\n",
              "       [2.60268897e-02],\n",
              "       [9.98389661e-01],\n",
              "       [9.99999821e-01],\n",
              "       [1.08162703e-05],\n",
              "       [1.16207026e-01],\n",
              "       [5.62933928e-06],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [4.15925443e-01],\n",
              "       [3.48786376e-02],\n",
              "       [9.99998331e-01],\n",
              "       [6.71359070e-04],\n",
              "       [1.97759047e-02],\n",
              "       [9.99999106e-01],\n",
              "       [4.90549392e-05],\n",
              "       [8.47927731e-05],\n",
              "       [9.60550249e-01],\n",
              "       [3.60743612e-01],\n",
              "       [4.19957072e-01],\n",
              "       [9.99958098e-01],\n",
              "       [4.63050128e-05],\n",
              "       [4.14458947e-04],\n",
              "       [4.81646304e-04],\n",
              "       [2.10189555e-08],\n",
              "       [6.27956935e-04],\n",
              "       [9.99998033e-01],\n",
              "       [1.77350485e-05],\n",
              "       [5.24813473e-01],\n",
              "       [4.38162535e-01],\n",
              "       [1.84779037e-02],\n",
              "       [3.84547673e-02],\n",
              "       [1.00620555e-05],\n",
              "       [2.30105710e-03],\n",
              "       [9.99994218e-01],\n",
              "       [9.99120235e-01],\n",
              "       [7.46305287e-02],\n",
              "       [3.13427954e-05],\n",
              "       [3.93634699e-02],\n",
              "       [2.15084174e-06],\n",
              "       [9.98499751e-01],\n",
              "       [1.37382274e-04],\n",
              "       [9.66513991e-01],\n",
              "       [9.83431637e-01],\n",
              "       [6.97290242e-01],\n",
              "       [9.72893119e-01],\n",
              "       [5.22414625e-01],\n",
              "       [2.33766641e-02],\n",
              "       [1.67938531e-03],\n",
              "       [2.46456027e-01],\n",
              "       [6.95368290e-01],\n",
              "       [9.48644876e-01],\n",
              "       [1.12610348e-01],\n",
              "       [9.35696438e-03],\n",
              "       [2.88073988e-06],\n",
              "       [7.83576834e-05],\n",
              "       [2.87737641e-02],\n",
              "       [2.72887021e-01],\n",
              "       [7.24213123e-02],\n",
              "       [9.99995351e-01],\n",
              "       [9.99972761e-01],\n",
              "       [9.45296705e-01],\n",
              "       [9.99877334e-01],\n",
              "       [1.43538667e-02],\n",
              "       [4.89499835e-05],\n",
              "       [9.99008417e-01],\n",
              "       [7.35954940e-02],\n",
              "       [2.53630290e-03],\n",
              "       [8.07578638e-02],\n",
              "       [9.08620059e-01],\n",
              "       [2.76265233e-08],\n",
              "       [6.17119133e-01],\n",
              "       [9.67334092e-01],\n",
              "       [8.17739844e-01],\n",
              "       [9.99967039e-01],\n",
              "       [2.30599478e-01],\n",
              "       [6.13892730e-03],\n",
              "       [9.24282610e-01],\n",
              "       [4.62690805e-05],\n",
              "       [6.97283670e-02],\n",
              "       [1.59603596e-01],\n",
              "       [8.80933285e-01],\n",
              "       [9.50913072e-01],\n",
              "       [6.36085460e-04],\n",
              "       [1.96861848e-03],\n",
              "       [8.48356426e-01],\n",
              "       [5.98608423e-03],\n",
              "       [1.43980724e-03],\n",
              "       [5.36185980e-05],\n",
              "       [7.07195580e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99863863e-01],\n",
              "       [1.62734374e-01],\n",
              "       [9.99370873e-01],\n",
              "       [9.99986649e-01],\n",
              "       [8.56321662e-08],\n",
              "       [9.99994814e-01],\n",
              "       [1.56654567e-02],\n",
              "       [9.83570457e-01],\n",
              "       [1.69646695e-01],\n",
              "       [1.57505497e-02],\n",
              "       [1.28002939e-04],\n",
              "       [1.73019689e-05],\n",
              "       [1.50928451e-02],\n",
              "       [5.58835396e-04],\n",
              "       [3.94201994e-01],\n",
              "       [1.03989076e-02],\n",
              "       [9.99993265e-01],\n",
              "       [1.16412633e-03],\n",
              "       [9.34940577e-01],\n",
              "       [3.76944929e-01],\n",
              "       [4.11228044e-04],\n",
              "       [4.25999053e-03],\n",
              "       [9.99965370e-01],\n",
              "       [2.07944680e-02],\n",
              "       [9.99585748e-01],\n",
              "       [1.07184283e-01],\n",
              "       [1.11731570e-02],\n",
              "       [2.17289254e-01],\n",
              "       [1.73045532e-03],\n",
              "       [1.09038211e-01],\n",
              "       [9.99986649e-01],\n",
              "       [4.97893438e-07],\n",
              "       [2.48729513e-04],\n",
              "       [3.38497423e-02],\n",
              "       [1.00000000e+00],\n",
              "       [6.12219423e-02],\n",
              "       [3.23050976e-04],\n",
              "       [9.99654353e-01],\n",
              "       [2.95023845e-08],\n",
              "       [1.99617893e-02],\n",
              "       [1.12802899e-02],\n",
              "       [1.19848080e-01],\n",
              "       [1.87764846e-04],\n",
              "       [2.15264261e-01],\n",
              "       [1.52133480e-02],\n",
              "       [9.19337496e-02],\n",
              "       [4.19265963e-02],\n",
              "       [1.32098049e-01],\n",
              "       [1.69157996e-04],\n",
              "       [9.98711407e-01],\n",
              "       [9.96684968e-01],\n",
              "       [5.94533324e-01],\n",
              "       [1.61243661e-05],\n",
              "       [1.03583804e-03],\n",
              "       [9.99953210e-01],\n",
              "       [9.83493388e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.48750439e-01],\n",
              "       [9.95790243e-01],\n",
              "       [1.89103564e-04],\n",
              "       [9.80173230e-01],\n",
              "       [9.68960047e-01],\n",
              "       [1.53883892e-08],\n",
              "       [9.99233663e-01],\n",
              "       [2.01931261e-02],\n",
              "       [9.81542528e-01],\n",
              "       [9.99970078e-01],\n",
              "       [2.68129688e-02],\n",
              "       [3.85130319e-04],\n",
              "       [2.91808754e-01],\n",
              "       [3.41614236e-06],\n",
              "       [9.83695034e-03],\n",
              "       [1.00000000e+00],\n",
              "       [5.61093867e-01],\n",
              "       [9.89735365e-01],\n",
              "       [1.13841638e-01],\n",
              "       [9.99920905e-01],\n",
              "       [9.77302492e-01],\n",
              "       [8.34495947e-03],\n",
              "       [1.34695568e-07],\n",
              "       [8.42233062e-01],\n",
              "       [2.16159737e-04],\n",
              "       [6.97984397e-02],\n",
              "       [9.99980628e-01],\n",
              "       [9.98190522e-01],\n",
              "       [9.99999821e-01],\n",
              "       [9.99729991e-01],\n",
              "       [1.18155316e-01],\n",
              "       [8.52290213e-01],\n",
              "       [1.62892156e-05],\n",
              "       [9.34895098e-01],\n",
              "       [9.92123187e-01],\n",
              "       [9.99300480e-01],\n",
              "       [2.11542565e-03],\n",
              "       [7.72828519e-01],\n",
              "       [9.92782354e-01],\n",
              "       [1.45272512e-04],\n",
              "       [1.45163778e-02],\n",
              "       [1.12610348e-01],\n",
              "       [4.76085357e-02],\n",
              "       [4.42749411e-01],\n",
              "       [9.37115550e-01],\n",
              "       [1.00000000e+00],\n",
              "       [3.22660053e-04],\n",
              "       [2.58478713e-06],\n",
              "       [3.05247886e-06],\n",
              "       [1.05225667e-01],\n",
              "       [6.02474378e-04],\n",
              "       [9.91179235e-03],\n",
              "       [9.70439851e-01],\n",
              "       [1.54644385e-05],\n",
              "       [4.09657180e-01],\n",
              "       [9.49712172e-02],\n",
              "       [7.85713673e-01],\n",
              "       [9.99963701e-01],\n",
              "       [4.63296892e-04],\n",
              "       [9.25042927e-01],\n",
              "       [6.36552721e-02],\n",
              "       [9.11323639e-08],\n",
              "       [1.18062226e-03],\n",
              "       [1.00000000e+00],\n",
              "       [8.58054280e-01],\n",
              "       [2.85076999e-06],\n",
              "       [5.29001653e-02],\n",
              "       [2.63629705e-01],\n",
              "       [1.06788766e-05],\n",
              "       [9.99321282e-01],\n",
              "       [6.19897153e-03],\n",
              "       [7.31459558e-01],\n",
              "       [7.43325129e-02],\n",
              "       [4.30285744e-03],\n",
              "       [3.17929626e-01],\n",
              "       [1.13135986e-01],\n",
              "       [1.25272095e-03],\n",
              "       [9.93677557e-01],\n",
              "       [7.71728531e-02],\n",
              "       [5.21611929e-01],\n",
              "       [9.92666245e-01],\n",
              "       [8.52192104e-01],\n",
              "       [5.02394319e-01],\n",
              "       [2.76265233e-08],\n",
              "       [1.32039443e-01],\n",
              "       [5.95258355e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.57047701e-01],\n",
              "       [1.58358729e-04],\n",
              "       [9.99995530e-01],\n",
              "       [3.58136535e-01],\n",
              "       [9.78991449e-01],\n",
              "       [3.58136535e-01],\n",
              "       [9.99835551e-01],\n",
              "       [6.58447789e-06],\n",
              "       [2.23239705e-01],\n",
              "       [4.86077795e-07],\n",
              "       [9.99953985e-01],\n",
              "       [6.66858628e-02],\n",
              "       [9.98156238e-03],\n",
              "       [4.50211046e-05],\n",
              "       [1.64475739e-02],\n",
              "       [2.29809359e-02],\n",
              "       [1.53872112e-04],\n",
              "       [2.20154911e-01],\n",
              "       [2.46820366e-03],\n",
              "       [3.56099233e-02],\n",
              "       [9.24885571e-01],\n",
              "       [2.04526260e-03],\n",
              "       [7.29464833e-03],\n",
              "       [1.16771043e-04],\n",
              "       [7.24574960e-08],\n",
              "       [3.99203226e-02],\n",
              "       [7.21199095e-01],\n",
              "       [1.77306065e-03],\n",
              "       [8.10018256e-02],\n",
              "       [3.48167354e-03],\n",
              "       [9.94803548e-01],\n",
              "       [9.99994874e-01],\n",
              "       [2.08132621e-03],\n",
              "       [4.74413537e-05],\n",
              "       [1.80694326e-06],\n",
              "       [5.71514647e-07],\n",
              "       [9.99990821e-01],\n",
              "       [7.24574960e-08],\n",
              "       [2.11356468e-02],\n",
              "       [9.99965370e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99999940e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99999881e-01],\n",
              "       [7.76790912e-05],\n",
              "       [1.14202301e-03],\n",
              "       [7.67142236e-01],\n",
              "       [5.79077661e-01],\n",
              "       [9.99998152e-01],\n",
              "       [9.50271130e-01],\n",
              "       [5.51184833e-01],\n",
              "       [8.23334575e-01],\n",
              "       [7.94386387e-01],\n",
              "       [1.07425592e-06],\n",
              "       [1.36645957e-08],\n",
              "       [1.25382720e-02],\n",
              "       [5.80367148e-02],\n",
              "       [5.72392355e-06],\n",
              "       [1.24841253e-03],\n",
              "       [9.99941111e-01],\n",
              "       [9.99999762e-01],\n",
              "       [3.50398877e-05],\n",
              "       [9.99848068e-01],\n",
              "       [8.72989416e-01],\n",
              "       [1.75981577e-02],\n",
              "       [1.57883167e-02],\n",
              "       [7.15316176e-01],\n",
              "       [7.63786316e-01],\n",
              "       [2.24097297e-02],\n",
              "       [1.99670330e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_preds=tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wci8HGxwb5vm",
        "outputId": "1dbe80a6-374e-4a5d-e14e-6dc0bd1b71f3"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(y_true=val_labels,\n",
        "                  y_pred=model_5_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qN_ie--b_0I",
        "outputId": "68fb892b-c848-4939-f6ad-ad167fdbec96"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.59055118110236,\n",
              " 'precision': 0.7567160722556739,\n",
              " 'recall': 0.7559055118110236,\n",
              " 'f1-score': 0.7539595513230887}"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVqhW-_3cENL",
        "outputId": "7fb14d3e-8452-406a-e692-7bf9a111b00d"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6: Tensorflow Hub pretrained Sentence Encoding"
      ],
      "metadata": {
        "id": "SPmprk6KcOoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvb-dAhMeEaL",
        "outputId": "dca9db00-a253-4b5c-82d9-a73ee72772e3"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01648418  0.01238944 -0.03802393  0.0161351   0.01126495  0.03020511\n",
            " -0.03046945  0.06194782 -0.02105992 -0.03057138  0.00088417 -0.01712315\n",
            "  0.02300225  0.13233913 -0.02402747 -0.04065575 -0.00783854 -0.01782105\n",
            "  0.00084766 -0.06022933  0.03030975 -0.02432619  0.01335938 -0.00702189\n",
            " -0.03293562  0.01491862  0.06453035 -0.03094473 -0.02930314  0.05430475\n",
            " -0.04252576  0.03884935  0.05540232  0.04995463  0.01574395 -0.04668788\n",
            "  0.06723309  0.07616691 -0.03243509 -0.09583163  0.0146003   0.05765746\n",
            " -0.05838085  0.08828382 -0.1043603  -0.03254436 -0.03735406 -0.04613885\n",
            "  0.02244526 -0.0233586 ], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create keras layer using USE Pretrained Layer from tensorflow hub\n",
        "sentence_encoder_layer= hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                       input_shape=[],#output will be a 512 vector\n",
        "                                       dtype=tf.string,\n",
        "                                       trainable=False,\n",
        "                                       name='USE')"
      ],
      "metadata": {
        "id": "C9P3Ljs1ft8V"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create moled using the sequential api\n",
        "model_6=tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    #layers.Dense(64,activation='relu)\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "], name='mode_6_use')\n",
        "\n",
        "#Complie\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLcgH-GynLSs",
        "outputId": "214c3300-74ac-4958-f5c3-58768d39bcfe"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mode_6_use\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train a classifier on top of pretrianed embeddings\n",
        "history_model_6=model_6.fit(train_sentences,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_sentences, val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                   experiment_name=\"tf_hub_sentnece_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1atbnpDsnysG",
        "outputId": "cd1126a7-b732-4f3c-d3d3-582e7851c91a"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentnece_encoder/20230616-051506\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 19ms/step - loss: 0.6498 - accuracy: 0.7288 - val_loss: 0.6130 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.5819 - accuracy: 0.7886 - val_loss: 0.5635 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.5390 - accuracy: 0.7938 - val_loss: 0.5317 - val_accuracy: 0.7861\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.5102 - accuracy: 0.7968 - val_loss: 0.5103 - val_accuracy: 0.7913\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.4900 - accuracy: 0.7987 - val_loss: 0.4959 - val_accuracy: 0.7927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions\n",
        "model_6_pred_probs=model_6.predict(val_sentences)\n",
        "model_6_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR-Yog5joKl0",
        "outputId": "9d8bd207-0b13-4d48-a43a-f32da5cae432"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35161564],\n",
              "       [0.6891301 ],\n",
              "       [0.8524273 ],\n",
              "       [0.35444233],\n",
              "       [0.64164054],\n",
              "       [0.72213525],\n",
              "       [0.82817763],\n",
              "       [0.83883035],\n",
              "       [0.74394643],\n",
              "       [0.19880618],\n",
              "       [0.54153204],\n",
              "       [0.48303577],\n",
              "       [0.42178598],\n",
              "       [0.46238017],\n",
              "       [0.4959602 ],\n",
              "       [0.17271355],\n",
              "       [0.3453706 ],\n",
              "       [0.49210456],\n",
              "       [0.5195231 ],\n",
              "       [0.5022646 ],\n",
              "       [0.63838494],\n",
              "       [0.29874006],\n",
              "       [0.4601072 ],\n",
              "       [0.16130714],\n",
              "       [0.6137609 ],\n",
              "       [0.79713607],\n",
              "       [0.24751458],\n",
              "       [0.30635315],\n",
              "       [0.24569707],\n",
              "       [0.34957093],\n",
              "       [0.54838145],\n",
              "       [0.7574002 ],\n",
              "       [0.45782018],\n",
              "       [0.48496887],\n",
              "       [0.5105053 ],\n",
              "       [0.2019349 ],\n",
              "       [0.78702515],\n",
              "       [0.16655482],\n",
              "       [0.18981917],\n",
              "       [0.80969155],\n",
              "       [0.2343275 ],\n",
              "       [0.30271477],\n",
              "       [0.5536191 ],\n",
              "       [0.56575245],\n",
              "       [0.27554742],\n",
              "       [0.73854256],\n",
              "       [0.31260368],\n",
              "       [0.84358346],\n",
              "       [0.52590764],\n",
              "       [0.79742295],\n",
              "       [0.17301571],\n",
              "       [0.6099644 ],\n",
              "       [0.32274553],\n",
              "       [0.13661729],\n",
              "       [0.24280743],\n",
              "       [0.10669478],\n",
              "       [0.30086935],\n",
              "       [0.7041002 ],\n",
              "       [0.24855931],\n",
              "       [0.2037811 ],\n",
              "       [0.11120865],\n",
              "       [0.77647555],\n",
              "       [0.8280891 ],\n",
              "       [0.23738922],\n",
              "       [0.67989945],\n",
              "       [0.8104112 ],\n",
              "       [0.4089116 ],\n",
              "       [0.44324973],\n",
              "       [0.20262705],\n",
              "       [0.52761555],\n",
              "       [0.18224119],\n",
              "       [0.20508893],\n",
              "       [0.6151867 ],\n",
              "       [0.16307546],\n",
              "       [0.13622922],\n",
              "       [0.57656014],\n",
              "       [0.24721675],\n",
              "       [0.42080817],\n",
              "       [0.20922837],\n",
              "       [0.67301655],\n",
              "       [0.70446724],\n",
              "       [0.5269211 ],\n",
              "       [0.6569713 ],\n",
              "       [0.29602578],\n",
              "       [0.46822017],\n",
              "       [0.56266445],\n",
              "       [0.2002987 ],\n",
              "       [0.21325256],\n",
              "       [0.87808037],\n",
              "       [0.6310183 ],\n",
              "       [0.8860317 ],\n",
              "       [0.14293236],\n",
              "       [0.16568987],\n",
              "       [0.17761903],\n",
              "       [0.74116963],\n",
              "       [0.65886056],\n",
              "       [0.7522985 ],\n",
              "       [0.70242226],\n",
              "       [0.78832257],\n",
              "       [0.6990881 ],\n",
              "       [0.7546232 ],\n",
              "       [0.25799367],\n",
              "       [0.16111219],\n",
              "       [0.8268876 ],\n",
              "       [0.768904  ],\n",
              "       [0.16119772],\n",
              "       [0.5987056 ],\n",
              "       [0.596791  ],\n",
              "       [0.26991084],\n",
              "       [0.6979114 ],\n",
              "       [0.50290173],\n",
              "       [0.2575704 ],\n",
              "       [0.36308798],\n",
              "       [0.4298216 ],\n",
              "       [0.43312487],\n",
              "       [0.48792306],\n",
              "       [0.5479158 ],\n",
              "       [0.66527677],\n",
              "       [0.59961593],\n",
              "       [0.6493672 ],\n",
              "       [0.76928174],\n",
              "       [0.3576102 ],\n",
              "       [0.48807552],\n",
              "       [0.6597648 ],\n",
              "       [0.5747108 ],\n",
              "       [0.422174  ],\n",
              "       [0.27371514],\n",
              "       [0.24530554],\n",
              "       [0.17446716],\n",
              "       [0.49319944],\n",
              "       [0.2590535 ],\n",
              "       [0.7666624 ],\n",
              "       [0.7124429 ],\n",
              "       [0.79959255],\n",
              "       [0.61828387],\n",
              "       [0.4110588 ],\n",
              "       [0.7232625 ],\n",
              "       [0.32934603],\n",
              "       [0.36741108],\n",
              "       [0.24175082],\n",
              "       [0.83368105],\n",
              "       [0.31009752],\n",
              "       [0.47272885],\n",
              "       [0.5015318 ],\n",
              "       [0.55846655],\n",
              "       [0.29947364],\n",
              "       [0.11382548],\n",
              "       [0.20940962],\n",
              "       [0.257865  ],\n",
              "       [0.8176638 ],\n",
              "       [0.58223265],\n",
              "       [0.2264191 ],\n",
              "       [0.5580071 ],\n",
              "       [0.24803159],\n",
              "       [0.28132737],\n",
              "       [0.6554025 ],\n",
              "       [0.4456967 ],\n",
              "       [0.21105383],\n",
              "       [0.7464436 ],\n",
              "       [0.44968435],\n",
              "       [0.71378934],\n",
              "       [0.25014362],\n",
              "       [0.2039958 ],\n",
              "       [0.7942173 ],\n",
              "       [0.3090387 ],\n",
              "       [0.28488055],\n",
              "       [0.9145246 ],\n",
              "       [0.3801905 ],\n",
              "       [0.7362958 ],\n",
              "       [0.20683537],\n",
              "       [0.8151902 ],\n",
              "       [0.67947495],\n",
              "       [0.8282333 ],\n",
              "       [0.26952562],\n",
              "       [0.72656846],\n",
              "       [0.12301667],\n",
              "       [0.7728217 ],\n",
              "       [0.46727562],\n",
              "       [0.53972596],\n",
              "       [0.8527963 ],\n",
              "       [0.13172813],\n",
              "       [0.7088819 ],\n",
              "       [0.53863597],\n",
              "       [0.6808831 ],\n",
              "       [0.6851381 ],\n",
              "       [0.38112625],\n",
              "       [0.30125237],\n",
              "       [0.7672016 ],\n",
              "       [0.51618606],\n",
              "       [0.2872832 ],\n",
              "       [0.3771956 ],\n",
              "       [0.746585  ],\n",
              "       [0.45911586],\n",
              "       [0.51294816],\n",
              "       [0.29473233],\n",
              "       [0.35969144],\n",
              "       [0.23272923],\n",
              "       [0.35573766],\n",
              "       [0.42831126],\n",
              "       [0.2447835 ],\n",
              "       [0.28438315],\n",
              "       [0.7145193 ],\n",
              "       [0.66897243],\n",
              "       [0.25630605],\n",
              "       [0.37490174],\n",
              "       [0.89064705],\n",
              "       [0.3702154 ],\n",
              "       [0.7019838 ],\n",
              "       [0.77436846],\n",
              "       [0.69479597],\n",
              "       [0.14185528],\n",
              "       [0.77237964],\n",
              "       [0.22018981],\n",
              "       [0.31738102],\n",
              "       [0.16518758],\n",
              "       [0.16471577],\n",
              "       [0.6640334 ],\n",
              "       [0.6637065 ],\n",
              "       [0.49174604],\n",
              "       [0.16931842],\n",
              "       [0.5726901 ],\n",
              "       [0.19353457],\n",
              "       [0.15880191],\n",
              "       [0.30789685],\n",
              "       [0.7731757 ],\n",
              "       [0.31941393],\n",
              "       [0.30262682],\n",
              "       [0.74731237],\n",
              "       [0.6052119 ],\n",
              "       [0.43762147],\n",
              "       [0.6910394 ],\n",
              "       [0.20621505],\n",
              "       [0.7637784 ],\n",
              "       [0.12555218],\n",
              "       [0.56450874],\n",
              "       [0.41939402],\n",
              "       [0.46086073],\n",
              "       [0.40744972],\n",
              "       [0.761035  ],\n",
              "       [0.12151999],\n",
              "       [0.39853713],\n",
              "       [0.38055804],\n",
              "       [0.8365066 ],\n",
              "       [0.76833904],\n",
              "       [0.16183747],\n",
              "       [0.4119218 ],\n",
              "       [0.7181795 ],\n",
              "       [0.24302061],\n",
              "       [0.19615641],\n",
              "       [0.58457404],\n",
              "       [0.29783836],\n",
              "       [0.5357926 ],\n",
              "       [0.15069225],\n",
              "       [0.5054109 ],\n",
              "       [0.68383795],\n",
              "       [0.27009258],\n",
              "       [0.71810806],\n",
              "       [0.8820939 ],\n",
              "       [0.19646624],\n",
              "       [0.33212897],\n",
              "       [0.76008826],\n",
              "       [0.26134127],\n",
              "       [0.3326499 ],\n",
              "       [0.79373485],\n",
              "       [0.5758017 ],\n",
              "       [0.63443303],\n",
              "       [0.68535936],\n",
              "       [0.20857488],\n",
              "       [0.3640888 ],\n",
              "       [0.15152447],\n",
              "       [0.40937105],\n",
              "       [0.42186576],\n",
              "       [0.7733653 ],\n",
              "       [0.21487646],\n",
              "       [0.42600626],\n",
              "       [0.75410175],\n",
              "       [0.53644127],\n",
              "       [0.10264447],\n",
              "       [0.82528013],\n",
              "       [0.5394826 ],\n",
              "       [0.25802517],\n",
              "       [0.3180119 ],\n",
              "       [0.816837  ],\n",
              "       [0.4312436 ],\n",
              "       [0.26526678],\n",
              "       [0.63880193],\n",
              "       [0.45611283],\n",
              "       [0.25636274],\n",
              "       [0.5822476 ],\n",
              "       [0.22154748],\n",
              "       [0.5669357 ],\n",
              "       [0.44445652],\n",
              "       [0.5153999 ],\n",
              "       [0.5778443 ],\n",
              "       [0.2606805 ],\n",
              "       [0.70421743],\n",
              "       [0.41081923],\n",
              "       [0.8373451 ],\n",
              "       [0.09994587],\n",
              "       [0.62922984],\n",
              "       [0.544781  ],\n",
              "       [0.26485208],\n",
              "       [0.3248952 ],\n",
              "       [0.65259284],\n",
              "       [0.3908952 ],\n",
              "       [0.3347588 ],\n",
              "       [0.22810414],\n",
              "       [0.5160078 ],\n",
              "       [0.23104648],\n",
              "       [0.09703458],\n",
              "       [0.24089599],\n",
              "       [0.6865545 ],\n",
              "       [0.52142125],\n",
              "       [0.34989744],\n",
              "       [0.827965  ],\n",
              "       [0.1938108 ],\n",
              "       [0.7360169 ],\n",
              "       [0.5908557 ],\n",
              "       [0.19053529],\n",
              "       [0.3782095 ],\n",
              "       [0.24128893],\n",
              "       [0.22597188],\n",
              "       [0.8057709 ],\n",
              "       [0.1318877 ],\n",
              "       [0.61115414],\n",
              "       [0.2842156 ],\n",
              "       [0.3108579 ],\n",
              "       [0.701396  ],\n",
              "       [0.24495052],\n",
              "       [0.77893615],\n",
              "       [0.5723802 ],\n",
              "       [0.15890716],\n",
              "       [0.7370222 ],\n",
              "       [0.34491676],\n",
              "       [0.24484995],\n",
              "       [0.65691113],\n",
              "       [0.17309864],\n",
              "       [0.5184445 ],\n",
              "       [0.45666587],\n",
              "       [0.43820167],\n",
              "       [0.2109204 ],\n",
              "       [0.24076058],\n",
              "       [0.6990626 ],\n",
              "       [0.75880086],\n",
              "       [0.5973734 ],\n",
              "       [0.34077266],\n",
              "       [0.35688245],\n",
              "       [0.2673643 ],\n",
              "       [0.12701169],\n",
              "       [0.40990478],\n",
              "       [0.29624158],\n",
              "       [0.46619797],\n",
              "       [0.15537867],\n",
              "       [0.3751103 ],\n",
              "       [0.39916033],\n",
              "       [0.18777956],\n",
              "       [0.7871812 ],\n",
              "       [0.7828567 ],\n",
              "       [0.69909203],\n",
              "       [0.40118986],\n",
              "       [0.56050414],\n",
              "       [0.28219578],\n",
              "       [0.65296984],\n",
              "       [0.46198216],\n",
              "       [0.6234617 ],\n",
              "       [0.16159265],\n",
              "       [0.29095533],\n",
              "       [0.25054833],\n",
              "       [0.3404038 ],\n",
              "       [0.14152183],\n",
              "       [0.54505956],\n",
              "       [0.13296387],\n",
              "       [0.1590455 ],\n",
              "       [0.4109516 ],\n",
              "       [0.17864671],\n",
              "       [0.20850879],\n",
              "       [0.24457844],\n",
              "       [0.47924978],\n",
              "       [0.19805022],\n",
              "       [0.47760805],\n",
              "       [0.78532183],\n",
              "       [0.5323971 ],\n",
              "       [0.18657537],\n",
              "       [0.46262714],\n",
              "       [0.43858653],\n",
              "       [0.7308288 ],\n",
              "       [0.4953424 ],\n",
              "       [0.28568724],\n",
              "       [0.8738059 ],\n",
              "       [0.39678305],\n",
              "       [0.19158724],\n",
              "       [0.27826908],\n",
              "       [0.11713237],\n",
              "       [0.74930507],\n",
              "       [0.4816796 ],\n",
              "       [0.82536334],\n",
              "       [0.20099102],\n",
              "       [0.59655267],\n",
              "       [0.38382015],\n",
              "       [0.6242209 ],\n",
              "       [0.76289546],\n",
              "       [0.20140573],\n",
              "       [0.5906484 ],\n",
              "       [0.6819922 ],\n",
              "       [0.40160757],\n",
              "       [0.76733696],\n",
              "       [0.45743528],\n",
              "       [0.43940455],\n",
              "       [0.17122059],\n",
              "       [0.39319706],\n",
              "       [0.6548262 ],\n",
              "       [0.12471118],\n",
              "       [0.23831752],\n",
              "       [0.30652767],\n",
              "       [0.7748501 ],\n",
              "       [0.60229385],\n",
              "       [0.45287597],\n",
              "       [0.80236506],\n",
              "       [0.3098925 ],\n",
              "       [0.23687568],\n",
              "       [0.7531704 ],\n",
              "       [0.67511266],\n",
              "       [0.66562873],\n",
              "       [0.731865  ],\n",
              "       [0.17666352],\n",
              "       [0.6320241 ],\n",
              "       [0.19941956],\n",
              "       [0.61507463],\n",
              "       [0.269116  ],\n",
              "       [0.7492577 ],\n",
              "       [0.18005335],\n",
              "       [0.23661512],\n",
              "       [0.17113993],\n",
              "       [0.6200468 ],\n",
              "       [0.343486  ],\n",
              "       [0.34117702],\n",
              "       [0.29078266],\n",
              "       [0.56912196],\n",
              "       [0.7681525 ],\n",
              "       [0.62433857],\n",
              "       [0.635951  ],\n",
              "       [0.67854047],\n",
              "       [0.48131663],\n",
              "       [0.2855656 ],\n",
              "       [0.22806899],\n",
              "       [0.69310164],\n",
              "       [0.24091873],\n",
              "       [0.1264398 ],\n",
              "       [0.4470323 ],\n",
              "       [0.28319165],\n",
              "       [0.18352011],\n",
              "       [0.7032195 ],\n",
              "       [0.7336353 ],\n",
              "       [0.63551974],\n",
              "       [0.87109965],\n",
              "       [0.8122799 ],\n",
              "       [0.21648891],\n",
              "       [0.42608008],\n",
              "       [0.59046173],\n",
              "       [0.7775991 ],\n",
              "       [0.78261   ],\n",
              "       [0.14021938],\n",
              "       [0.28373405],\n",
              "       [0.48961747],\n",
              "       [0.8507935 ],\n",
              "       [0.8357981 ],\n",
              "       [0.32943746],\n",
              "       [0.26244026],\n",
              "       [0.7537047 ],\n",
              "       [0.11576708],\n",
              "       [0.18850064],\n",
              "       [0.7738077 ],\n",
              "       [0.6026614 ],\n",
              "       [0.44500154],\n",
              "       [0.45169052],\n",
              "       [0.66478026],\n",
              "       [0.7773628 ],\n",
              "       [0.83867794],\n",
              "       [0.15324636],\n",
              "       [0.17487945],\n",
              "       [0.51940036],\n",
              "       [0.2718515 ],\n",
              "       [0.30643132],\n",
              "       [0.7113221 ],\n",
              "       [0.09742688],\n",
              "       [0.48699278],\n",
              "       [0.3135871 ],\n",
              "       [0.17444512],\n",
              "       [0.40295798],\n",
              "       [0.50630975],\n",
              "       [0.4751075 ],\n",
              "       [0.7749995 ],\n",
              "       [0.3614742 ],\n",
              "       [0.41631258],\n",
              "       [0.31874081],\n",
              "       [0.325345  ],\n",
              "       [0.4432095 ],\n",
              "       [0.6963201 ],\n",
              "       [0.24922715],\n",
              "       [0.5322795 ],\n",
              "       [0.78382623],\n",
              "       [0.1197919 ],\n",
              "       [0.37199724],\n",
              "       [0.72685754],\n",
              "       [0.20776047],\n",
              "       [0.6441142 ],\n",
              "       [0.27750307],\n",
              "       [0.8027655 ],\n",
              "       [0.3127676 ],\n",
              "       [0.23672129],\n",
              "       [0.16384345],\n",
              "       [0.22209686],\n",
              "       [0.38625157],\n",
              "       [0.4489012 ],\n",
              "       [0.75597364],\n",
              "       [0.2266871 ],\n",
              "       [0.8227829 ],\n",
              "       [0.53376704],\n",
              "       [0.6486426 ],\n",
              "       [0.74629617],\n",
              "       [0.47439736],\n",
              "       [0.37562922],\n",
              "       [0.54869914],\n",
              "       [0.75507796],\n",
              "       [0.12143173],\n",
              "       [0.45965388],\n",
              "       [0.22591619],\n",
              "       [0.35076278],\n",
              "       [0.59326893],\n",
              "       [0.735184  ],\n",
              "       [0.61539865],\n",
              "       [0.7108007 ],\n",
              "       [0.19495673],\n",
              "       [0.19280462],\n",
              "       [0.5796409 ],\n",
              "       [0.25211352],\n",
              "       [0.1690271 ],\n",
              "       [0.21493672],\n",
              "       [0.3019329 ],\n",
              "       [0.55963063],\n",
              "       [0.3130256 ],\n",
              "       [0.4461253 ],\n",
              "       [0.36772653],\n",
              "       [0.37999913],\n",
              "       [0.37395975],\n",
              "       [0.4185486 ],\n",
              "       [0.55762506],\n",
              "       [0.82818216],\n",
              "       [0.7133065 ],\n",
              "       [0.63476044],\n",
              "       [0.6454483 ],\n",
              "       [0.6154525 ],\n",
              "       [0.3326375 ],\n",
              "       [0.6240519 ],\n",
              "       [0.16250204],\n",
              "       [0.8082855 ],\n",
              "       [0.17192714],\n",
              "       [0.38602668],\n",
              "       [0.5851497 ],\n",
              "       [0.15693566],\n",
              "       [0.19938174],\n",
              "       [0.44504508],\n",
              "       [0.79531604],\n",
              "       [0.779955  ],\n",
              "       [0.6245473 ],\n",
              "       [0.26105848],\n",
              "       [0.6175967 ],\n",
              "       [0.60187477],\n",
              "       [0.2069201 ],\n",
              "       [0.31304398],\n",
              "       [0.6454562 ],\n",
              "       [0.5924758 ],\n",
              "       [0.8405286 ],\n",
              "       [0.42633802],\n",
              "       [0.4339179 ],\n",
              "       [0.3784434 ],\n",
              "       [0.39715466],\n",
              "       [0.5929094 ],\n",
              "       [0.5687369 ],\n",
              "       [0.5137147 ],\n",
              "       [0.2298601 ],\n",
              "       [0.21267027],\n",
              "       [0.75422037],\n",
              "       [0.18054028],\n",
              "       [0.16431558],\n",
              "       [0.8058931 ],\n",
              "       [0.46578422],\n",
              "       [0.18820345],\n",
              "       [0.55912715],\n",
              "       [0.15642679],\n",
              "       [0.3848283 ],\n",
              "       [0.4210526 ],\n",
              "       [0.58670455],\n",
              "       [0.13198057],\n",
              "       [0.42298564],\n",
              "       [0.7668813 ],\n",
              "       [0.3389683 ],\n",
              "       [0.7488296 ],\n",
              "       [0.759163  ],\n",
              "       [0.1570654 ],\n",
              "       [0.23227812],\n",
              "       [0.22784765],\n",
              "       [0.72744286],\n",
              "       [0.41512462],\n",
              "       [0.7870429 ],\n",
              "       [0.3184337 ],\n",
              "       [0.4755657 ],\n",
              "       [0.29148072],\n",
              "       [0.19304734],\n",
              "       [0.5749144 ],\n",
              "       [0.23237732],\n",
              "       [0.7633465 ],\n",
              "       [0.22212929],\n",
              "       [0.28795484],\n",
              "       [0.83199143],\n",
              "       [0.36430883],\n",
              "       [0.19013757],\n",
              "       [0.47823608],\n",
              "       [0.18512608],\n",
              "       [0.61224675],\n",
              "       [0.8888368 ],\n",
              "       [0.33288848],\n",
              "       [0.8734606 ],\n",
              "       [0.28629974],\n",
              "       [0.57106936],\n",
              "       [0.29321966],\n",
              "       [0.6368415 ],\n",
              "       [0.5113792 ],\n",
              "       [0.48306644],\n",
              "       [0.13702184],\n",
              "       [0.67435145],\n",
              "       [0.697519  ],\n",
              "       [0.4930591 ],\n",
              "       [0.61838526],\n",
              "       [0.76654047],\n",
              "       [0.12480957],\n",
              "       [0.54632014],\n",
              "       [0.38716072],\n",
              "       [0.6014934 ],\n",
              "       [0.23854634],\n",
              "       [0.6202469 ],\n",
              "       [0.37274086],\n",
              "       [0.54872584],\n",
              "       [0.3049125 ],\n",
              "       [0.35744607],\n",
              "       [0.44978082],\n",
              "       [0.173431  ],\n",
              "       [0.47472113],\n",
              "       [0.3515515 ],\n",
              "       [0.7240683 ],\n",
              "       [0.8575228 ],\n",
              "       [0.16597334],\n",
              "       [0.3102413 ],\n",
              "       [0.19585778],\n",
              "       [0.33765617],\n",
              "       [0.34657034],\n",
              "       [0.16720429],\n",
              "       [0.73282266],\n",
              "       [0.25773737],\n",
              "       [0.37535116],\n",
              "       [0.23828733],\n",
              "       [0.26045218],\n",
              "       [0.6841954 ],\n",
              "       [0.29116264],\n",
              "       [0.21352388],\n",
              "       [0.28230116],\n",
              "       [0.314546  ],\n",
              "       [0.39878336],\n",
              "       [0.80874115],\n",
              "       [0.5010295 ],\n",
              "       [0.24264218],\n",
              "       [0.34399384],\n",
              "       [0.25332668],\n",
              "       [0.09525536],\n",
              "       [0.76306474],\n",
              "       [0.46813753],\n",
              "       [0.6097172 ],\n",
              "       [0.5865235 ],\n",
              "       [0.27969158],\n",
              "       [0.4960727 ],\n",
              "       [0.47338638],\n",
              "       [0.14906368],\n",
              "       [0.49325362],\n",
              "       [0.6141073 ],\n",
              "       [0.32794738],\n",
              "       [0.7611403 ],\n",
              "       [0.1328972 ],\n",
              "       [0.39706314],\n",
              "       [0.35076278],\n",
              "       [0.16213898],\n",
              "       [0.78082144],\n",
              "       [0.77626854],\n",
              "       [0.37016103],\n",
              "       [0.25467685],\n",
              "       [0.82612807],\n",
              "       [0.6504419 ],\n",
              "       [0.6248545 ],\n",
              "       [0.5994536 ],\n",
              "       [0.6496457 ],\n",
              "       [0.39616826],\n",
              "       [0.3502756 ],\n",
              "       [0.48391297],\n",
              "       [0.7069782 ],\n",
              "       [0.27978688],\n",
              "       [0.43747175],\n",
              "       [0.44699797],\n",
              "       [0.5134335 ],\n",
              "       [0.20941995],\n",
              "       [0.26150104],\n",
              "       [0.36618555],\n",
              "       [0.23628539],\n",
              "       [0.3345886 ],\n",
              "       [0.6533264 ],\n",
              "       [0.13220401],\n",
              "       [0.18041764],\n",
              "       [0.27325884],\n",
              "       [0.42912376],\n",
              "       [0.16007558],\n",
              "       [0.6004998 ],\n",
              "       [0.18857907],\n",
              "       [0.518756  ],\n",
              "       [0.22638454],\n",
              "       [0.1765978 ],\n",
              "       [0.6281058 ],\n",
              "       [0.282747  ],\n",
              "       [0.34199664],\n",
              "       [0.24491985],\n",
              "       [0.22628057],\n",
              "       [0.79089314],\n",
              "       [0.4130089 ],\n",
              "       [0.25797978],\n",
              "       [0.7571538 ],\n",
              "       [0.70348334],\n",
              "       [0.700259  ],\n",
              "       [0.87237704],\n",
              "       [0.836431  ],\n",
              "       [0.27417415],\n",
              "       [0.28103885],\n",
              "       [0.12097548],\n",
              "       [0.50341713],\n",
              "       [0.67308307],\n",
              "       [0.4861127 ],\n",
              "       [0.4408805 ],\n",
              "       [0.28577495],\n",
              "       [0.5034438 ],\n",
              "       [0.46036088],\n",
              "       [0.4710449 ],\n",
              "       [0.28977317],\n",
              "       [0.3300801 ],\n",
              "       [0.2411673 ],\n",
              "       [0.22066574],\n",
              "       [0.5370399 ],\n",
              "       [0.7485754 ],\n",
              "       [0.22256213],\n",
              "       [0.76044965],\n",
              "       [0.62902486],\n",
              "       [0.21223217],\n",
              "       [0.2768031 ],\n",
              "       [0.2057567 ],\n",
              "       [0.7166662 ],\n",
              "       [0.5546115 ],\n",
              "       [0.3752544 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_preds=tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx3NjhggoY20",
        "outputId": "7a9eba17-3800-4277-c02e-8244dbb30938"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results=calculate_results(y_true=val_labels,\n",
        "                  y_pred=model_6_preds)"
      ],
      "metadata": {
        "id": "SUaDolUGoi1x"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04jMSzwToqhb",
        "outputId": "4c2c542c-9b76-4a34-ffec-ddc28f29d6bd"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.7930624875358199,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7916058782200516}"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "ZKnM52waouVz",
        "outputId": "13e599a0-2540-4ec1-f6c7-97f58c330b7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fc25854fca07>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'baseline_results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBIk9FMvove3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}