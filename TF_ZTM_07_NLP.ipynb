{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwkhxClPRhruxGYu9y/w5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshitgosain/Tensorflow-ZTM/blob/main/TF_ZTM_07_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Fundamentals in TF"
      ],
      "metadata": {
        "id": "CKP8rK-46aDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence-to-sequence\n",
        "* One to one- Image Captioning\n",
        "* Many to one- Sentiment analysis\n",
        "* Many to one- time series forecasting\n",
        "* many- to-many- Machine translation\n"
      ],
      "metadata": {
        "id": "UEIfyi-r8kcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfEm1Kes8lgu",
        "outputId": "165e57c6-b7af-4706-fe24-2305113b1f93"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-c8cff312-ebbc-c4f7-6a64-89c9a478a6b0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3FIIV0NRezo",
        "outputId": "355578e9-acfb-443b-8462-80fbdbae5259"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-17 04:19:30--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-17 04:19:30 (98.1 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "FZdua_xCR3nj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu1aEiChSBoa",
        "outputId": "0313f169-48d6-4b02-fa3f-807007482d20"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-17 04:19:34--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 142.250.4.128, 142.251.10.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip.1’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K   700KB/s    in 0.8s    \n",
            "\n",
            "2023-06-17 04:19:35 (700 KB/s) - ‘nlp_getting_started.zip.1’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "id": "ZwhaaRJFSXGF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the dataset\n",
        "\n",
        "To visualize the sample data, we need to read the in. On way is to use python.\n",
        "\n",
        "Another way to do this is use pandas\n",
        "\n"
      ],
      "metadata": {
        "id": "FnODZX-2SZtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df=pd.read_csv(\"train.csv\")\n",
        "test_df=pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "OA7Fu5nwKZJE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yECy1rYFLgUa",
        "outputId": "1276cdc5-b850-42ea-fb7b-b532dcafcdaa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ccc169d-2401-4d31-8130-7524c8ba90f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ccc169d-2401-4d31-8130-7524c8ba90f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ccc169d-2401-4d31-8130-7524c8ba90f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ccc169d-2401-4d31-8130-7524c8ba90f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_shuffled=train_df.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "6mcpKv3ULfok"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_shuffled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "rheeFHeLMEPe",
        "outputId": "e0d2bd0a-2481-4039-c916-fa410d07c8a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id       keyword                        location  \\\n",
              "2644   3796   destruction                             NaN   \n",
              "2227   3185        deluge                             NaN   \n",
              "5448   7769        police                              UK   \n",
              "132     191    aftershock                             NaN   \n",
              "6845   9810        trauma           Montgomery County, MD   \n",
              "...     ...           ...                             ...   \n",
              "5226   7470  obliteration                         Merica!   \n",
              "5390   7691         panic                             NaN   \n",
              "860    1242         blood                             NaN   \n",
              "7603  10862           NaN                             NaN   \n",
              "7270  10409     whirlwind  Stamford & Cork (& Shropshire)   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  \n",
              "...                                                 ...     ...  \n",
              "5226  @Eganator2000 There aren't many Obliteration s...       0  \n",
              "5390  just had a panic attack bc I don't have enough...       0  \n",
              "860   Omron HEM-712C Automatic Blood Pressure Monito...       0  \n",
              "7603  Officials say a quarantine is in place at an A...       1  \n",
              "7270  I moved to England five years ago today. What ...       1  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0037e6bf-831f-443c-859f-819c9856e3fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5226</th>\n",
              "      <td>7470</td>\n",
              "      <td>obliteration</td>\n",
              "      <td>Merica!</td>\n",
              "      <td>@Eganator2000 There aren't many Obliteration s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>7691</td>\n",
              "      <td>panic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>just had a panic attack bc I don't have enough...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>1242</td>\n",
              "      <td>blood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Omron HEM-712C Automatic Blood Pressure Monito...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7603</th>\n",
              "      <td>10862</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Officials say a quarantine is in place at an A...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>10409</td>\n",
              "      <td>whirlwind</td>\n",
              "      <td>Stamford &amp; Cork (&amp; Shropshire)</td>\n",
              "      <td>I moved to England five years ago today. What ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0037e6bf-831f-443c-859f-819c9856e3fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0037e6bf-831f-443c-859f-819c9856e3fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0037e6bf-831f-443c-859f-819c9856e3fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test dataframe looks like:\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EOKnKXMgMLmz",
        "outputId": "c14c2c23-1077-41b6-ac9d-f2666e45ff24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb880aac-8d83-43c5-81e2-c23ceb2ed66b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb880aac-8d83-43c5-81e2-c23ceb2ed66b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb880aac-8d83-43c5-81e2-c23ceb2ed66b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb880aac-8d83-43c5-81e2-c23ceb2ed66b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVroyArwMSAd",
        "outputId": "e17d8633-5efc-40a1-b094-4fb8e2444c20"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How many total number of samples\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJwjZWDvMbP0",
        "outputId": "ce603bca-3dbc-496c-e29c-89d9eae395fe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's visualize some random training samples\n",
        "import random\n",
        "random_index = random.randint(0,len(train_df)-5)\n",
        "for row in train_data_shuffled[['text','target']][random_index:random_index+5].itertuples():\n",
        "  _,text, target=row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target >0 else \"(not real disaster)\")\n",
        "  print(f\"text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDoIh77fM8xb",
        "outputId": "3b982290-8963-4566-f5a1-3459b69d062d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "text:\n",
            "Lmao that light skin guy blew up on Twitter by talking about how ugly he was as a kid..\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "text:\n",
            "I just screamed what the fuck is a hond\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "text:\n",
            "So if I capsize on your thighs high tide B-5 you sunk my battleship\n",
            "&gt;\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "text:\n",
            "@zaynmalik don't overwork yourself. Your album is gonna be fire just don't overwork or stress! I love you take care\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "text:\n",
            "Armageddon averted by El Patron\n",
            "#UltimaLucha\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and validation sets\n",
        "\n"
      ],
      "metadata": {
        "id": "Q3_KYNkVORfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "K-_DDtcAeap3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels=train_test_split(train_data_shuffled['text'].to_numpy(),\n",
        "                                                                          train_data_shuffled['target'].to_numpy(),\n",
        "                                                                          test_size=0.1,\n",
        "                                                                          random_state=42)"
      ],
      "metadata": {
        "id": "rFRtXZeded8h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvV1nQX6fD8S",
        "outputId": "1ff556cb-c621-4323-98a6-ab4a0327e719"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting words into numbers\n",
        "\n",
        "First thing while building a model is to convert your text into numbers\n"
      ],
      "metadata": {
        "id": "xQJN3MYYktnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization VS Embedding\n",
        "Tkenization - word level and character level. Direct apping of a token.\n",
        "\n",
        "Embedding - every word gets turned into a vector and we can define size of the vector. Embeddings can learn as our model trains\n",
        "\n"
      ],
      "metadata": {
        "id": "6GOhJ-mcfRFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text vectorization(tokenization)"
      ],
      "metadata": {
        "id": "CZ_FBHbwjhjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "metadata": {
        "id": "otEJGiTzJmNX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the default text vectorization parameters\n",
        "text_vectoizer= TextVectorization(max_tokens=None, #Defines how many words in our vocab\n",
        "                               standardize= \"lower_and_strip_punctuation\",\n",
        "                               split=\"whitespace\",\n",
        "                               ngrams=None,\n",
        "                               output_mode='int',\n",
        "                               output_sequence_length=None) #how long do you want your sequences to be\n",
        "                               #pad_to_max_tokens=True)"
      ],
      "metadata": {
        "id": "1iQnXkkeJvaQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[0].split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7P5w8FmXiRk",
        "outputId": "53ecefd5-587c-4cf5-d2ef-d1b8f526c3aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the average number of tokens(words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUNdYmJ9WjZY",
        "outputId": "88fddbea-6d3a-4a4a-ddf4-2864f871eb60"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length= 10000 #max no of words to have in our vocab\n",
        "max_length=15 #Max length our sequences will be (e.g. how many words from a Tweet does a model see)\n",
        "\n",
        "text_vectorizer=TextVectorization(max_tokens=max_vocab_length,\n",
        "                                     output_mode=\"int\",\n",
        "                                     output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "LMx1h8VWX4uS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)\n"
      ],
      "metadata": {
        "id": "yo-nO5JSYXiy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIUXVbetZ-sI",
        "outputId": "65693604-2e4a-44e7-f918-c3355feebfe3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "       '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "       'destroy the free fandom honestly',\n",
              "       'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "       '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "       'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a sample sentence and tokenize it\n",
        "sample_sentence=\"There is a floow in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfFwEaKYaAoe",
        "outputId": "16441417-5028-4ae2-dc32-a362d536ec43"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 74,   9,   3,   1,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence=random.choice(train_sentences)\n",
        "print(random_sentence)\n",
        "vectorized_random_sentence=text_vectorizer([random_sentence])\n",
        "print(f\"Random Sentence: {random_sentence}\\nVectoized Random Sentence: {vectorized_random_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfpgC8tgaN4z",
        "outputId": "8c5b8d7f-3203-4c6d-a8fc-265a4847dfe6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "catastrophic-fallen-angel: reveillertm: macabrelolita: I was supposed to write Û÷amino acidsÛª and I nearly... http://t.co/dIoBzGHFju\n",
            "Random Sentence: catastrophic-fallen-angel: reveillertm: macabrelolita: I was supposed to write Û÷amino acidsÛª and I nearly... http://t.co/dIoBzGHFju\n",
            "Vectoized Random Sentence: [[   1 9117    1    8   23 1463    5 1917 6429    1    7    8  841    1\n",
            "     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_vocab=text_vectorizer.get_vocabulary()\n",
        "top_5_words=words_in_vocab[:5]\n",
        "botton_5_words=words_in_vocab[-5:]"
      ],
      "metadata": {
        "id": "ijV2vvTqbNLm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_vocab,top_5_words,botton_5_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WMshKSybv4a",
        "outputId": "5b65781d-6c9d-4e86-c477-9909533d2c1d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['',\n",
              "  '[UNK]',\n",
              "  'the',\n",
              "  'a',\n",
              "  'in',\n",
              "  'to',\n",
              "  'of',\n",
              "  'and',\n",
              "  'i',\n",
              "  'is',\n",
              "  'for',\n",
              "  'on',\n",
              "  'you',\n",
              "  'my',\n",
              "  'with',\n",
              "  'it',\n",
              "  'that',\n",
              "  'at',\n",
              "  'by',\n",
              "  'this',\n",
              "  'from',\n",
              "  'be',\n",
              "  'are',\n",
              "  'was',\n",
              "  'have',\n",
              "  'like',\n",
              "  'as',\n",
              "  'up',\n",
              "  'so',\n",
              "  'just',\n",
              "  'but',\n",
              "  'me',\n",
              "  'im',\n",
              "  'your',\n",
              "  'not',\n",
              "  'amp',\n",
              "  'out',\n",
              "  'its',\n",
              "  'will',\n",
              "  'an',\n",
              "  'no',\n",
              "  'has',\n",
              "  'fire',\n",
              "  'after',\n",
              "  'all',\n",
              "  'when',\n",
              "  'we',\n",
              "  'if',\n",
              "  'now',\n",
              "  'via',\n",
              "  'new',\n",
              "  'more',\n",
              "  'get',\n",
              "  'or',\n",
              "  'about',\n",
              "  'what',\n",
              "  'he',\n",
              "  'people',\n",
              "  'news',\n",
              "  'been',\n",
              "  'over',\n",
              "  'one',\n",
              "  'how',\n",
              "  'dont',\n",
              "  'they',\n",
              "  'who',\n",
              "  'into',\n",
              "  'were',\n",
              "  'do',\n",
              "  'us',\n",
              "  '2',\n",
              "  'can',\n",
              "  'video',\n",
              "  'emergency',\n",
              "  'there',\n",
              "  'disaster',\n",
              "  'than',\n",
              "  'police',\n",
              "  'would',\n",
              "  'his',\n",
              "  'still',\n",
              "  'her',\n",
              "  'some',\n",
              "  'body',\n",
              "  'storm',\n",
              "  'crash',\n",
              "  'burning',\n",
              "  'suicide',\n",
              "  'back',\n",
              "  'man',\n",
              "  'california',\n",
              "  'why',\n",
              "  'time',\n",
              "  'them',\n",
              "  'had',\n",
              "  'buildings',\n",
              "  'rt',\n",
              "  'first',\n",
              "  'cant',\n",
              "  'see',\n",
              "  'got',\n",
              "  'day',\n",
              "  'off',\n",
              "  'our',\n",
              "  'going',\n",
              "  'nuclear',\n",
              "  'know',\n",
              "  'world',\n",
              "  'bomb',\n",
              "  'fires',\n",
              "  'love',\n",
              "  'killed',\n",
              "  'go',\n",
              "  'attack',\n",
              "  'youtube',\n",
              "  'dead',\n",
              "  'two',\n",
              "  'families',\n",
              "  '3',\n",
              "  'train',\n",
              "  'full',\n",
              "  'being',\n",
              "  'war',\n",
              "  'many',\n",
              "  'today',\n",
              "  'think',\n",
              "  'only',\n",
              "  'car',\n",
              "  'accident',\n",
              "  'life',\n",
              "  'hiroshima',\n",
              "  'their',\n",
              "  'say',\n",
              "  'may',\n",
              "  'down',\n",
              "  'watch',\n",
              "  'good',\n",
              "  'could',\n",
              "  'want',\n",
              "  'last',\n",
              "  'here',\n",
              "  'years',\n",
              "  'u',\n",
              "  'then',\n",
              "  'make',\n",
              "  'did',\n",
              "  'wildfire',\n",
              "  'way',\n",
              "  'help',\n",
              "  'best',\n",
              "  'too',\n",
              "  'even',\n",
              "  'because',\n",
              "  'home',\n",
              "  'death',\n",
              "  'collapse',\n",
              "  'bombing',\n",
              "  'mass',\n",
              "  'him',\n",
              "  'black',\n",
              "  'am',\n",
              "  'those',\n",
              "  'need',\n",
              "  'fatal',\n",
              "  'army',\n",
              "  'another',\n",
              "  'work',\n",
              "  'take',\n",
              "  'should',\n",
              "  'really',\n",
              "  'please',\n",
              "  'mh370',\n",
              "  'youre',\n",
              "  'look',\n",
              "  'lol',\n",
              "  'hot',\n",
              "  'pm',\n",
              "  'legionnaires',\n",
              "  '4',\n",
              "  'right',\n",
              "  '5',\n",
              "  'let',\n",
              "  'city',\n",
              "  'year',\n",
              "  'wreck',\n",
              "  'school',\n",
              "  'northern',\n",
              "  'much',\n",
              "  'forest',\n",
              "  'bomber',\n",
              "  'water',\n",
              "  'she',\n",
              "  'never',\n",
              "  'read',\n",
              "  'latest',\n",
              "  'homes',\n",
              "  'great',\n",
              "  'every',\n",
              "  '1',\n",
              "  'live',\n",
              "  'god',\n",
              "  'fear',\n",
              "  'any',\n",
              "  '\\x89Û',\n",
              "  'under',\n",
              "  'said',\n",
              "  'old',\n",
              "  'floods',\n",
              "  '2015',\n",
              "  'getting',\n",
              "  'atomic',\n",
              "  'while',\n",
              "  'top',\n",
              "  'obama',\n",
              "  'feel',\n",
              "  'thats',\n",
              "  'since',\n",
              "  'near',\n",
              "  'flames',\n",
              "  'ever',\n",
              "  'come',\n",
              "  'where',\n",
              "  'these',\n",
              "  'military',\n",
              "  'japan',\n",
              "  'found',\n",
              "  'content',\n",
              "  'ass',\n",
              "  'without',\n",
              "  'weather',\n",
              "  'most',\n",
              "  'flooding',\n",
              "  'flood',\n",
              "  'damage',\n",
              "  'which',\n",
              "  'shit',\n",
              "  's',\n",
              "  'hope',\n",
              "  'everyone',\n",
              "  'before',\n",
              "  'stop',\n",
              "  'plan',\n",
              "  'malaysia',\n",
              "  'injured',\n",
              "  'hit',\n",
              "  'evacuation',\n",
              "  'during',\n",
              "  'debris',\n",
              "  'cross',\n",
              "  'coming',\n",
              "  'wild',\n",
              "  'well',\n",
              "  'times',\n",
              "  'sinking',\n",
              "  'oil',\n",
              "  'fucking',\n",
              "  'check',\n",
              "  'cause',\n",
              "  'weapons',\n",
              "  'truck',\n",
              "  'food',\n",
              "  'bloody',\n",
              "  'always',\n",
              "  'weapon',\n",
              "  'theres',\n",
              "  'state',\n",
              "  'little',\n",
              "  'injuries',\n",
              "  'free',\n",
              "  'wounded',\n",
              "  'summer',\n",
              "  'smoke',\n",
              "  'severe',\n",
              "  'reddit',\n",
              "  'next',\n",
              "  'movie',\n",
              "  'ive',\n",
              "  'hes',\n",
              "  'fall',\n",
              "  'evacuate',\n",
              "  'confirmed',\n",
              "  'bad',\n",
              "  'again',\n",
              "  'thunderstorm',\n",
              "  'set',\n",
              "  'night',\n",
              "  'natural',\n",
              "  'looks',\n",
              "  'heat',\n",
              "  'face',\n",
              "  'earthquake',\n",
              "  'boy',\n",
              "  'whole',\n",
              "  'until',\n",
              "  'thunder',\n",
              "  'through',\n",
              "  'says',\n",
              "  'panic',\n",
              "  'outbreak',\n",
              "  'made',\n",
              "  'lightning',\n",
              "  'fatalities',\n",
              "  'family',\n",
              "  'explosion',\n",
              "  'end',\n",
              "  'destroy',\n",
              "  'derailment',\n",
              "  'air',\n",
              "  'w',\n",
              "  'terrorist',\n",
              "  'survive',\n",
              "  'screaming',\n",
              "  'saudi',\n",
              "  'refugees',\n",
              "  'rain',\n",
              "  'murder',\n",
              "  'loud',\n",
              "  'liked',\n",
              "  'house',\n",
              "  'gonna',\n",
              "  'failure',\n",
              "  'collided',\n",
              "  'bag',\n",
              "  'attacked',\n",
              "  'ambulance',\n",
              "  '70',\n",
              "  'wind',\n",
              "  'services',\n",
              "  'save',\n",
              "  'report',\n",
              "  'migrants',\n",
              "  'head',\n",
              "  'explode',\n",
              "  'charged',\n",
              "  'change',\n",
              "  'big',\n",
              "  'also',\n",
              "  'wrecked',\n",
              "  'warning',\n",
              "  'update',\n",
              "  'run',\n",
              "  'rescuers',\n",
              "  'released',\n",
              "  'photo',\n",
              "  'massacre',\n",
              "  'injury',\n",
              "  'hurricane',\n",
              "  'high',\n",
              "  'hail',\n",
              "  'fuck',\n",
              "  'does',\n",
              "  'destroyed',\n",
              "  'bus',\n",
              "  'blood',\n",
              "  '40',\n",
              "  '\\x89ÛÒ',\n",
              "  'wreckage',\n",
              "  'violent',\n",
              "  'twister',\n",
              "  'trauma',\n",
              "  'tragedy',\n",
              "  'terrorism',\n",
              "  'survivors',\n",
              "  'survived',\n",
              "  'sinkhole',\n",
              "  'sandstorm',\n",
              "  'road',\n",
              "  'rioting',\n",
              "  'red',\n",
              "  'real',\n",
              "  'put',\n",
              "  'post',\n",
              "  'national',\n",
              "  'missing',\n",
              "  'landslide',\n",
              "  'keep',\n",
              "  'girl',\n",
              "  'drought',\n",
              "  'curfew',\n",
              "  'breaking',\n",
              "  'bags',\n",
              "  'white',\n",
              "  'twitter',\n",
              "  'tonight',\n",
              "  'structural',\n",
              "  'spill',\n",
              "  'service',\n",
              "  'screamed',\n",
              "  'rescued',\n",
              "  'rescue',\n",
              "  'phone',\n",
              "  'ok',\n",
              "  'oh',\n",
              "  'mosque',\n",
              "  'lives',\n",
              "  'horrible',\n",
              "  'harm',\n",
              "  'game',\n",
              "  'dust',\n",
              "  'destruction',\n",
              "  'deluge',\n",
              "  'deaths',\n",
              "  'crashed',\n",
              "  'cliff',\n",
              "  'catastrophe',\n",
              "  'boat',\n",
              "  'away',\n",
              "  'august',\n",
              "  'area',\n",
              "  'apocalypse',\n",
              "  'woman',\n",
              "  'whirlwind',\n",
              "  'traumatised',\n",
              "  'stock',\n",
              "  'saw',\n",
              "  'ruin',\n",
              "  'riot',\n",
              "  'quarantine',\n",
              "  'kills',\n",
              "  'island',\n",
              "  'investigators',\n",
              "  'ill',\n",
              "  'hostages',\n",
              "  'hazard',\n",
              "  'danger',\n",
              "  'call',\n",
              "  '15',\n",
              "  'women',\n",
              "  'windstorm',\n",
              "  'things',\n",
              "  'suspect',\n",
              "  'show',\n",
              "  'reunion',\n",
              "  'quarantined',\n",
              "  'lava',\n",
              "  'heart',\n",
              "  'engulfed',\n",
              "  'detonate',\n",
              "  'crush',\n",
              "  'collapsed',\n",
              "  'came',\n",
              "  'better',\n",
              "  'battle',\n",
              "  'armageddon',\n",
              "  'airplane',\n",
              "  'against',\n",
              "  'affected',\n",
              "  'use',\n",
              "  'trapped',\n",
              "  'thank',\n",
              "  'sunk',\n",
              "  'story',\n",
              "  'send',\n",
              "  'part',\n",
              "  'other',\n",
              "  'must',\n",
              "  'mudslide',\n",
              "  'market',\n",
              "  'iran',\n",
              "  'famine',\n",
              "  'exploded',\n",
              "  'electrocuted',\n",
              "  'ebay',\n",
              "  'displaced',\n",
              "  'derailed',\n",
              "  'derail',\n",
              "  'burned',\n",
              "  'bombed',\n",
              "  'blown',\n",
              "  'baby',\n",
              "  'around',\n",
              "  'zone',\n",
              "  'wave',\n",
              "  'wanna',\n",
              "  'sure',\n",
              "  'someone',\n",
              "  'screams',\n",
              "  'razed',\n",
              "  'power',\n",
              "  'obliterated',\n",
              "  'long',\n",
              "  'land',\n",
              "  'hundreds',\n",
              "  'heard',\n",
              "  'group',\n",
              "  'flattened',\n",
              "  'drown',\n",
              "  'doing',\n",
              "  'care',\n",
              "  'bridge',\n",
              "  'bagging',\n",
              "  '9',\n",
              "  'went',\n",
              "  'used',\n",
              "  'typhoon',\n",
              "  'trouble',\n",
              "  'tornado',\n",
              "  'thought',\n",
              "  'thing',\n",
              "  'river',\n",
              "  'responders',\n",
              "  'past',\n",
              "  'pandemonium',\n",
              "  'officials',\n",
              "  'meltdown',\n",
              "  'lot',\n",
              "  'least',\n",
              "  'inundated',\n",
              "  'id',\n",
              "  'hostage',\n",
              "  'hijacking',\n",
              "  'hazardous',\n",
              "  'goes',\n",
              "  'drowning',\n",
              "  'didnt',\n",
              "  'devastation',\n",
              "  'demolish',\n",
              "  'collide',\n",
              "  'casualties',\n",
              "  'calgary',\n",
              "  'bang',\n",
              "  'anniversary',\n",
              "  'yet',\n",
              "  'wounds',\n",
              "  'volcano',\n",
              "  'tsunami',\n",
              "  'sue',\n",
              "  'st',\n",
              "  'song',\n",
              "  'something',\n",
              "  'shoulder',\n",
              "  'security',\n",
              "  'prebreak',\n",
              "  'possible',\n",
              "  'pkk',\n",
              "  'panicking',\n",
              "  'obliteration',\n",
              "  'obliterate',\n",
              "  'murderer',\n",
              "  'minute',\n",
              "  'light',\n",
              "  'lets',\n",
              "  'kill',\n",
              "  'isis',\n",
              "  'india',\n",
              "  'hijacker',\n",
              "  'hellfire',\n",
              "  'government',\n",
              "  'few',\n",
              "  'evacuated',\n",
              "  'due',\n",
              "  'detonated',\n",
              "  'desolation',\n",
              "  'crushed',\n",
              "  'chemical',\n",
              "  'blew',\n",
              "  'blazing',\n",
              "  'blast',\n",
              "  'annihilated',\n",
              "  'airport',\n",
              "  '6',\n",
              "  'week',\n",
              "  'upheaval',\n",
              "  'trying',\n",
              "  'three',\n",
              "  'thanks',\n",
              "  'sound',\n",
              "  'soon',\n",
              "  'sirens',\n",
              "  'rainstorm',\n",
              "  'plane',\n",
              "  'music',\n",
              "  'making',\n",
              "  'kids',\n",
              "  'issues',\n",
              "  'half',\n",
              "  'guys',\n",
              "  'fedex',\n",
              "  'done',\n",
              "  'died',\n",
              "  'detonation',\n",
              "  'days',\n",
              "  'cyclone',\n",
              "  'county',\n",
              "  'collision',\n",
              "  'caused',\n",
              "  'catastrophic',\n",
              "  'bleeding',\n",
              "  'beautiful',\n",
              "  '8',\n",
              "  'words',\n",
              "  'very',\n",
              "  'traffic',\n",
              "  'south',\n",
              "  'remember',\n",
              "  'policy',\n",
              "  'place',\n",
              "  'nothing',\n",
              "  'north',\n",
              "  'mp',\n",
              "  'longer',\n",
              "  'left',\n",
              "  'israeli',\n",
              "  'hell',\n",
              "  'fun',\n",
              "  'drowned',\n",
              "  'demolished',\n",
              "  'cool',\n",
              "  'both',\n",
              "  'bioterror',\n",
              "  'believe',\n",
              "  'avalanche',\n",
              "  'arson',\n",
              "  'turkey',\n",
              "  'snowstorm',\n",
              "  'site',\n",
              "  'shot',\n",
              "  'shooting',\n",
              "  'pic',\n",
              "  'nowplaying',\n",
              "  'media',\n",
              "  'islam',\n",
              "  'inside',\n",
              "  'hijack',\n",
              "  'helicopter',\n",
              "  'fight',\n",
              "  'fatality',\n",
              "  'fan',\n",
              "  'electrocute',\n",
              "  'doesnt',\n",
              "  'building',\n",
              "  'brown',\n",
              "  'bc',\n",
              "  'actually',\n",
              "  '16yr',\n",
              "  'yes',\n",
              "  'watching',\n",
              "  'wait',\n",
              "  'ur',\n",
              "  'tell',\n",
              "  'swallowed',\n",
              "  'seismic',\n",
              "  'second',\n",
              "  'rubble',\n",
              "  're\\x89Û',\n",
              "  'plans',\n",
              "  'men',\n",
              "  'memories',\n",
              "  'line',\n",
              "  'la',\n",
              "  'horror',\n",
              "  'health',\n",
              "  'having',\n",
              "  'find',\n",
              "  'eyewitness',\n",
              "  'deluged',\n",
              "  'children',\n",
              "  'bush',\n",
              "  'anything',\n",
              "  'already',\n",
              "  'almost',\n",
              "  'aircraft',\n",
              "  'yourself',\n",
              "  'yeah',\n",
              "  'whats',\n",
              "  'tomorrow',\n",
              "  'such',\n",
              "  'start',\n",
              "  'side',\n",
              "  'searching',\n",
              "  'saved',\n",
              "  'reactor',\n",
              "  'probably',\n",
              "  'play',\n",
              "  'person',\n",
              "  'peace',\n",
              "  'outside',\n",
              "  'officer',\n",
              "  'nearby',\n",
              "  'n',\n",
              "  'maybe',\n",
              "  'lost',\n",
              "  'literally',\n",
              "  'hours',\n",
              "  'hear',\n",
              "  'far',\n",
              "  'die',\n",
              "  'demolition',\n",
              "  'data',\n",
              "  'crews',\n",
              "  'conclusively',\n",
              "  'business',\n",
              "  'american',\n",
              "  '20',\n",
              "  '\\x89ÛÓ',\n",
              "  'west',\n",
              "  'waves',\n",
              "  'team',\n",
              "  'street',\n",
              "  'stay',\n",
              "  'soudelor',\n",
              "  'reuters',\n",
              "  'manslaughter',\n",
              "  'leather',\n",
              "  'job',\n",
              "  'history',\n",
              "  'hey',\n",
              "  'feeling',\n",
              "  'eyes',\n",
              "  'everything',\n",
              "  'declares',\n",
              "  'deal',\n",
              "  'casualty',\n",
              "  'bodies',\n",
              "  'amid',\n",
              "  'ablaze',\n",
              "  '7',\n",
              "  '50',\n",
              "  '30',\n",
              "  '12',\n",
              "  'youth',\n",
              "  'wont',\n",
              "  'wake',\n",
              "  'theyre',\n",
              "  'support',\n",
              "  'stretcher',\n",
              "  'same',\n",
              "  'rise',\n",
              "  'picking',\n",
              "  'photos',\n",
              "  'own',\n",
              "  'others',\n",
              "  'order',\n",
              "  'omg',\n",
              "  'okay',\n",
              "  'name',\n",
              "  'myself',\n",
              "  'money',\n",
              "  'makes',\n",
              "  'leave',\n",
              "  'lab',\n",
              "  'gt',\n",
              "  'gets',\n",
              "  'flag',\n",
              "  'desolate',\n",
              "  'crisis',\n",
              "  'center',\n",
              "  'book',\n",
              "  'blight',\n",
              "  'blaze',\n",
              "  'ago',\n",
              "  'abc',\n",
              "  '11yearold',\n",
              "  'womens',\n",
              "  'typhoondevastated',\n",
              "  'tv',\n",
              "  'trench',\n",
              "  'trains',\n",
              "  'texas',\n",
              "  'space',\n",
              "  'siren',\n",
              "  'shes',\n",
              "  'self',\n",
              "  'saipan',\n",
              "  'reason',\n",
              "  'rd',\n",
              "  'pretty',\n",
              "  'pick',\n",
              "  'offensive',\n",
              "  'move',\n",
              "  'meek',\n",
              "  'major',\n",
              "  'm',\n",
              "  'low',\n",
              "  'lord',\n",
              "  'huge',\n",
              "  'hat',\n",
              "  'flash',\n",
              "  'feared',\n",
              "  'fast',\n",
              "  'effect',\n",
              "  'course',\n",
              "  'country',\n",
              "  'control',\n",
              "  'class',\n",
              "  'child',\n",
              "  'chance',\n",
              "  'caught',\n",
              "  'called',\n",
              "  'bioterrorism',\n",
              "  'bestnaijamade',\n",
              "  'become',\n",
              "  'bar',\n",
              "  'banned',\n",
              "  'ball',\n",
              "  'aug',\n",
              "  'annihilation',\n",
              "  'wrong',\n",
              "  'win',\n",
              "  'usa',\n",
              "  'united',\n",
              "  'town',\n",
              "  'totally',\n",
              "  'toddler',\n",
              "  'though',\n",
              "  'temple',\n",
              "  'taken',\n",
              "  'stand',\n",
              "  'spot',\n",
              "  'signs',\n",
              "  'ship',\n",
              "  'pakistan',\n",
              "  'online',\n",
              "  'level',\n",
              "  'ladies',\n",
              "  'jobs',\n",
              "  'isnt',\n",
              "  'happy',\n",
              "  'hailstorm',\n",
              "  'friends',\n",
              "  'disea',\n",
              "  'damn',\n",
              "  'couple',\n",
              "  'case',\n",
              "  'blue',\n",
              "  'bigger',\n",
              "  'america',\n",
              "  'across',\n",
              "  '10',\n",
              "  'yours',\n",
              "  'village',\n",
              "  'try',\n",
              "  'transport',\n",
              "  'talk',\n",
              "  'seen',\n",
              "  'russian',\n",
              "  'radio',\n",
              "  'projected',\n",
              "  'once',\n",
              "  'official',\n",
              "  'needs',\n",
              "  'nearly',\n",
              "  'mount',\n",
              "  'might',\n",
              "  'mayhem',\n",
              "  'instead',\n",
              "  'hollywood',\n",
              "  'haha',\n",
              "  'guy',\n",
              "  'gun',\n",
              "  'green',\n",
              "  'front',\n",
              "  'finally',\n",
              "  'favorite',\n",
              "  'experts',\n",
              "  'entire',\n",
              "  'east',\n",
              "  'daily',\n",
              "  'crazy',\n",
              "  'computers',\n",
              "  'coaches',\n",
              "  'christian',\n",
              "  'china',\n",
              "  'blizzard',\n",
              "  'anyone',\n",
              "  'aint',\n",
              "  'action',\n",
              "  '25',\n",
              "  'virgin',\n",
              "  'vehicle',\n",
              "  'truth',\n",
              "  'trust',\n",
              "  'takes',\n",
              "  't',\n",
              "  'star',\n",
              "  'sorry',\n",
              "  'running',\n",
              "  'refugio',\n",
              "  'reddits',\n",
              "  'poor',\n",
              "  'pain',\n",
              "  'mom',\n",
              "  'miners',\n",
              "  'marks',\n",
              "  'looking',\n",
              "  'knock',\n",
              "  'issued',\n",
              "  'insurance',\n",
              "  'ignition',\n",
              "  'houses',\n",
              "  'heavy',\n",
              "  'hate',\n",
              "  'hard',\n",
              "  'happened',\n",
              "  'global',\n",
              "  'giant',\n",
              "  'gbbo',\n",
              "  'flight',\n",
              "  'eye',\n",
              "  'emmerdale',\n",
              "  'driver',\n",
              "  'devastated',\n",
              "  'd',\n",
              "  'costlier',\n",
              "  'cnn',\n",
              "  'cars',\n",
              "  'camp',\n",
              "  'beach',\n",
              "  'arsonist',\n",
              "  'angry',\n",
              "  'alone',\n",
              "  'added',\n",
              "  '05',\n",
              "  'york',\n",
              "  'wonder',\n",
              "  'uk',\n",
              "  'turn',\n",
              "  'taking',\n",
              "  'subreddits',\n",
              "  'sounds',\n",
              "  'scared',\n",
              "  'russia',\n",
              "  'rly',\n",
              "  'reports',\n",
              "  'ready',\n",
              "  'quiz',\n",
              "  'public',\n",
              "  'property',\n",
              "  'pradesh',\n",
              "  'ppl',\n",
              "  'playing',\n",
              "  'pay',\n",
              "  'parole',\n",
              "  'pamela',\n",
              "  'pakistani',\n",
              "  'outrage',\n",
              "  'niggas',\n",
              "  'nagasaki',\n",
              "  'myanmar',\n",
              "  'muslims',\n",
              "  'mop',\n",
              "  'madhya',\n",
              "  'mad',\n",
              "  'lmao',\n",
              "  'learn',\n",
              "  'large',\n",
              "  'govt',\n",
              "  'give',\n",
              "  'gems',\n",
              "  'gave',\n",
              "  'funtenna',\n",
              "  'fukushima',\n",
              "  'former',\n",
              "  'film',\n",
              "  'earth',\n",
              "  'drive',\n",
              "  'downtown',\n",
              "  'dog',\n",
              "  'comes',\n",
              "  'closed',\n",
              "  'cake',\n",
              "  'british',\n",
              "  'bring',\n",
              "  'bbc',\n",
              "  'b',\n",
              "  'appears',\n",
              "  'aftershock',\n",
              "  '13',\n",
              "  '11',\n",
              "  'young',\n",
              "  'wow',\n",
              "  'worst',\n",
              "  'waving',\n",
              "  'washington',\n",
              "  'wanted',\n",
              "  'vs',\n",
              "  'view',\n",
              "  'upon',\n",
              "  'tweet',\n",
              "  'tree',\n",
              "  'tote',\n",
              "  'thousands',\n",
              "  'thinking',\n",
              "  'theater',\n",
              "  'soul',\n",
              "  'sky',\n",
              "  'sign',\n",
              "  'shows',\n",
              "  'shift',\n",
              "  'seeing',\n",
              "  'sea',\n",
              "  'scene',\n",
              "  'safety',\n",
              "  'rules',\n",
              "  'rock',\n",
              "  'reported',\n",
              "  'r',\n",
              "  'pray',\n",
              "  'playlist',\n",
              "  'patience',\n",
              "  ...],\n",
              " ['', '[UNK]', 'the', 'a', 'in'],\n",
              " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an embedding using an embedding layer\n",
        "\n",
        "To make our embedding, we're going to use the TF's embedding layer.\n",
        "\n",
        "The parameters we care the most about our embedding layers are:\n",
        "* input_dim= sie of our vocab\n",
        "* output_dim= size of the output embedding vector. A value of a 100 will mean that each token will be represented as a vector of 100 long length\n",
        "* input_length= length of sequences being passed to the embedding layer\n",
        "*"
      ],
      "metadata": {
        "id": "UscIzRK9b6M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "05ZNG325d5QR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding=layers.Embedding(input_dim=max_vocab_length,\n",
        "                           output_dim=128,\n",
        "                           input_length=max_length)"
      ],
      "metadata": {
        "id": "sQrtz6UzEDid"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFptstOWEVJj",
        "outputId": "98f7059f-ebf1-4cf2-bf8a-5c26062d3094"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f55bee4d390>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a random sentence from the training set\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"Original Sentence:{random_sentence}\\\n",
        "      \\nEmbedded Sentence\")\n",
        "\n",
        "sample_embedding=embedding(text_vectorizer([random_sentence]))\n",
        "sample_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0XRCbb8EYo0",
        "outputId": "8c695740-90e8-405f-9161-de5164125481"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence:Bluedio Turbine Hurricane H Bluetooth 4.1 Wireless Stereo Headphones Headset BLK - Full reÛ_ http://t.co/WeUDLkc4o4 http://t.co/trl1dskF81      \n",
            "Embedded Sentence\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-7.5580850e-03, -3.3151068e-02, -6.4847842e-03, ...,\n",
              "         -2.3289109e-02,  2.7769897e-02,  2.0428982e-02],\n",
              "        [ 4.3598786e-03,  3.6121372e-02,  1.1861347e-02, ...,\n",
              "         -4.4446230e-02, -6.2571391e-03,  9.9399686e-03],\n",
              "        [-6.2232129e-03,  3.4715068e-02, -2.7298704e-03, ...,\n",
              "          2.1669362e-02,  3.4684684e-02, -4.7717154e-02],\n",
              "        ...,\n",
              "        [-2.1747053e-02, -3.4965575e-05, -8.9477524e-03, ...,\n",
              "          3.2201890e-02,  2.7319375e-02, -1.3037540e-02],\n",
              "        [-2.0786524e-02,  2.1357086e-02, -4.0223885e-02, ...,\n",
              "          4.5343880e-02,  4.1947354e-02, -4.4432949e-02],\n",
              "        [-2.0786524e-02,  2.1357086e-02, -4.0223885e-02, ...,\n",
              "          4.5343880e-02,  4.1947354e-02, -4.4432949e-02]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check out a single token's embedding\n",
        "sample_embedding[0][0], sample_embedding[0][0].shape, random_sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12ur4eOWE9w1",
        "outputId": "d012159d-97b5-4f5d-b6c0-892b1a719679"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-7.55808502e-03, -3.31510678e-02, -6.48478419e-03, -5.96556813e-03,\n",
              "        -3.59295122e-02, -2.78921966e-02,  7.63517618e-03, -1.99476127e-02,\n",
              "         3.10974009e-02, -1.67658180e-03, -1.31419525e-02,  1.97634958e-02,\n",
              "        -3.29667106e-02,  4.74361815e-02,  4.29836661e-03, -2.26278231e-03,\n",
              "         1.71732418e-02, -1.21700987e-02,  2.98037641e-02,  1.06105208e-02,\n",
              "         4.30832766e-02, -4.70493808e-02,  1.43727921e-02, -1.00178607e-02,\n",
              "         3.76285203e-02,  3.69115956e-02,  2.47030519e-02,  3.52167152e-02,\n",
              "         7.50090927e-03, -1.68534294e-02,  2.34817341e-03, -3.07986494e-02,\n",
              "         3.58474739e-02,  7.69631937e-03, -3.37794647e-02,  4.98376377e-02,\n",
              "         3.87169458e-02,  4.51937057e-02, -2.01298837e-02,  1.92135014e-02,\n",
              "         2.14891545e-02, -1.61392465e-02,  2.29170211e-02, -3.83401886e-02,\n",
              "        -2.57441532e-02, -2.90279035e-02, -1.24157891e-02, -3.99810560e-02,\n",
              "        -3.24310437e-02,  2.79830955e-02,  4.58849408e-02, -3.89314182e-02,\n",
              "        -2.91255359e-02,  4.21068817e-03, -3.45511548e-02,  1.87765472e-02,\n",
              "         8.26307386e-03, -3.30995470e-02,  1.03395581e-02,  6.28592819e-03,\n",
              "         4.76116873e-02, -4.86491323e-02,  4.48515266e-03, -2.68196948e-02,\n",
              "        -2.93994192e-02, -1.19955316e-02,  3.66103761e-02,  2.56736018e-02,\n",
              "        -4.23168205e-02, -2.50830650e-02,  4.96247075e-02, -4.65095155e-02,\n",
              "         2.90241502e-02,  3.86207812e-02, -3.87364514e-02, -4.95885015e-02,\n",
              "        -4.50912118e-02,  2.42863931e-02,  3.68593000e-02, -3.84376049e-02,\n",
              "        -8.17376375e-03, -6.72572851e-03,  3.39299478e-02, -2.66119596e-02,\n",
              "        -1.51821375e-02, -6.75083324e-03, -2.53421068e-03, -1.81883574e-02,\n",
              "         4.89077233e-02, -3.22861224e-02,  2.27443129e-03, -1.09259710e-02,\n",
              "        -2.07941178e-02,  1.70953572e-05, -1.33235939e-02, -2.85458695e-02,\n",
              "         3.27451937e-02, -4.96531650e-03, -2.51810439e-02, -2.53539085e-02,\n",
              "         1.56463645e-02,  4.18351963e-03, -1.50087103e-02,  2.56398655e-02,\n",
              "        -1.64785609e-02, -3.26296836e-02,  4.13622148e-02,  3.99974622e-02,\n",
              "         1.25638358e-02, -4.81392741e-02,  4.64511625e-02, -2.43752245e-02,\n",
              "         4.99555804e-02, -4.23900038e-03,  2.77002715e-02, -2.63986122e-02,\n",
              "         4.28654291e-02,  1.14664659e-02, -8.95433500e-03, -1.21489875e-02,\n",
              "         2.48062126e-02,  4.40561660e-02,  1.10959895e-02,  4.37200069e-03,\n",
              "         4.45387401e-02, -2.32891086e-02,  2.77698971e-02,  2.04289816e-02],\n",
              "       dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'B')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelling a text dataset(running a series of experiments)\n",
        "\n",
        "* Model 0: Naive Bayes with Tokenization\n",
        "* Model 1: Feed-forward Neural Network(Dense Model)\n",
        "* Model 2: LSTM Model(RNN)\n",
        "* Model 3: GRU Model\n",
        "* Moel 4: Bidirectional LSTM\n",
        "* Model 5 : 1D Convolutional Layer\n",
        "* model 6: Tensorflow hub pretrained feature extraction (using transfer learning)\n",
        "* Model 7 : Same as model 6 with 10% of data\n",
        "\n",
        "How are we going to approach all of these:\n",
        "Use the standard steps in modelling with tensorflow\n",
        "\n",
        "* Create->build->fit->Evaluate\n",
        "\n"
      ],
      "metadata": {
        "id": "FhiG7RYnF6Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0\n",
        "\n",
        "To create a baseline, we'll use sklearn's Naive Bayes using Tf-IDF to convert our words to numbers\n",
        "\n",
        "It is a good practice to use non-DL Algos as a baseline because of their speed and then later use DL to see if you can improve upon them"
      ],
      "metadata": {
        "id": "aXUkwxQcI759"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "SgYwLWoxZ-rB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0=Pipeline([\n",
        "    (\"tfidf\",TfidfVectorizer()),\n",
        "    (\"clf\",MultinomialNB())\n",
        "])\n",
        "\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "c2zhqUaGZ_un",
        "outputId": "910433c9-e691-49e4-85a3-87710807d839"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the baseline Model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"our baseline model achieves an accuracy of : {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqpo7Zw4cuEp",
        "outputId": "8cb6d06e-3365-4075-faa7-1e81ab07c8ad"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "our baseline model achieves an accuracy of : 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK5L1LTydGik",
        "outputId": "3234106a-264a-4ccf-c9c5-e66cd42a2013"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method IndexOpsMixin.value_counts of 0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "7608    1\n",
              "7609    1\n",
              "7610    1\n",
              "7611    1\n",
              "7612    1\n",
              "Name: target, Length: 7613, dtype: int64>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions\n",
        "baseline_preds= model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSf0XjLidIru",
        "outputId": "83b0ea42-0a32-46c6-c06d-feccb731e967"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an evaluation function for our model experiments"
      ],
      "metadata": {
        "id": "f7C2BDI1dUx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could evaluate all of our model's predictions with different metrics every time.\n",
        "Calculate:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1 score\n"
      ],
      "metadata": {
        "id": "fsfPdfPdeBYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to evaluate the above metrics\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculated model accuracy, precision, recall and f1 score of a binary classification model\n",
        "  \"\"\"\n",
        "  #Calculate model accuracy\n",
        "  model_accuracy=accuracy_score(y_true, y_pred) * 100\n",
        "  #Calculate model precision, recall and f1 score using the\"weighted average\"\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred,average=\"weighted\" )\n",
        "  model_results={'accuracy':model_accuracy,\n",
        "                 'precision': model_precision,\n",
        "                 'recall': model_recall,\n",
        "                 'f1-score':model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "w3KO2bNCeH9x"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get baseline results\n",
        "baseline_results=calculate_results(y_true=val_labels,\n",
        "                                   y_pred=baseline_preds)"
      ],
      "metadata": {
        "id": "ZRhBrZUceYKk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results['accuracy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5u_ypVpggRH",
        "outputId": "1c2eba6f-83a6-47b9-8634-bd58c73575ff"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79.26509186351706"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgSLKFUigjOp",
        "outputId": "3ae22c4a-8c40-4925-a506-01cd464c0e3a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: A simple Dense Model"
      ],
      "metadata": {
        "id": "GkA8wqsZgkFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensorflow callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "#Create a directory to save tensorboard logs\n",
        "SAVE_DIR=\"model_logs\"\n"
      ],
      "metadata": {
        "id": "4UMvTAO0lRnx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build model with functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs=layers.Input(shape=(1,), dtype=tf.string) #Inputs are 1 dimensional\n",
        "x= text_vectorizer(inputs) #Turn the input text into numbers\n",
        "x= embedding(x) #Create an embedding of vctorized embeddings\n",
        "x=layers.GlobalAveragePooling1D()(x)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_1=tf.keras.Model(inputs, outputs, name=\"Model_1_dense\")"
      ],
      "metadata": {
        "id": "v-YXqNhHlXFp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGntW8rbmRG_",
        "outputId": "cfd54525-6726-4500-a051-73a83655bc56"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile model\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AtH4W9MamYbc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_history=model_1.fit(x=train_sentences,\n",
        "                            y=train_labels,\n",
        "                            epochs=5,\n",
        "                            validation_data=(val_sentences,val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                   experiment_name=\"model_1_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG4M-QjhnJEQ",
        "outputId": "239b3289-096d-417e-9a97-4701739e7ede"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20230617-041938\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 33s 138ms/step - loss: 0.6119 - accuracy: 0.6887 - val_loss: 0.5345 - val_accuracy: 0.7625\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.4434 - accuracy: 0.8183 - val_loss: 0.4725 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3491 - accuracy: 0.8591 - val_loss: 0.4584 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.2859 - accuracy: 0.8892 - val_loss: 0.4625 - val_accuracy: 0.7848\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.2393 - accuracy: 0.9121 - val_loss: 0.4866 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWArT8vcnekL",
        "outputId": "96045bfd-d291-4158-c9b3-0f6096170e94"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4866436719894409, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_pred_probs=model_1.predict(val_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QoASaI1nn5Y",
        "outputId": "6f68ec23-e5df-4326-9727-aafaa3788c70"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_pred_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYMwZRAMntde",
        "outputId": "2f944bc0-6cec-469b-f0f3-c18fc52ecca3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate_results(val_labels, model_1_pred_probs)"
      ],
      "metadata": {
        "id": "x3zF16Kjon-Y"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DefvW6HlpEhM",
        "outputId": "a0653edd-8c01-4492-debc-bcc50c2c0604"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Model_prediction Probabs into label formats\n",
        "model_1_preds=tf.squeeze(tf.round(model_1_pred_probs))"
      ],
      "metadata": {
        "id": "Siu3N9yupHrE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5_rn_dtpMSZ",
        "outputId": "33116ac9-293e-458b-dadf-7d5ada005fd3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results=calculate_results(y_true=val_labels,\n",
        "                                  y_pred=model_1_preds)"
      ],
      "metadata": {
        "id": "e4LzOiRYqp97"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbsaMJeNq0-H",
        "outputId": "b71a9039-d042-4e41-d7c3-7e18460a5bca"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'precision': 0.7952890169870324,\n",
              " 'recall': 0.7874015748031497,\n",
              " 'f1-score': 0.7834758226606451}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS3Y8aGrq2r3",
        "outputId": "6831155b-9d00-423d-e04c-e6238165ee5c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values()))> np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pSLUJ6Zq4a8",
        "outputId": "ccbc6ad4-bb75-497e-ae06-e669baa2ff08"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the learned embeddings\n"
      ],
      "metadata": {
        "id": "xYmbF71CrAkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()"
      ],
      "metadata": {
        "id": "3jyHcUrWtyhI"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "id": "DjOpoiLUt4T3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85159ae-b6a1-4041-f2f0-6266d3516b03"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "3iZQmS3ouAsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3dada2-5b7b-4b42-c4b9-1ea99e7df708"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the weight matrix of the embedding layers\n",
        "#These are numerical representation of our numerical datawhich are trained for 5 epochs\n",
        "\n",
        "embed_weights=model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights"
      ],
      "metadata": {
        "id": "cY5xpTiVuHbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd92587-5def-40d0-9886-e8aef006251a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04639365, -0.00425685, -0.0058459 , ...,  0.01861798,\n",
              "        -0.00898123, -0.02822156],\n",
              "       [-0.00832366,  0.03336032, -0.03449535, ...,  0.03449606,\n",
              "         0.03056703, -0.05740191],\n",
              "       [-0.01224537, -0.02599777, -0.01307229, ..., -0.04689934,\n",
              "        -0.02821775, -0.0225463 ],\n",
              "       ...,\n",
              "       [-0.02350407,  0.00194113, -0.01120711, ..., -0.02893713,\n",
              "         0.04752084, -0.03119372],\n",
              "       [ 0.01748386, -0.00923529,  0.01836829, ..., -0.06523332,\n",
              "        -0.07976959, -0.01253115],\n",
              "       [ 0.04014959,  0.06424671,  0.05911784, ..., -0.10467663,\n",
              "        -0.06407124, -0.0478763 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed_weights.shape)"
      ],
      "metadata": {
        "id": "_IDMc9ssuec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4b440e-fc88-4de7-ae6a-0060ff9b75ce"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got the embedding matrix our model has learned to represent tokens, let's see how we can visualize it\n",
        "\n",
        "To do so, tensorflow has a tool called Projector"
      ],
      "metadata": {
        "id": "lxSNxbJPusKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "import io\n",
        "\n",
        "# Create output writers\n",
        "out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# Write embedding vectors and words to file\n",
        "for num, word in enumerate(words_in_vocab):\n",
        "  if num == 0:\n",
        "     continue # skip padding token\n",
        "  vec = embed_weights[num]\n",
        "  out_m.write(word + \"\\n\") # write words to file\n",
        "  out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "AWIx-3ehvLck"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files locally to upload to Embedding Projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(\"embedding_vectors.tsv\")\n",
        "  files.download(\"embedding_metadata.tsv\")"
      ],
      "metadata": {
        "id": "5RPlhbYAwOBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f12e6cc1-57c8-417a-a860-6c8e02f62d49"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cad6186b-fad8-42ba-858b-8479c5e45a43\", \"embedding_vectors.tsv\", 15384187)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dce57cb3-b103-4bac-878f-58c7fb7571aa\", \"embedding_metadata.tsv\", 80388)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks(RNNs)\n",
        "\n",
        "the premise of the Recurrent Neural Networs is to use the representation of the previous input to aid the representation of the later input\n",
        "\n",
        "RNNs are used for sequence data (this example is a sequence of text)"
      ],
      "metadata": {
        "id": "CrZT_hGHyOfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 📖 Resources:\n",
        "\n",
        "MIT Deep Learning Lecture on Recurrent Neural Networks - explains the background of recurrent neural networks and introduces LSTMs.\n",
        "The Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences.\n",
        "Understanding LSTMs by Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block."
      ],
      "metadata": {
        "id": "K_J8CWsiCbyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM= long short term memory\n",
        "\n",
        "Our structure of an RNN Looks like this\n",
        "\n",
        "Input(text)-> Tokenize -> Embedding -> Layers(RNNs/Dense)->output(label probability)"
      ],
      "metadata": {
        "id": "JIpS5KdMDdhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an LSTM Model\n",
        "from tensorflow.keras import layers\n",
        "inputs= layers.Input(shape=(1,), dtype=tf.string)\n",
        "x=text_vectorizer(inputs)\n",
        "x= embedding(x)\n",
        "print(x.shape)\n",
        "x=layers.LSTM(64, return_sequences=True)(x) #64 is hidden units\n",
        "#When you a stacking RNN Cells together, you need to return sequences=true\n",
        "print(x.shape)\n",
        "x= layers.LSTM(64)(x)\n",
        "print(x.shape)\n",
        "x= layers.Dense(64, activation='relu')(x)\n",
        "print(x.shape)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_2= tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n"
      ],
      "metadata": {
        "id": "hA922aKJASoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1b0c9f-8f8c-4112-9ec8-5c38180a0409"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 64)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an LSTM Model\n",
        "from tensorflow.keras import layers\n",
        "inputs= layers.Input(shape=(1,), dtype=tf.string)\n",
        "x=text_vectorizer(inputs)\n",
        "x= embedding(x)\n",
        "#print(x.shape)\n",
        "#x=layers.LSTM(64, return_sequences=True)(x) #64 is hidden units\n",
        "#When you a stacking RNN Cells together, you need to return sequences=true\n",
        "#print(x.shape)\n",
        "x= layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "#x= layers.Dense(64, activation='relu')(x)\n",
        "#print(x.shape)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_2= tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n"
      ],
      "metadata": {
        "id": "7nHB-E4PBuQU"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "id": "FzlIZIY8Dm7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9190b70f-5ee2-4ae5-e3d0-ca9d30c8ec3a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The default activation function for RNNs is TanH"
      ],
      "metadata": {
        "id": "QxsN2GykDo_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complie the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rf9WWNf9D1xh"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_2_LSTM=model_2.fit(train_sentences,\n",
        "                                 train_labels,\n",
        "                                 epochs=5,\n",
        "                                 validation_data=(val_sentences, val_labels),\n",
        "                                 callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                        experiment_name=\"model_2_LSTM\")])"
      ],
      "metadata": {
        "id": "qfH-KOfKEI_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb8471b-2593-42cc-fb5e-3366c4d018eb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230617-042104\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 24s 71ms/step - loss: 0.2241 - accuracy: 0.9212 - val_loss: 0.5227 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.1579 - accuracy: 0.9423 - val_loss: 0.5741 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.1292 - accuracy: 0.9505 - val_loss: 0.6151 - val_accuracy: 0.7782\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1057 - accuracy: 0.9603 - val_loss: 0.8725 - val_accuracy: 0.7808\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0840 - accuracy: 0.9656 - val_loss: 0.9455 - val_accuracy: 0.7743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_pred_probs=model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "id": "n5qVJNf2EY7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea0e953-9550-4329-b937-228a04ed253b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9279160e-02],\n",
              "       [9.3277431e-01],\n",
              "       [9.9986005e-01],\n",
              "       [5.4312073e-02],\n",
              "       [6.0018071e-04],\n",
              "       [9.9944550e-01],\n",
              "       [8.5512459e-01],\n",
              "       [9.9989760e-01],\n",
              "       [9.9984968e-01],\n",
              "       [7.0770234e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the probabs to pred\n",
        "model_2_preds=tf.squeeze(tf.round(model_2_pred_probs))"
      ],
      "metadata": {
        "id": "ZSymwXH5EjXO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_preds\n"
      ],
      "metadata": {
        "id": "xfA-YNydEuin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588e5223-f397-44a7-98aa-b291c9819aca"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results=calculate_results(y_true=val_labels,\n",
        "                                  y_pred=model_2_preds)"
      ],
      "metadata": {
        "id": "F4Nt6h5PEwPr"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "kRUgB8tnE2Wz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5435b9c3-20fe-4be2-9016-7a7c7c15692c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'precision': 0.7759894665484696,\n",
              " 'recall': 0.7742782152230971,\n",
              " 'f1-score': 0.7722311836526509}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results\n"
      ],
      "metadata": {
        "id": "_y-bd5d6E3Mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153a1cd0-4f50-4e4b-f823-88f8978b874b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Similar to LSTM but has less params"
      ],
      "metadata": {
        "id": "UXF740ofE4nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs= tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "\n",
        "x=embedding(x)\n",
        "\n",
        "x = tf.keras.layers.GRU(64, return_sequences=True)(x) #if you want to stack recurrent layers on top of each other, you need to use return_sequences=True\n",
        "x=layers.LSTM(64, return_sequences=True)(x)\n",
        "x=layers.GRU(64)(x)\n",
        "\n",
        "x=layers.Dense(64, activation='relu')(x)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3=tf.keras.Model(inputs, outputs, name=\"Model_3_GRU\")\n"
      ],
      "metadata": {
        "id": "co1zgceRGAbg"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs= tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "\n",
        "x=embedding(x)\n",
        "\n",
        "x = tf.keras.layers.GRU(64)(x) #if you want to stack recurrent layers on top of each other, you need to use return_sequences=True\n",
        "#x=layers.LSTM(64, return_sequences=True)(x)\n",
        "#x=layers.GRU(64)(x)\n",
        "\n",
        "x=layers.Dense(64, activation='relu')(x)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3=tf.keras.Model(inputs, outputs, name=\"Model_3_GRU\")\n"
      ],
      "metadata": {
        "id": "DY1pSYYhIGWy"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "id": "4KKTktRsHIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe154b9-a61c-4be3-db40-6de6b0b05e12"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,473\n",
            "Trainable params: 1,321,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "j-bjh1F5HkL7"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_3_GRU=model_3.fit(train_sentences,\n",
        "                                train_labels,\n",
        "                                validation_data=(val_sentences, val_labels),\n",
        "                                epochs=5,\n",
        "                                callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                      experiment_name='model_name_GRU')])"
      ],
      "metadata": {
        "id": "xCnE4GUYIBBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc0388a-eae7-416c-9e42-d075a8661f4e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_name_GRU/20230617-042141\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 16s 60ms/step - loss: 0.1736 - accuracy: 0.9291 - val_loss: 0.7101 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0818 - accuracy: 0.9682 - val_loss: 0.8873 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0659 - accuracy: 0.9717 - val_loss: 1.2823 - val_accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0568 - accuracy: 0.9764 - val_loss: 1.3370 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0506 - accuracy: 0.9766 - val_loss: 1.5760 - val_accuracy: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_pred_probs=model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "metadata": {
        "id": "2bOgGL-qJHvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2d717c-656f-4258-cc7e-eb93f87aecd8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3250248e-04],\n",
              "       [8.2421100e-01],\n",
              "       [9.9997103e-01],\n",
              "       [2.7224673e-02],\n",
              "       [2.9768021e-06],\n",
              "       [9.9931490e-01],\n",
              "       [6.1515782e-02],\n",
              "       [9.9998903e-01],\n",
              "       [9.9996090e-01],\n",
              "       [4.0234429e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_preds=tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_pNU9DZMcnG",
        "outputId": "7c94bfc0-41ae-49ac-ff35-174110f3ad2d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results=calculate_results(y_true=val_labels,\n",
        "                  y_pred=model_3_preds)"
      ],
      "metadata": {
        "id": "dYGuZrfxMnza"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYltXXH5MuZe",
        "outputId": "aec1685e-17b7-4a2d-f17d-499cf8106774"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model_4 : Bidirectional LSTM\n",
        "\n",
        "Normal RNNs go from left to right..\n",
        "Bidirectional RNNs go from left to right as well as right to left\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "45Q_Fz5nMwZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs=layers.Input(shape=(1,), dtype=tf.string)\n",
        "x= text_vectorizer(inputs)\n",
        "\n",
        "x= embedding(x)\n",
        "\n",
        "x=layers.Bidirectional(layers.LSTM(64))(x)\n",
        "#print(x.shape) #Doubles the value of the shape...as the cell is bidirectional\n",
        "#x=layers.Bidirectional(layers.GRU(64))(x)\n",
        "\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_4=tf.keras.Model(inputs, outputs, name='model_4_bidirectional')"
      ],
      "metadata": {
        "id": "yExqxgfRP-sq"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df9ldRCqR3to",
        "outputId": "c7c7cb94-8bc5-4893-f63e-5ba5da6c2b63"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss='binary_crossentropy',\n",
        "                metrics=['accuracy'],\n",
        "                optimizer=tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "eo_029tXSGlh"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_4_bidirectional=model_4.fit(train_sentences,\n",
        "                                    train_labels,\n",
        "                                    validation_data=(val_sentences, val_labels),\n",
        "                                    epochs=5,\n",
        "                                    callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                           experiment_name='model_4_bidirectional')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv1JVDxMS-Bd",
        "outputId": "0c7ec0a5-2c2a-4828-e068-c7d85f4873e3"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20230617-042225\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 20s 69ms/step - loss: 0.1098 - accuracy: 0.9656 - val_loss: 1.0226 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0521 - accuracy: 0.9772 - val_loss: 1.0867 - val_accuracy: 0.7717\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0448 - accuracy: 0.9790 - val_loss: 1.2189 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0450 - accuracy: 0.9799 - val_loss: 1.2579 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0402 - accuracy: 0.9806 - val_loss: 1.4292 - val_accuracy: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_pred_probs=model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnbBSNVWTRI_",
        "outputId": "1b3f0cfc-4c20-4482-e1c6-8031b40065ab"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2142494e-01],\n",
              "       [6.5166271e-01],\n",
              "       [9.9999189e-01],\n",
              "       [2.5688884e-01],\n",
              "       [5.3289965e-05],\n",
              "       [9.9987614e-01],\n",
              "       [6.8735951e-01],\n",
              "       [9.9999595e-01],\n",
              "       [9.9999309e-01],\n",
              "       [9.9806184e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_preds=tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W5brRHbTmU1",
        "outputId": "7ba537e2-10b5-47b9-e36a-177fd370761d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results=calculate_results(y_true=val_labels,\n",
        "                y_pred=model_4_preds)"
      ],
      "metadata": {
        "id": "05u_VmVITt6m"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja-R9v37T7eS",
        "outputId": "f586ee20-33a6-4097-f7c6-b8235b2eb65b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'precision': 0.7794151013007613,\n",
              " 'recall': 0.7782152230971129,\n",
              " 'f1-score': 0.7765058443845926}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgK46Tz_Tx7P",
        "outputId": "abbb3ec0-8d41-4502-92c3-f3150a9b6cfd"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks for text and other types of sequences\n",
        "\n",
        "We've used CNN for images bit typically images are 2D(HxW)...however the text data is 1D\n",
        "\n",
        "previously we used Conv2D for our image data...but now we will use conv1d\n",
        "\n",
        "Typical structure of Conv1D model for sequences :\n",
        "\n",
        "Inputs(text)-> tokenization-> embedding-> layers(Conv1D)->Pooling-> Output(class Probabs)"
      ],
      "metadata": {
        "id": "KioDZiajT8gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Conv1D"
      ],
      "metadata": {
        "id": "pN65cQneVa7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_test=embedding(text_vectorizer([\"THis is a test sentence\"]))\n",
        "conv1d= layers.Conv1D(filters=32,\n",
        "                      kernel_size=5,\n",
        "                      activation='relu',\n",
        "                      padding='valid') #Default=valid, the outpus is smaller than the 'same' shape than the input\n",
        "\n",
        "conv_1d_output=conv1d(embedding_test)\n",
        "max_pool=layers.GlobalMaxPool1D()\n",
        "max_pool_output=max_pool(conv_1d_output) #Get the mot imporetant features...get the feature with hightest value\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-3K2iKzWKav",
        "outputId": "b3d0d12b-92d9-4e1b-fc10-670052bb9ef1"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Where is the 11 coming from. THis is because we are using padding as valid and kernel size as 5"
      ],
      "metadata": {
        "id": "o9iVMctHXWIn"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD983IgpYCN5",
        "outputId": "64a8dab2-5424-49a5-ba8d-e83ff546fedb"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.03222757,  0.02307181, -0.01385835, ...,  0.01608749,\n",
              "         -0.03466342, -0.05507896],\n",
              "        [ 0.00948064,  0.02890947, -0.0157517 , ...,  0.01041117,\n",
              "          0.04778346, -0.04333053],\n",
              "        [ 0.01150913,  0.04150007,  0.0030097 , ...,  0.01878862,\n",
              "         -0.03257723, -0.05333283],\n",
              "        ...,\n",
              "        [ 0.01600279, -0.00266789,  0.0018959 , ...,  0.02919514,\n",
              "         -0.0020319 , -0.01676903],\n",
              "        [ 0.01600279, -0.00266789,  0.0018959 , ...,  0.02919514,\n",
              "         -0.0020319 , -0.01676903],\n",
              "        [ 0.01600279, -0.00266789,  0.0018959 , ...,  0.02919514,\n",
              "         -0.0020319 , -0.01676903]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_1d_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ium20hlVZdHi",
        "outputId": "044ba3d3-2bae-4c2d-e736-a5605f096645"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              "array([[[0.        , 0.        , 0.        , 0.        , 0.08637103,\n",
              "         0.06598052, 0.03108212, 0.        , 0.06123593, 0.05022851,\n",
              "         0.00388112, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01553611, 0.05085507, 0.03817522, 0.        , 0.        ,\n",
              "         0.        , 0.04697706, 0.02625585, 0.02888207, 0.0948526 ,\n",
              "         0.        , 0.0543611 , 0.        , 0.04842124, 0.01253425,\n",
              "         0.        , 0.        ],\n",
              "        [0.04182441, 0.04007557, 0.0132966 , 0.03003826, 0.        ,\n",
              "         0.03016315, 0.        , 0.        , 0.01618664, 0.0091231 ,\n",
              "         0.        , 0.08178469, 0.        , 0.052497  , 0.04473214,\n",
              "         0.        , 0.        , 0.0572531 , 0.        , 0.        ,\n",
              "         0.        , 0.05269448, 0.01056402, 0.        , 0.        ,\n",
              "         0.        , 0.00928992, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.01166761, 0.        , 0.03375591, 0.        , 0.02394951,\n",
              "         0.04752542, 0.        , 0.0340161 , 0.        , 0.        ,\n",
              "         0.01111539, 0.01789488, 0.00420705, 0.        , 0.02443718,\n",
              "         0.        , 0.        , 0.03273496, 0.        , 0.        ,\n",
              "         0.03470616, 0.01488666, 0.        , 0.        , 0.04316603,\n",
              "         0.        , 0.0691933 , 0.0052118 , 0.00776436, 0.        ,\n",
              "         0.        , 0.0424952 ],\n",
              "        [0.03891216, 0.        , 0.        , 0.        , 0.00467325,\n",
              "         0.04695689, 0.01280552, 0.00112795, 0.01189512, 0.        ,\n",
              "         0.        , 0.01625172, 0.        , 0.06425364, 0.        ,\n",
              "         0.        , 0.0085236 , 0.0642417 , 0.        , 0.02875374,\n",
              "         0.01049674, 0.05491918, 0.        , 0.        , 0.08116912,\n",
              "         0.        , 0.        , 0.        , 0.04510795, 0.        ,\n",
              "         0.        , 0.00172995],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.00982937, 0.        , 0.        , 0.        , 0.00171054,\n",
              "         0.        , 0.07687575, 0.        , 0.00681994, 0.        ,\n",
              "         0.        , 0.        , 0.03129989, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.01738748, 0.01002972, 0.        ,\n",
              "         0.        , 0.03060191, 0.        , 0.        , 0.01004485,\n",
              "         0.        , 0.03071981],\n",
              "        [0.00781168, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.04748577, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.04026726, 0.        , 0.01750668, 0.        ,\n",
              "         0.        , 0.        , 0.05196531, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.02429274,\n",
              "         0.        , 0.00422711, 0.        , 0.00114944, 0.        ,\n",
              "         0.        , 0.01393152],\n",
              "        [0.00781168, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.04748577, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.04026726, 0.        , 0.01750668, 0.        ,\n",
              "         0.        , 0.        , 0.05196531, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.02429274,\n",
              "         0.        , 0.00422711, 0.        , 0.00114944, 0.        ,\n",
              "         0.        , 0.01393152],\n",
              "        [0.00781168, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.04748577, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.04026726, 0.        , 0.01750668, 0.        ,\n",
              "         0.        , 0.        , 0.05196531, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.02429274,\n",
              "         0.        , 0.00422711, 0.        , 0.00114944, 0.        ,\n",
              "         0.        , 0.01393152],\n",
              "        [0.00781168, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.04748577, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.04026726, 0.        , 0.01750668, 0.        ,\n",
              "         0.        , 0.        , 0.05196531, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.02429274,\n",
              "         0.        , 0.00422711, 0.        , 0.00114944, 0.        ,\n",
              "         0.        , 0.01393152],\n",
              "        [0.00781168, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.04748577, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.04026726, 0.        , 0.01750668, 0.        ,\n",
              "         0.        , 0.        , 0.05196531, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.02429274,\n",
              "         0.        , 0.00422711, 0.        , 0.00114944, 0.        ,\n",
              "         0.        , 0.01393152],\n",
              "        [0.00781168, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.04748577, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.04026726, 0.        , 0.01750668, 0.        ,\n",
              "         0.        , 0.        , 0.05196531, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.02429274,\n",
              "         0.        , 0.00422711, 0.        , 0.00114944, 0.        ,\n",
              "         0.        , 0.01393152]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_pool_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQGdhT2cZgA8",
        "outputId": "e91ca326-e45f-4ecd-e0cb-ff8eab9b4d5f"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              "array([[0.04182441, 0.04007557, 0.03375591, 0.03003826, 0.08637103,\n",
              "        0.06598052, 0.03108212, 0.0340161 , 0.06123593, 0.05022851,\n",
              "        0.01111539, 0.08178469, 0.00420705, 0.06425364, 0.04473214,\n",
              "        0.01553611, 0.05085507, 0.0642417 , 0.        , 0.02875374,\n",
              "        0.03470616, 0.05491918, 0.02625585, 0.02888207, 0.0948526 ,\n",
              "        0.        , 0.0691933 , 0.0052118 , 0.04842124, 0.01253425,\n",
              "        0.        , 0.0424952 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs= layers.Input(shape=(1,),dtype=tf.string)\n",
        "x= text_vectorizer(inputs)\n",
        "x= embedding(x)\n",
        "\n",
        "x= layers.Conv1D(filters=64,\n",
        "                 kernel_size=5,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 padding='valid')(x)\n",
        "\n",
        "x= layers.GlobalMaxPool1D()(x)\n",
        "\n",
        "outputs=layers.Dense(1, activation='sigmoid')(x)\n",
        "model_5=tf.keras.Model(inputs, outputs,name='model_5_conv_1_d')"
      ],
      "metadata": {
        "id": "F8UkWImoZznJ"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP8-VeDDbDfx",
        "outputId": "d90ea087-8315-4eb0-9f17-c4b0e1b5be84"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_conv_1_d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gM8IgcekbXqi"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_history_Conv1D=model_5.fit(train_sentences,\n",
        "                                   train_labels,\n",
        "                                   validation_data=(val_sentences, val_labels),\n",
        "                                   epochs=5,\n",
        "                                   callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                          experiment_name=\"model_5_Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMdmNRFPbf1y",
        "outputId": "ff381e9e-5d92-4b10-9dc1-1f9ea499cf32"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_Conv1D/20230617-042315\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 16s 60ms/step - loss: 0.1222 - accuracy: 0.9585 - val_loss: 0.9516 - val_accuracy: 0.7717\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0758 - accuracy: 0.9721 - val_loss: 1.0588 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0625 - accuracy: 0.9765 - val_loss: 1.1392 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0561 - accuracy: 0.9777 - val_loss: 1.1604 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0507 - accuracy: 0.9784 - val_loss: 1.2255 - val_accuracy: 0.7559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_pred_probs=model_5.predict(val_sentences)\n",
        "model_5_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-42G2nw1bz3k",
        "outputId": "e9f4f126-98e6-45fd-ba6a-3f0d091d6d45"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.21557730e-01],\n",
              "       [8.87807608e-01],\n",
              "       [9.99963641e-01],\n",
              "       [4.32081968e-02],\n",
              "       [2.09741486e-07],\n",
              "       [9.99308109e-01],\n",
              "       [9.92154300e-01],\n",
              "       [9.99995232e-01],\n",
              "       [9.99998569e-01],\n",
              "       [9.44045365e-01],\n",
              "       [1.25121318e-07],\n",
              "       [8.25677216e-01],\n",
              "       [4.22499261e-06],\n",
              "       [3.20354968e-01],\n",
              "       [9.81269864e-07],\n",
              "       [3.20360553e-03],\n",
              "       [1.19884079e-03],\n",
              "       [1.00308956e-04],\n",
              "       [1.51129030e-02],\n",
              "       [9.95813906e-01],\n",
              "       [9.67854261e-01],\n",
              "       [5.26136546e-07],\n",
              "       [9.99772847e-01],\n",
              "       [4.26380604e-04],\n",
              "       [9.99996424e-01],\n",
              "       [1.00000000e+00],\n",
              "       [5.51812933e-04],\n",
              "       [1.77727942e-03],\n",
              "       [3.39159416e-03],\n",
              "       [8.51355374e-01],\n",
              "       [3.51696014e-01],\n",
              "       [4.70721789e-05],\n",
              "       [5.51142871e-01],\n",
              "       [5.90138952e-04],\n",
              "       [1.05721153e-01],\n",
              "       [6.02560043e-01],\n",
              "       [9.99999642e-01],\n",
              "       [2.67340362e-01],\n",
              "       [1.38809476e-02],\n",
              "       [9.99977350e-01],\n",
              "       [4.49016839e-01],\n",
              "       [1.48595245e-05],\n",
              "       [2.18042620e-02],\n",
              "       [6.13228985e-05],\n",
              "       [9.71713901e-01],\n",
              "       [9.99947906e-01],\n",
              "       [9.93627667e-01],\n",
              "       [9.94630933e-01],\n",
              "       [3.26019409e-03],\n",
              "       [8.39249194e-01],\n",
              "       [4.42528166e-04],\n",
              "       [2.37407178e-01],\n",
              "       [3.45322816e-03],\n",
              "       [7.79214352e-02],\n",
              "       [9.56090033e-01],\n",
              "       [2.72885486e-02],\n",
              "       [5.05471695e-03],\n",
              "       [9.99988079e-01],\n",
              "       [5.61732850e-05],\n",
              "       [8.64090055e-07],\n",
              "       [1.80442091e-02],\n",
              "       [9.99999881e-01],\n",
              "       [9.90293384e-01],\n",
              "       [6.70877052e-03],\n",
              "       [9.98496890e-01],\n",
              "       [9.99985576e-01],\n",
              "       [9.85265315e-01],\n",
              "       [2.49728980e-03],\n",
              "       [9.88628328e-01],\n",
              "       [9.62863415e-02],\n",
              "       [4.35670605e-04],\n",
              "       [6.01081438e-02],\n",
              "       [9.98197615e-01],\n",
              "       [8.40975624e-03],\n",
              "       [9.93842006e-01],\n",
              "       [9.86884832e-01],\n",
              "       [2.03159526e-02],\n",
              "       [9.97792721e-01],\n",
              "       [4.88760829e-01],\n",
              "       [4.28218118e-05],\n",
              "       [1.62133723e-01],\n",
              "       [3.57663184e-02],\n",
              "       [1.00000000e+00],\n",
              "       [2.62178335e-04],\n",
              "       [4.48371656e-03],\n",
              "       [5.62831934e-04],\n",
              "       [4.32421875e-05],\n",
              "       [3.16240848e-03],\n",
              "       [4.96582597e-01],\n",
              "       [9.99998569e-01],\n",
              "       [1.00000000e+00],\n",
              "       [4.96592438e-05],\n",
              "       [9.92824793e-01],\n",
              "       [9.48282890e-03],\n",
              "       [1.00000000e+00],\n",
              "       [8.87807608e-01],\n",
              "       [9.77451980e-01],\n",
              "       [9.89797115e-01],\n",
              "       [9.93589044e-01],\n",
              "       [9.99717891e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.08631715e-04],\n",
              "       [1.90247945e-07],\n",
              "       [9.97338474e-01],\n",
              "       [9.98705506e-01],\n",
              "       [7.61490464e-02],\n",
              "       [9.97456491e-01],\n",
              "       [9.99973893e-01],\n",
              "       [1.53426311e-06],\n",
              "       [9.98832643e-01],\n",
              "       [8.06028724e-01],\n",
              "       [4.42033439e-07],\n",
              "       [4.97177422e-01],\n",
              "       [2.04093565e-04],\n",
              "       [6.70943828e-03],\n",
              "       [2.05207184e-01],\n",
              "       [4.27064568e-01],\n",
              "       [9.88360882e-01],\n",
              "       [4.42499340e-01],\n",
              "       [8.49726843e-04],\n",
              "       [1.00000000e+00],\n",
              "       [6.58516137e-06],\n",
              "       [6.63685799e-03],\n",
              "       [9.62562144e-01],\n",
              "       [9.80912745e-01],\n",
              "       [2.77775316e-03],\n",
              "       [9.94387329e-01],\n",
              "       [4.62184980e-05],\n",
              "       [3.62514344e-04],\n",
              "       [9.99597251e-01],\n",
              "       [6.12534568e-05],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [9.99994636e-01],\n",
              "       [1.65656507e-01],\n",
              "       [9.99998927e-01],\n",
              "       [8.67083848e-01],\n",
              "       [1.98613084e-03],\n",
              "       [6.70274196e-04],\n",
              "       [1.00000000e+00],\n",
              "       [6.06143534e-01],\n",
              "       [3.20354968e-01],\n",
              "       [9.99661565e-01],\n",
              "       [6.34865314e-02],\n",
              "       [2.64242720e-02],\n",
              "       [7.73026887e-03],\n",
              "       [9.66963176e-10],\n",
              "       [1.84743397e-03],\n",
              "       [9.64024901e-01],\n",
              "       [1.73622335e-03],\n",
              "       [1.40563503e-01],\n",
              "       [3.39209326e-02],\n",
              "       [3.55353258e-08],\n",
              "       [2.49135634e-03],\n",
              "       [9.99995947e-01],\n",
              "       [9.99743640e-01],\n",
              "       [8.30420200e-03],\n",
              "       [9.94751871e-01],\n",
              "       [1.01787542e-07],\n",
              "       [9.95690644e-01],\n",
              "       [5.65083846e-02],\n",
              "       [1.40438110e-01],\n",
              "       [9.99970675e-01],\n",
              "       [5.50604053e-03],\n",
              "       [2.01198924e-03],\n",
              "       [1.00000000e+00],\n",
              "       [1.62815288e-01],\n",
              "       [9.99998212e-01],\n",
              "       [7.66476333e-01],\n",
              "       [9.99995589e-01],\n",
              "       [9.99822319e-01],\n",
              "       [9.99924541e-01],\n",
              "       [2.67028372e-05],\n",
              "       [9.99998212e-01],\n",
              "       [3.83420079e-03],\n",
              "       [3.91601175e-01],\n",
              "       [3.67216766e-02],\n",
              "       [8.58866036e-01],\n",
              "       [9.99995828e-01],\n",
              "       [2.38820887e-03],\n",
              "       [8.06928456e-01],\n",
              "       [9.96668994e-01],\n",
              "       [9.99999881e-01],\n",
              "       [9.97409880e-01],\n",
              "       [8.65044945e-04],\n",
              "       [4.32844899e-06],\n",
              "       [1.00000000e+00],\n",
              "       [5.92083964e-08],\n",
              "       [1.05887715e-07],\n",
              "       [3.47668260e-01],\n",
              "       [4.02978003e-01],\n",
              "       [1.84825421e-05],\n",
              "       [9.52388364e-05],\n",
              "       [6.24091268e-09],\n",
              "       [7.73286156e-05],\n",
              "       [4.09632339e-05],\n",
              "       [4.08847295e-02],\n",
              "       [9.99956369e-01],\n",
              "       [7.89848418e-05],\n",
              "       [2.04885704e-03],\n",
              "       [9.99979019e-01],\n",
              "       [9.99964356e-01],\n",
              "       [1.23229111e-03],\n",
              "       [3.43029096e-04],\n",
              "       [1.00000000e+00],\n",
              "       [9.99984264e-01],\n",
              "       [9.99976873e-01],\n",
              "       [9.35416877e-01],\n",
              "       [9.94182885e-01],\n",
              "       [2.43962854e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.20827574e-07],\n",
              "       [3.11706361e-04],\n",
              "       [1.26777067e-07],\n",
              "       [4.95231234e-09],\n",
              "       [9.99945164e-01],\n",
              "       [9.91108656e-01],\n",
              "       [9.56489384e-01],\n",
              "       [9.86373425e-01],\n",
              "       [1.21783994e-01],\n",
              "       [3.04398156e-04],\n",
              "       [8.10337195e-04],\n",
              "       [8.09640042e-05],\n",
              "       [9.99999762e-01],\n",
              "       [4.24476326e-01],\n",
              "       [7.74006844e-02],\n",
              "       [1.00000000e+00],\n",
              "       [7.89759696e-01],\n",
              "       [7.74768531e-01],\n",
              "       [3.38387031e-06],\n",
              "       [3.76324332e-03],\n",
              "       [9.97201085e-01],\n",
              "       [4.03659672e-01],\n",
              "       [5.14055669e-01],\n",
              "       [6.45114621e-03],\n",
              "       [3.65192622e-01],\n",
              "       [1.39422387e-01],\n",
              "       [6.31950656e-03],\n",
              "       [3.88767425e-04],\n",
              "       [7.20396638e-01],\n",
              "       [4.45232391e-02],\n",
              "       [1.00000000e+00],\n",
              "       [9.99992728e-01],\n",
              "       [4.24658137e-05],\n",
              "       [1.44907051e-06],\n",
              "       [9.99998212e-01],\n",
              "       [3.08627864e-06],\n",
              "       [1.61099841e-03],\n",
              "       [1.88347340e-01],\n",
              "       [8.41898600e-06],\n",
              "       [9.98347878e-01],\n",
              "       [3.53138874e-09],\n",
              "       [3.13992787e-05],\n",
              "       [9.99997973e-01],\n",
              "       [1.51759818e-01],\n",
              "       [9.99851823e-01],\n",
              "       [9.99999881e-01],\n",
              "       [9.87172872e-03],\n",
              "       [1.69024698e-03],\n",
              "       [5.47707686e-03],\n",
              "       [2.16998553e-04],\n",
              "       [7.98089559e-07],\n",
              "       [1.00000000e+00],\n",
              "       [9.99970317e-01],\n",
              "       [7.07719505e-01],\n",
              "       [9.99991417e-01],\n",
              "       [1.94226683e-04],\n",
              "       [7.34305233e-02],\n",
              "       [4.96837758e-02],\n",
              "       [3.03026708e-03],\n",
              "       [7.36990769e-05],\n",
              "       [9.99999404e-01],\n",
              "       [6.31224690e-03],\n",
              "       [7.38998267e-07],\n",
              "       [9.99994516e-01],\n",
              "       [4.61483360e-05],\n",
              "       [1.29002042e-03],\n",
              "       [9.99957085e-01],\n",
              "       [2.32204358e-04],\n",
              "       [1.67873092e-02],\n",
              "       [1.83012686e-04],\n",
              "       [9.99987960e-01],\n",
              "       [9.98674631e-01],\n",
              "       [9.17818010e-01],\n",
              "       [6.87546790e-01],\n",
              "       [9.99859810e-01],\n",
              "       [9.16903745e-03],\n",
              "       [9.97364581e-01],\n",
              "       [1.49475259e-03],\n",
              "       [6.90129280e-01],\n",
              "       [9.99160767e-01],\n",
              "       [3.52810591e-01],\n",
              "       [4.78369325e-01],\n",
              "       [1.50818872e-04],\n",
              "       [6.50759816e-01],\n",
              "       [4.02566604e-03],\n",
              "       [2.21986938e-02],\n",
              "       [7.67941994e-04],\n",
              "       [1.83863595e-01],\n",
              "       [1.38865080e-05],\n",
              "       [4.45748167e-03],\n",
              "       [5.65368049e-02],\n",
              "       [9.99989629e-01],\n",
              "       [3.35058896e-03],\n",
              "       [2.48813245e-04],\n",
              "       [7.76187956e-01],\n",
              "       [1.54931381e-01],\n",
              "       [6.93290904e-02],\n",
              "       [4.32119805e-06],\n",
              "       [1.55231864e-05],\n",
              "       [9.99967933e-01],\n",
              "       [4.00733143e-01],\n",
              "       [6.69782400e-01],\n",
              "       [1.00000000e+00],\n",
              "       [2.40730913e-03],\n",
              "       [9.99068916e-01],\n",
              "       [2.19203513e-02],\n",
              "       [4.63125580e-05],\n",
              "       [9.28221643e-02],\n",
              "       [4.29547708e-06],\n",
              "       [8.90322123e-03],\n",
              "       [9.99979377e-01],\n",
              "       [1.84861869e-01],\n",
              "       [9.99999166e-01],\n",
              "       [6.94581270e-02],\n",
              "       [8.82535642e-06],\n",
              "       [9.99997854e-01],\n",
              "       [2.76545732e-04],\n",
              "       [9.99999642e-01],\n",
              "       [8.11294420e-04],\n",
              "       [1.67489525e-05],\n",
              "       [1.00000000e+00],\n",
              "       [1.98180514e-05],\n",
              "       [7.86506553e-06],\n",
              "       [9.99971032e-01],\n",
              "       [1.48616928e-05],\n",
              "       [7.60524426e-06],\n",
              "       [9.99704301e-01],\n",
              "       [9.97182488e-01],\n",
              "       [4.70521968e-07],\n",
              "       [4.47291741e-03],\n",
              "       [9.99997497e-01],\n",
              "       [9.94924307e-01],\n",
              "       [9.99236703e-01],\n",
              "       [1.83729872e-01],\n",
              "       [9.26343083e-01],\n",
              "       [9.99222159e-01],\n",
              "       [2.08491436e-03],\n",
              "       [7.17053626e-05],\n",
              "       [8.32762662e-03],\n",
              "       [8.08930956e-03],\n",
              "       [1.81367686e-05],\n",
              "       [4.98477995e-01],\n",
              "       [1.45351276e-01],\n",
              "       [1.79684753e-06],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [6.93819951e-04],\n",
              "       [9.85694751e-02],\n",
              "       [1.01601388e-02],\n",
              "       [5.53511441e-01],\n",
              "       [9.86140966e-01],\n",
              "       [3.74899238e-01],\n",
              "       [2.22804767e-04],\n",
              "       [4.31395293e-08],\n",
              "       [2.20714812e-03],\n",
              "       [9.89719927e-01],\n",
              "       [2.79881293e-03],\n",
              "       [5.71437273e-03],\n",
              "       [1.06656253e-05],\n",
              "       [3.59933893e-03],\n",
              "       [1.20056085e-02],\n",
              "       [9.97863114e-01],\n",
              "       [3.57838795e-02],\n",
              "       [2.99065368e-06],\n",
              "       [8.69689323e-03],\n",
              "       [1.65131241e-02],\n",
              "       [1.00000000e+00],\n",
              "       [9.98088062e-01],\n",
              "       [5.89189887e-01],\n",
              "       [9.93512332e-01],\n",
              "       [3.71860276e-09],\n",
              "       [8.37567449e-01],\n",
              "       [9.99999881e-01],\n",
              "       [7.38733828e-01],\n",
              "       [3.84411931e-01],\n",
              "       [9.99972224e-01],\n",
              "       [5.82193285e-02],\n",
              "       [9.99966741e-01],\n",
              "       [3.62134762e-02],\n",
              "       [1.04343139e-01],\n",
              "       [5.50759196e-01],\n",
              "       [2.92713463e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.67617723e-02],\n",
              "       [5.36635598e-05],\n",
              "       [5.36101106e-05],\n",
              "       [3.74899238e-01],\n",
              "       [1.00000000e+00],\n",
              "       [7.20459357e-05],\n",
              "       [4.95401360e-02],\n",
              "       [9.99971509e-01],\n",
              "       [5.41093468e-05],\n",
              "       [1.00000000e+00],\n",
              "       [5.52733522e-03],\n",
              "       [6.73865579e-05],\n",
              "       [2.08222009e-02],\n",
              "       [9.99372303e-01],\n",
              "       [9.98456359e-01],\n",
              "       [1.20450663e-04],\n",
              "       [1.48307072e-06],\n",
              "       [1.09900482e-01],\n",
              "       [9.99998808e-01],\n",
              "       [4.69240367e-01],\n",
              "       [1.41403743e-03],\n",
              "       [8.95903483e-02],\n",
              "       [6.07263520e-02],\n",
              "       [4.14404076e-06],\n",
              "       [9.99998450e-01],\n",
              "       [1.45665288e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99987841e-01],\n",
              "       [4.31729332e-02],\n",
              "       [8.49810064e-01],\n",
              "       [2.18036977e-04],\n",
              "       [9.99212027e-01],\n",
              "       [9.98811722e-01],\n",
              "       [9.99662519e-01],\n",
              "       [5.32324240e-03],\n",
              "       [1.27307372e-02],\n",
              "       [1.41883856e-05],\n",
              "       [2.94851401e-04],\n",
              "       [1.93762990e-05],\n",
              "       [4.29196371e-04],\n",
              "       [8.60041201e-01],\n",
              "       [3.65924323e-03],\n",
              "       [1.00000000e+00],\n",
              "       [9.99989867e-01],\n",
              "       [4.15957391e-01],\n",
              "       [8.87807608e-01],\n",
              "       [4.99975961e-03],\n",
              "       [3.16544028e-04],\n",
              "       [1.84021384e-01],\n",
              "       [7.71506011e-01],\n",
              "       [2.71009147e-01],\n",
              "       [6.51086643e-02],\n",
              "       [2.81478879e-06],\n",
              "       [1.69990992e-04],\n",
              "       [4.62366074e-08],\n",
              "       [9.99698758e-01],\n",
              "       [9.99681950e-01],\n",
              "       [9.99995589e-01],\n",
              "       [2.98859119e-01],\n",
              "       [8.71164739e-01],\n",
              "       [2.02036485e-01],\n",
              "       [2.86266499e-07],\n",
              "       [1.62279084e-01],\n",
              "       [9.99845862e-01],\n",
              "       [1.00000000e+00],\n",
              "       [3.35056882e-07],\n",
              "       [7.73786604e-01],\n",
              "       [4.44716943e-06],\n",
              "       [9.99999762e-01],\n",
              "       [1.00000000e+00],\n",
              "       [5.08813143e-01],\n",
              "       [1.82688832e-01],\n",
              "       [9.99998450e-01],\n",
              "       [5.79443295e-04],\n",
              "       [3.93411377e-03],\n",
              "       [9.99994159e-01],\n",
              "       [2.82192705e-05],\n",
              "       [5.78658000e-05],\n",
              "       [9.99370277e-01],\n",
              "       [2.02101603e-01],\n",
              "       [7.29023993e-01],\n",
              "       [9.99990344e-01],\n",
              "       [1.98557187e-04],\n",
              "       [9.06656845e-04],\n",
              "       [5.58624888e-05],\n",
              "       [2.17685003e-09],\n",
              "       [2.71512399e-04],\n",
              "       [9.99997616e-01],\n",
              "       [6.70365216e-06],\n",
              "       [8.83131087e-01],\n",
              "       [3.15995485e-01],\n",
              "       [4.72471714e-02],\n",
              "       [1.70065135e-01],\n",
              "       [2.62873596e-06],\n",
              "       [5.91426389e-03],\n",
              "       [9.99996185e-01],\n",
              "       [9.99957561e-01],\n",
              "       [1.20931938e-02],\n",
              "       [7.18977117e-06],\n",
              "       [3.34391706e-02],\n",
              "       [1.09784723e-05],\n",
              "       [9.91962850e-01],\n",
              "       [4.15862305e-05],\n",
              "       [9.65286493e-01],\n",
              "       [9.70440030e-01],\n",
              "       [7.81380415e-01],\n",
              "       [9.91331577e-01],\n",
              "       [6.19940102e-01],\n",
              "       [7.34458736e-04],\n",
              "       [2.13843631e-03],\n",
              "       [2.61708349e-01],\n",
              "       [7.18163013e-01],\n",
              "       [9.20793355e-01],\n",
              "       [1.57057613e-01],\n",
              "       [9.64670442e-03],\n",
              "       [2.26621887e-06],\n",
              "       [8.06188291e-06],\n",
              "       [1.12823546e-02],\n",
              "       [1.76286817e-01],\n",
              "       [1.48710385e-01],\n",
              "       [9.99998450e-01],\n",
              "       [9.99998212e-01],\n",
              "       [8.87807608e-01],\n",
              "       [9.99500751e-01],\n",
              "       [1.24484980e-02],\n",
              "       [9.67535016e-06],\n",
              "       [9.98245239e-01],\n",
              "       [8.01692486e-01],\n",
              "       [4.64038952e-04],\n",
              "       [3.89380276e-01],\n",
              "       [9.84700799e-01],\n",
              "       [3.23019878e-09],\n",
              "       [8.07852924e-01],\n",
              "       [8.68254185e-01],\n",
              "       [7.84531534e-01],\n",
              "       [9.99981403e-01],\n",
              "       [1.07021250e-01],\n",
              "       [1.64634886e-03],\n",
              "       [9.53110516e-01],\n",
              "       [3.00391184e-05],\n",
              "       [6.19418249e-02],\n",
              "       [9.08230662e-01],\n",
              "       [9.89592314e-01],\n",
              "       [8.52044940e-01],\n",
              "       [1.25142382e-04],\n",
              "       [2.66279257e-03],\n",
              "       [9.48506653e-01],\n",
              "       [3.55461449e-03],\n",
              "       [1.83061391e-04],\n",
              "       [5.21206857e-05],\n",
              "       [2.89143294e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99345601e-01],\n",
              "       [2.86502719e-01],\n",
              "       [9.99975920e-01],\n",
              "       [9.99986172e-01],\n",
              "       [5.06472986e-07],\n",
              "       [9.99999404e-01],\n",
              "       [2.58428473e-02],\n",
              "       [9.99650359e-01],\n",
              "       [3.49125028e-01],\n",
              "       [3.29836123e-02],\n",
              "       [1.36833827e-04],\n",
              "       [3.88760236e-06],\n",
              "       [1.34662353e-02],\n",
              "       [4.93514235e-04],\n",
              "       [5.57448864e-01],\n",
              "       [1.58030039e-03],\n",
              "       [9.99994636e-01],\n",
              "       [8.68134375e-04],\n",
              "       [9.62723792e-01],\n",
              "       [3.74012083e-01],\n",
              "       [3.64199601e-04],\n",
              "       [2.69907434e-03],\n",
              "       [9.99997377e-01],\n",
              "       [1.06055546e-03],\n",
              "       [9.99843836e-01],\n",
              "       [1.05777636e-01],\n",
              "       [2.87625622e-02],\n",
              "       [3.47187489e-01],\n",
              "       [1.68922503e-04],\n",
              "       [2.31186710e-02],\n",
              "       [9.99986172e-01],\n",
              "       [7.10368568e-07],\n",
              "       [5.53850317e-04],\n",
              "       [1.49192028e-02],\n",
              "       [1.00000000e+00],\n",
              "       [2.39108875e-02],\n",
              "       [2.91201577e-05],\n",
              "       [9.99993086e-01],\n",
              "       [8.58401634e-08],\n",
              "       [3.76825891e-02],\n",
              "       [4.67082150e-02],\n",
              "       [2.34275967e-01],\n",
              "       [6.12501317e-05],\n",
              "       [5.27781606e-01],\n",
              "       [1.33292479e-02],\n",
              "       [1.66177914e-01],\n",
              "       [5.28528318e-02],\n",
              "       [9.83826146e-02],\n",
              "       [1.89746555e-04],\n",
              "       [9.99538898e-01],\n",
              "       [9.97609973e-01],\n",
              "       [6.36795104e-01],\n",
              "       [8.98085000e-06],\n",
              "       [1.30479375e-03],\n",
              "       [9.99996901e-01],\n",
              "       [9.88703251e-01],\n",
              "       [1.00000000e+00],\n",
              "       [8.93098414e-02],\n",
              "       [9.98866677e-01],\n",
              "       [5.19533060e-05],\n",
              "       [9.98996317e-01],\n",
              "       [9.93677437e-01],\n",
              "       [1.89996863e-09],\n",
              "       [9.99855399e-01],\n",
              "       [1.71724744e-02],\n",
              "       [9.94573891e-01],\n",
              "       [9.99522448e-01],\n",
              "       [1.76340025e-02],\n",
              "       [1.16970194e-04],\n",
              "       [3.32232058e-01],\n",
              "       [2.19211915e-06],\n",
              "       [2.54845750e-02],\n",
              "       [1.00000000e+00],\n",
              "       [3.31620842e-01],\n",
              "       [9.99157548e-01],\n",
              "       [2.97101527e-01],\n",
              "       [9.99996662e-01],\n",
              "       [9.97586608e-01],\n",
              "       [4.56534000e-03],\n",
              "       [5.87930415e-08],\n",
              "       [9.28675711e-01],\n",
              "       [2.78613676e-04],\n",
              "       [1.07914306e-01],\n",
              "       [9.99994397e-01],\n",
              "       [9.99763191e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99936581e-01],\n",
              "       [4.37591165e-01],\n",
              "       [9.92504001e-01],\n",
              "       [1.06424250e-06],\n",
              "       [8.33496571e-01],\n",
              "       [9.96234834e-01],\n",
              "       [9.99916077e-01],\n",
              "       [1.22041623e-04],\n",
              "       [9.84607160e-01],\n",
              "       [9.98329222e-01],\n",
              "       [4.60858224e-04],\n",
              "       [9.26075689e-03],\n",
              "       [1.57057613e-01],\n",
              "       [1.57951079e-02],\n",
              "       [9.76710498e-01],\n",
              "       [9.92110312e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.07491692e-03],\n",
              "       [9.62844865e-07],\n",
              "       [6.07634263e-07],\n",
              "       [1.25060186e-01],\n",
              "       [8.12481996e-03],\n",
              "       [1.48764383e-02],\n",
              "       [9.86699700e-01],\n",
              "       [3.85187595e-05],\n",
              "       [6.10242248e-01],\n",
              "       [1.89346075e-02],\n",
              "       [9.44511056e-01],\n",
              "       [9.99950409e-01],\n",
              "       [2.14185420e-05],\n",
              "       [9.70666111e-01],\n",
              "       [4.69071902e-02],\n",
              "       [1.71517729e-06],\n",
              "       [1.50239572e-03],\n",
              "       [1.00000000e+00],\n",
              "       [7.52424300e-01],\n",
              "       [6.47495938e-07],\n",
              "       [7.55475610e-02],\n",
              "       [5.28759301e-01],\n",
              "       [5.70572547e-06],\n",
              "       [9.99992847e-01],\n",
              "       [1.83486077e-03],\n",
              "       [9.27926838e-01],\n",
              "       [3.99117708e-01],\n",
              "       [1.21402030e-03],\n",
              "       [2.80222327e-01],\n",
              "       [2.43793398e-01],\n",
              "       [3.31209833e-03],\n",
              "       [9.98853922e-01],\n",
              "       [1.44400105e-01],\n",
              "       [5.77431560e-01],\n",
              "       [9.77527559e-01],\n",
              "       [7.40853071e-01],\n",
              "       [2.80300021e-01],\n",
              "       [3.23019878e-09],\n",
              "       [6.53898120e-01],\n",
              "       [4.46287066e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.43492115e-01],\n",
              "       [6.02240732e-04],\n",
              "       [9.99998927e-01],\n",
              "       [2.18014881e-01],\n",
              "       [9.93724048e-01],\n",
              "       [2.18014881e-01],\n",
              "       [9.99978304e-01],\n",
              "       [1.02515496e-05],\n",
              "       [6.39823778e-03],\n",
              "       [1.37288680e-07],\n",
              "       [9.99999285e-01],\n",
              "       [1.27619043e-01],\n",
              "       [2.23111501e-03],\n",
              "       [1.41953569e-05],\n",
              "       [1.29645271e-02],\n",
              "       [8.54089782e-02],\n",
              "       [2.01310959e-05],\n",
              "       [2.02148512e-01],\n",
              "       [2.26310291e-03],\n",
              "       [1.53760379e-03],\n",
              "       [9.49540019e-01],\n",
              "       [8.87709321e-04],\n",
              "       [1.31138728e-03],\n",
              "       [9.53501789e-04],\n",
              "       [5.91569247e-08],\n",
              "       [9.19468328e-02],\n",
              "       [9.93315518e-01],\n",
              "       [6.60385471e-04],\n",
              "       [3.24700654e-01],\n",
              "       [3.37310345e-03],\n",
              "       [9.99312520e-01],\n",
              "       [9.99999881e-01],\n",
              "       [1.33905225e-04],\n",
              "       [1.82031708e-05],\n",
              "       [5.58301053e-07],\n",
              "       [4.46631105e-07],\n",
              "       [9.99995947e-01],\n",
              "       [5.91569247e-08],\n",
              "       [3.10706976e-03],\n",
              "       [9.99629378e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [7.09300002e-05],\n",
              "       [4.65368503e-04],\n",
              "       [7.19223201e-01],\n",
              "       [8.35137486e-01],\n",
              "       [9.99998331e-01],\n",
              "       [9.10952687e-01],\n",
              "       [9.32815492e-01],\n",
              "       [9.72571135e-01],\n",
              "       [9.61142659e-01],\n",
              "       [3.60155013e-07],\n",
              "       [1.44432644e-08],\n",
              "       [5.47019998e-03],\n",
              "       [2.21738201e-02],\n",
              "       [1.01162739e-04],\n",
              "       [1.35562045e-03],\n",
              "       [9.99999166e-01],\n",
              "       [9.99996543e-01],\n",
              "       [1.19201002e-04],\n",
              "       [9.99954343e-01],\n",
              "       [8.64349246e-01],\n",
              "       [2.22402513e-01],\n",
              "       [4.88288421e-03],\n",
              "       [5.74921787e-01],\n",
              "       [4.07083511e-01],\n",
              "       [1.13419183e-01],\n",
              "       [4.13333692e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_preds=tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wci8HGxwb5vm",
        "outputId": "9ed8693d-1ee0-4968-9478-b88892246f5a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_results=calculate_results(y_true=val_labels,\n",
        "                  y_pred=model_5_preds)"
      ],
      "metadata": {
        "id": "3qN_ie--b_0I"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVqhW-_3cENL",
        "outputId": "2afe323d-ec77-403a-bd9f-beed1c8d00cf"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6: Tensorflow Hub pretrained Sentence Encoding"
      ],
      "metadata": {
        "id": "SPmprk6KcOoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvb-dAhMeEaL",
        "outputId": "5d0173c8-253f-4dcb-a64e-c03a0a9f5688"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01648414  0.01238942 -0.03802392  0.01613512  0.01126497  0.03020509\n",
            " -0.03046947  0.06194781 -0.02105992 -0.03057137  0.0008841  -0.01712316\n",
            "  0.02300218  0.13233913 -0.02402753 -0.04065577 -0.00783854 -0.01782103\n",
            "  0.00084766 -0.06022935  0.03030973 -0.0243262   0.01335942 -0.0070219\n",
            " -0.03293562  0.01491859  0.06453037 -0.03094468 -0.02930314  0.0543048\n",
            " -0.04252577  0.03884937  0.05540233  0.0499546   0.01574396 -0.04668788\n",
            "  0.06723305  0.0761669  -0.0324351  -0.09583164  0.0146003   0.05765748\n",
            " -0.05838084  0.08828386 -0.10436028 -0.03254431 -0.0373541  -0.04613885\n",
            "  0.0224453  -0.02335855], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create keras layer using USE Pretrained Layer from tensorflow hub\n",
        "sentence_encoder_layer= hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                       input_shape=[],#output will be a 512 vector\n",
        "                                       dtype=tf.string,\n",
        "                                       trainable=False,\n",
        "                                       name='USE')"
      ],
      "metadata": {
        "id": "C9P3Ljs1ft8V"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create moled using the sequential api\n",
        "model_6=tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    #layers.Dense(64,activation='relu)\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "], name='mode_6_use')\n",
        "\n",
        "#Complie\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLcgH-GynLSs",
        "outputId": "75d65cde-07c0-49a7-ab91-903410f6c18b"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mode_6_use\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train a classifier on top of pretrianed embeddings\n",
        "history_model_6=model_6.fit(train_sentences,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_sentences, val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                   experiment_name=\"tf_hub_sentnece_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1atbnpDsnysG",
        "outputId": "5031b0b1-c28c-4416-d6ac-f8e2be45ead1"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentnece_encoder/20230617-042458\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 27ms/step - loss: 0.6463 - accuracy: 0.7463 - val_loss: 0.6118 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.5790 - accuracy: 0.7938 - val_loss: 0.5626 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.5364 - accuracy: 0.7975 - val_loss: 0.5309 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.5083 - accuracy: 0.7973 - val_loss: 0.5098 - val_accuracy: 0.7940\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.4884 - accuracy: 0.8013 - val_loss: 0.4956 - val_accuracy: 0.7953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions\n",
        "model_6_pred_probs=model_6.predict(val_sentences)\n",
        "model_6_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR-Yog5joKl0",
        "outputId": "647c8300-9457-402b-cafd-2ba76c2c6e0b"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.36461294],\n",
              "       [0.67280084],\n",
              "       [0.85701054],\n",
              "       [0.3530801 ],\n",
              "       [0.63473403],\n",
              "       [0.72364056],\n",
              "       [0.8247915 ],\n",
              "       [0.84205276],\n",
              "       [0.7506826 ],\n",
              "       [0.19538848],\n",
              "       [0.5147888 ],\n",
              "       [0.50769603],\n",
              "       [0.40201965],\n",
              "       [0.47633982],\n",
              "       [0.47518697],\n",
              "       [0.1802003 ],\n",
              "       [0.34763247],\n",
              "       [0.47871843],\n",
              "       [0.5133213 ],\n",
              "       [0.53631353],\n",
              "       [0.6062126 ],\n",
              "       [0.26801613],\n",
              "       [0.50340015],\n",
              "       [0.16370292],\n",
              "       [0.6165177 ],\n",
              "       [0.7966377 ],\n",
              "       [0.25056186],\n",
              "       [0.3245427 ],\n",
              "       [0.24108338],\n",
              "       [0.35932237],\n",
              "       [0.54147965],\n",
              "       [0.7624572 ],\n",
              "       [0.46170503],\n",
              "       [0.48045015],\n",
              "       [0.5179098 ],\n",
              "       [0.18952167],\n",
              "       [0.7878452 ],\n",
              "       [0.17097682],\n",
              "       [0.20289005],\n",
              "       [0.81277394],\n",
              "       [0.23260249],\n",
              "       [0.31122327],\n",
              "       [0.5306614 ],\n",
              "       [0.5402832 ],\n",
              "       [0.28434733],\n",
              "       [0.7408651 ],\n",
              "       [0.3204906 ],\n",
              "       [0.8448125 ],\n",
              "       [0.53234416],\n",
              "       [0.79892796],\n",
              "       [0.15851289],\n",
              "       [0.59090376],\n",
              "       [0.308898  ],\n",
              "       [0.13703154],\n",
              "       [0.21568932],\n",
              "       [0.10528954],\n",
              "       [0.3133144 ],\n",
              "       [0.7211349 ],\n",
              "       [0.23440698],\n",
              "       [0.1979262 ],\n",
              "       [0.11194272],\n",
              "       [0.7806071 ],\n",
              "       [0.8303337 ],\n",
              "       [0.21690474],\n",
              "       [0.6780121 ],\n",
              "       [0.7965783 ],\n",
              "       [0.41377544],\n",
              "       [0.43524486],\n",
              "       [0.19157083],\n",
              "       [0.5378755 ],\n",
              "       [0.19161181],\n",
              "       [0.21140014],\n",
              "       [0.606729  ],\n",
              "       [0.16800964],\n",
              "       [0.1353806 ],\n",
              "       [0.5522856 ],\n",
              "       [0.24670325],\n",
              "       [0.42053768],\n",
              "       [0.2059934 ],\n",
              "       [0.66235083],\n",
              "       [0.6975903 ],\n",
              "       [0.52635044],\n",
              "       [0.6530952 ],\n",
              "       [0.29251775],\n",
              "       [0.4601022 ],\n",
              "       [0.57478136],\n",
              "       [0.21704192],\n",
              "       [0.23204884],\n",
              "       [0.87380415],\n",
              "       [0.62433326],\n",
              "       [0.8899986 ],\n",
              "       [0.1196999 ],\n",
              "       [0.16738835],\n",
              "       [0.17102197],\n",
              "       [0.7652007 ],\n",
              "       [0.639905  ],\n",
              "       [0.74529773],\n",
              "       [0.7192516 ],\n",
              "       [0.79892904],\n",
              "       [0.71295303],\n",
              "       [0.7526137 ],\n",
              "       [0.2561707 ],\n",
              "       [0.1489672 ],\n",
              "       [0.82145524],\n",
              "       [0.7625897 ],\n",
              "       [0.15864721],\n",
              "       [0.6179128 ],\n",
              "       [0.61105955],\n",
              "       [0.26538128],\n",
              "       [0.68263453],\n",
              "       [0.48229793],\n",
              "       [0.27820826],\n",
              "       [0.33671016],\n",
              "       [0.43628964],\n",
              "       [0.4484139 ],\n",
              "       [0.4929846 ],\n",
              "       [0.5633985 ],\n",
              "       [0.66418755],\n",
              "       [0.58366245],\n",
              "       [0.66023177],\n",
              "       [0.76674944],\n",
              "       [0.37091094],\n",
              "       [0.48386016],\n",
              "       [0.6130054 ],\n",
              "       [0.5658729 ],\n",
              "       [0.43042636],\n",
              "       [0.26784045],\n",
              "       [0.24252783],\n",
              "       [0.17194484],\n",
              "       [0.4898492 ],\n",
              "       [0.2775681 ],\n",
              "       [0.77267927],\n",
              "       [0.7303073 ],\n",
              "       [0.79917747],\n",
              "       [0.6093078 ],\n",
              "       [0.40113464],\n",
              "       [0.7332052 ],\n",
              "       [0.3522367 ],\n",
              "       [0.36345252],\n",
              "       [0.23332353],\n",
              "       [0.8280483 ],\n",
              "       [0.33694685],\n",
              "       [0.49016252],\n",
              "       [0.5040842 ],\n",
              "       [0.56347436],\n",
              "       [0.303197  ],\n",
              "       [0.11348741],\n",
              "       [0.19671902],\n",
              "       [0.23426385],\n",
              "       [0.808402  ],\n",
              "       [0.6174521 ],\n",
              "       [0.21559168],\n",
              "       [0.55830663],\n",
              "       [0.26807597],\n",
              "       [0.27872396],\n",
              "       [0.66232425],\n",
              "       [0.46319625],\n",
              "       [0.2037632 ],\n",
              "       [0.75564885],\n",
              "       [0.45570803],\n",
              "       [0.72128475],\n",
              "       [0.26246014],\n",
              "       [0.19498111],\n",
              "       [0.7872699 ],\n",
              "       [0.3332539 ],\n",
              "       [0.2840874 ],\n",
              "       [0.91438556],\n",
              "       [0.38903457],\n",
              "       [0.7331631 ],\n",
              "       [0.20767038],\n",
              "       [0.81104934],\n",
              "       [0.6577203 ],\n",
              "       [0.81868976],\n",
              "       [0.26893887],\n",
              "       [0.72088605],\n",
              "       [0.11629438],\n",
              "       [0.765511  ],\n",
              "       [0.4749547 ],\n",
              "       [0.51722616],\n",
              "       [0.85571873],\n",
              "       [0.1319337 ],\n",
              "       [0.6817693 ],\n",
              "       [0.52935994],\n",
              "       [0.693955  ],\n",
              "       [0.6776935 ],\n",
              "       [0.39944524],\n",
              "       [0.30658442],\n",
              "       [0.7782541 ],\n",
              "       [0.4974392 ],\n",
              "       [0.29221082],\n",
              "       [0.4003933 ],\n",
              "       [0.7487473 ],\n",
              "       [0.47261298],\n",
              "       [0.49565572],\n",
              "       [0.2834455 ],\n",
              "       [0.3495199 ],\n",
              "       [0.2415407 ],\n",
              "       [0.3625937 ],\n",
              "       [0.41585132],\n",
              "       [0.23385967],\n",
              "       [0.27699587],\n",
              "       [0.7299659 ],\n",
              "       [0.6887427 ],\n",
              "       [0.25907707],\n",
              "       [0.383978  ],\n",
              "       [0.8828956 ],\n",
              "       [0.3803229 ],\n",
              "       [0.7052652 ],\n",
              "       [0.77764946],\n",
              "       [0.6659854 ],\n",
              "       [0.14490505],\n",
              "       [0.77769697],\n",
              "       [0.22621603],\n",
              "       [0.32761112],\n",
              "       [0.16803539],\n",
              "       [0.16224155],\n",
              "       [0.66266817],\n",
              "       [0.6884687 ],\n",
              "       [0.51019746],\n",
              "       [0.15710066],\n",
              "       [0.5633263 ],\n",
              "       [0.16857585],\n",
              "       [0.16987352],\n",
              "       [0.28695378],\n",
              "       [0.7817198 ],\n",
              "       [0.29269692],\n",
              "       [0.28487462],\n",
              "       [0.75723207],\n",
              "       [0.5937338 ],\n",
              "       [0.4419372 ],\n",
              "       [0.6872462 ],\n",
              "       [0.2063492 ],\n",
              "       [0.7801498 ],\n",
              "       [0.11660084],\n",
              "       [0.5381593 ],\n",
              "       [0.42571786],\n",
              "       [0.4637003 ],\n",
              "       [0.42541012],\n",
              "       [0.75972223],\n",
              "       [0.11712679],\n",
              "       [0.39556813],\n",
              "       [0.38087428],\n",
              "       [0.8387595 ],\n",
              "       [0.7795057 ],\n",
              "       [0.17001976],\n",
              "       [0.40532964],\n",
              "       [0.72298753],\n",
              "       [0.25487688],\n",
              "       [0.18811834],\n",
              "       [0.5881798 ],\n",
              "       [0.2932179 ],\n",
              "       [0.527676  ],\n",
              "       [0.15077615],\n",
              "       [0.48920378],\n",
              "       [0.7099194 ],\n",
              "       [0.26546144],\n",
              "       [0.72279   ],\n",
              "       [0.8899537 ],\n",
              "       [0.20425394],\n",
              "       [0.32244036],\n",
              "       [0.7634851 ],\n",
              "       [0.2607852 ],\n",
              "       [0.31984308],\n",
              "       [0.8018354 ],\n",
              "       [0.56468457],\n",
              "       [0.6301886 ],\n",
              "       [0.7014045 ],\n",
              "       [0.20551816],\n",
              "       [0.36421743],\n",
              "       [0.13765956],\n",
              "       [0.39359558],\n",
              "       [0.42737007],\n",
              "       [0.79036385],\n",
              "       [0.21167181],\n",
              "       [0.43525037],\n",
              "       [0.7643613 ],\n",
              "       [0.52694035],\n",
              "       [0.1011026 ],\n",
              "       [0.83247554],\n",
              "       [0.5556017 ],\n",
              "       [0.2558132 ],\n",
              "       [0.30818155],\n",
              "       [0.8246765 ],\n",
              "       [0.4248867 ],\n",
              "       [0.29067752],\n",
              "       [0.6353117 ],\n",
              "       [0.46862888],\n",
              "       [0.2611494 ],\n",
              "       [0.576649  ],\n",
              "       [0.22962618],\n",
              "       [0.55193645],\n",
              "       [0.4350584 ],\n",
              "       [0.4929416 ],\n",
              "       [0.5737715 ],\n",
              "       [0.24278249],\n",
              "       [0.7098962 ],\n",
              "       [0.4172853 ],\n",
              "       [0.8355114 ],\n",
              "       [0.09799559],\n",
              "       [0.648339  ],\n",
              "       [0.5365306 ],\n",
              "       [0.25844157],\n",
              "       [0.30065536],\n",
              "       [0.63232493],\n",
              "       [0.38866454],\n",
              "       [0.34723428],\n",
              "       [0.22062266],\n",
              "       [0.543245  ],\n",
              "       [0.22073892],\n",
              "       [0.1016803 ],\n",
              "       [0.22139923],\n",
              "       [0.68520004],\n",
              "       [0.5406131 ],\n",
              "       [0.36824572],\n",
              "       [0.8115692 ],\n",
              "       [0.17149813],\n",
              "       [0.75315076],\n",
              "       [0.60425806],\n",
              "       [0.19852184],\n",
              "       [0.3726107 ],\n",
              "       [0.2286624 ],\n",
              "       [0.23325147],\n",
              "       [0.79608774],\n",
              "       [0.13553543],\n",
              "       [0.60219425],\n",
              "       [0.28631517],\n",
              "       [0.2737524 ],\n",
              "       [0.6917942 ],\n",
              "       [0.24641618],\n",
              "       [0.7806238 ],\n",
              "       [0.5489361 ],\n",
              "       [0.1728607 ],\n",
              "       [0.7470546 ],\n",
              "       [0.35970092],\n",
              "       [0.25380698],\n",
              "       [0.66939914],\n",
              "       [0.17851327],\n",
              "       [0.49177733],\n",
              "       [0.44501644],\n",
              "       [0.4171345 ],\n",
              "       [0.20614283],\n",
              "       [0.24397418],\n",
              "       [0.70949197],\n",
              "       [0.7546154 ],\n",
              "       [0.6097571 ],\n",
              "       [0.35425916],\n",
              "       [0.35472167],\n",
              "       [0.2767904 ],\n",
              "       [0.12407327],\n",
              "       [0.4040527 ],\n",
              "       [0.30798402],\n",
              "       [0.4412583 ],\n",
              "       [0.14056534],\n",
              "       [0.36041808],\n",
              "       [0.38453802],\n",
              "       [0.17155506],\n",
              "       [0.7885469 ],\n",
              "       [0.7820302 ],\n",
              "       [0.67947507],\n",
              "       [0.39475313],\n",
              "       [0.5734882 ],\n",
              "       [0.27759525],\n",
              "       [0.6523253 ],\n",
              "       [0.4692372 ],\n",
              "       [0.6414485 ],\n",
              "       [0.15861246],\n",
              "       [0.29519135],\n",
              "       [0.2326493 ],\n",
              "       [0.3325238 ],\n",
              "       [0.1429245 ],\n",
              "       [0.53762764],\n",
              "       [0.12892725],\n",
              "       [0.15600418],\n",
              "       [0.41550043],\n",
              "       [0.1660026 ],\n",
              "       [0.22113644],\n",
              "       [0.24215278],\n",
              "       [0.47968957],\n",
              "       [0.19441496],\n",
              "       [0.4586749 ],\n",
              "       [0.78229123],\n",
              "       [0.5652686 ],\n",
              "       [0.18170866],\n",
              "       [0.4479365 ],\n",
              "       [0.43374842],\n",
              "       [0.7319762 ],\n",
              "       [0.5111237 ],\n",
              "       [0.2941092 ],\n",
              "       [0.87141985],\n",
              "       [0.39267406],\n",
              "       [0.19420196],\n",
              "       [0.2804335 ],\n",
              "       [0.11009963],\n",
              "       [0.74749595],\n",
              "       [0.4900332 ],\n",
              "       [0.829631  ],\n",
              "       [0.1990896 ],\n",
              "       [0.58820784],\n",
              "       [0.387741  ],\n",
              "       [0.64122087],\n",
              "       [0.7480175 ],\n",
              "       [0.20485178],\n",
              "       [0.606827  ],\n",
              "       [0.6738864 ],\n",
              "       [0.40129355],\n",
              "       [0.771063  ],\n",
              "       [0.45195186],\n",
              "       [0.42561245],\n",
              "       [0.17445685],\n",
              "       [0.3950045 ],\n",
              "       [0.6458992 ],\n",
              "       [0.12500317],\n",
              "       [0.22582103],\n",
              "       [0.31534234],\n",
              "       [0.7752076 ],\n",
              "       [0.606363  ],\n",
              "       [0.47629842],\n",
              "       [0.8000867 ],\n",
              "       [0.319272  ],\n",
              "       [0.24254997],\n",
              "       [0.7662994 ],\n",
              "       [0.66844726],\n",
              "       [0.6685223 ],\n",
              "       [0.72956574],\n",
              "       [0.17382425],\n",
              "       [0.63906765],\n",
              "       [0.18762921],\n",
              "       [0.6140245 ],\n",
              "       [0.26654333],\n",
              "       [0.73727536],\n",
              "       [0.18394595],\n",
              "       [0.21266867],\n",
              "       [0.18194504],\n",
              "       [0.6167469 ],\n",
              "       [0.31727862],\n",
              "       [0.32493076],\n",
              "       [0.30636802],\n",
              "       [0.5749748 ],\n",
              "       [0.7690651 ],\n",
              "       [0.60040736],\n",
              "       [0.6529667 ],\n",
              "       [0.6626074 ],\n",
              "       [0.46904767],\n",
              "       [0.28053537],\n",
              "       [0.25435013],\n",
              "       [0.6975491 ],\n",
              "       [0.23002392],\n",
              "       [0.12393463],\n",
              "       [0.44370732],\n",
              "       [0.2883379 ],\n",
              "       [0.18835422],\n",
              "       [0.6844293 ],\n",
              "       [0.73989564],\n",
              "       [0.624794  ],\n",
              "       [0.8708644 ],\n",
              "       [0.8105521 ],\n",
              "       [0.22142603],\n",
              "       [0.42187473],\n",
              "       [0.56029177],\n",
              "       [0.77603424],\n",
              "       [0.8025733 ],\n",
              "       [0.15150876],\n",
              "       [0.29012373],\n",
              "       [0.4943307 ],\n",
              "       [0.858683  ],\n",
              "       [0.8422599 ],\n",
              "       [0.34322855],\n",
              "       [0.26865175],\n",
              "       [0.76345754],\n",
              "       [0.12367672],\n",
              "       [0.19001685],\n",
              "       [0.7780074 ],\n",
              "       [0.61517423],\n",
              "       [0.44232628],\n",
              "       [0.44031054],\n",
              "       [0.6769433 ],\n",
              "       [0.77668756],\n",
              "       [0.8354376 ],\n",
              "       [0.15380651],\n",
              "       [0.15901528],\n",
              "       [0.481686  ],\n",
              "       [0.25438794],\n",
              "       [0.29696247],\n",
              "       [0.7016465 ],\n",
              "       [0.09525129],\n",
              "       [0.483372  ],\n",
              "       [0.30672607],\n",
              "       [0.1759108 ],\n",
              "       [0.4283669 ],\n",
              "       [0.497024  ],\n",
              "       [0.4671355 ],\n",
              "       [0.7812285 ],\n",
              "       [0.37551796],\n",
              "       [0.4009854 ],\n",
              "       [0.3137451 ],\n",
              "       [0.3229101 ],\n",
              "       [0.486991  ],\n",
              "       [0.6961679 ],\n",
              "       [0.2398279 ],\n",
              "       [0.5322898 ],\n",
              "       [0.79363626],\n",
              "       [0.12602296],\n",
              "       [0.3603934 ],\n",
              "       [0.7183277 ],\n",
              "       [0.21735334],\n",
              "       [0.6432685 ],\n",
              "       [0.2858537 ],\n",
              "       [0.80301255],\n",
              "       [0.2897398 ],\n",
              "       [0.25270727],\n",
              "       [0.15563712],\n",
              "       [0.21898383],\n",
              "       [0.4002679 ],\n",
              "       [0.42818245],\n",
              "       [0.74536437],\n",
              "       [0.24442866],\n",
              "       [0.8298937 ],\n",
              "       [0.51735705],\n",
              "       [0.6279794 ],\n",
              "       [0.74066406],\n",
              "       [0.47996438],\n",
              "       [0.37920794],\n",
              "       [0.56320995],\n",
              "       [0.77178556],\n",
              "       [0.11000086],\n",
              "       [0.4741117 ],\n",
              "       [0.2429278 ],\n",
              "       [0.3517756 ],\n",
              "       [0.5863298 ],\n",
              "       [0.72057897],\n",
              "       [0.6291718 ],\n",
              "       [0.6906043 ],\n",
              "       [0.20186643],\n",
              "       [0.18909934],\n",
              "       [0.57423097],\n",
              "       [0.2540205 ],\n",
              "       [0.16518393],\n",
              "       [0.22708148],\n",
              "       [0.29723603],\n",
              "       [0.5626581 ],\n",
              "       [0.3200874 ],\n",
              "       [0.46016195],\n",
              "       [0.39564282],\n",
              "       [0.38673565],\n",
              "       [0.35649678],\n",
              "       [0.42064285],\n",
              "       [0.5527864 ],\n",
              "       [0.8199329 ],\n",
              "       [0.72596323],\n",
              "       [0.6471485 ],\n",
              "       [0.6413574 ],\n",
              "       [0.6287108 ],\n",
              "       [0.3171659 ],\n",
              "       [0.6486627 ],\n",
              "       [0.15748747],\n",
              "       [0.7934202 ],\n",
              "       [0.16778469],\n",
              "       [0.40197828],\n",
              "       [0.5899547 ],\n",
              "       [0.14121674],\n",
              "       [0.20958379],\n",
              "       [0.48318452],\n",
              "       [0.7954382 ],\n",
              "       [0.7756316 ],\n",
              "       [0.6089392 ],\n",
              "       [0.25839767],\n",
              "       [0.6322208 ],\n",
              "       [0.6155088 ],\n",
              "       [0.21249485],\n",
              "       [0.2958017 ],\n",
              "       [0.65575296],\n",
              "       [0.61961246],\n",
              "       [0.8195823 ],\n",
              "       [0.44007212],\n",
              "       [0.4473348 ],\n",
              "       [0.3747709 ],\n",
              "       [0.37155432],\n",
              "       [0.6056046 ],\n",
              "       [0.5847736 ],\n",
              "       [0.5037654 ],\n",
              "       [0.19891253],\n",
              "       [0.2095046 ],\n",
              "       [0.7598052 ],\n",
              "       [0.18096694],\n",
              "       [0.1691971 ],\n",
              "       [0.8261881 ],\n",
              "       [0.4222847 ],\n",
              "       [0.1695982 ],\n",
              "       [0.54235864],\n",
              "       [0.15750715],\n",
              "       [0.38089648],\n",
              "       [0.43256643],\n",
              "       [0.5837256 ],\n",
              "       [0.12488447],\n",
              "       [0.413803  ],\n",
              "       [0.7887274 ],\n",
              "       [0.32692274],\n",
              "       [0.7348497 ],\n",
              "       [0.7699352 ],\n",
              "       [0.15215366],\n",
              "       [0.22515623],\n",
              "       [0.21962675],\n",
              "       [0.74204206],\n",
              "       [0.41304556],\n",
              "       [0.78353846],\n",
              "       [0.30034292],\n",
              "       [0.48689038],\n",
              "       [0.2851316 ],\n",
              "       [0.19638611],\n",
              "       [0.6040196 ],\n",
              "       [0.23684324],\n",
              "       [0.7772698 ],\n",
              "       [0.2169549 ],\n",
              "       [0.30229467],\n",
              "       [0.82867366],\n",
              "       [0.36991775],\n",
              "       [0.17935231],\n",
              "       [0.4974581 ],\n",
              "       [0.18714207],\n",
              "       [0.59493375],\n",
              "       [0.880659  ],\n",
              "       [0.34603876],\n",
              "       [0.87832415],\n",
              "       [0.28133726],\n",
              "       [0.580115  ],\n",
              "       [0.32435855],\n",
              "       [0.645011  ],\n",
              "       [0.4928064 ],\n",
              "       [0.47311723],\n",
              "       [0.13738817],\n",
              "       [0.69693744],\n",
              "       [0.71479183],\n",
              "       [0.49474108],\n",
              "       [0.6387925 ],\n",
              "       [0.7697664 ],\n",
              "       [0.12936912],\n",
              "       [0.5545586 ],\n",
              "       [0.4094492 ],\n",
              "       [0.599451  ],\n",
              "       [0.25500137],\n",
              "       [0.63322747],\n",
              "       [0.37356997],\n",
              "       [0.5735791 ],\n",
              "       [0.29934517],\n",
              "       [0.3339087 ],\n",
              "       [0.467762  ],\n",
              "       [0.18241408],\n",
              "       [0.4958887 ],\n",
              "       [0.38122627],\n",
              "       [0.7214402 ],\n",
              "       [0.857265  ],\n",
              "       [0.16844098],\n",
              "       [0.32574052],\n",
              "       [0.20996104],\n",
              "       [0.34237963],\n",
              "       [0.37112126],\n",
              "       [0.17420043],\n",
              "       [0.7314101 ],\n",
              "       [0.22515778],\n",
              "       [0.36439267],\n",
              "       [0.23948534],\n",
              "       [0.25204417],\n",
              "       [0.65282863],\n",
              "       [0.28915098],\n",
              "       [0.22999577],\n",
              "       [0.28198156],\n",
              "       [0.31164625],\n",
              "       [0.38522184],\n",
              "       [0.80655193],\n",
              "       [0.48405382],\n",
              "       [0.23708956],\n",
              "       [0.34680814],\n",
              "       [0.25027618],\n",
              "       [0.09817619],\n",
              "       [0.77517575],\n",
              "       [0.46633846],\n",
              "       [0.59539825],\n",
              "       [0.6036986 ],\n",
              "       [0.29135674],\n",
              "       [0.48092818],\n",
              "       [0.46503633],\n",
              "       [0.14653517],\n",
              "       [0.5054664 ],\n",
              "       [0.64018655],\n",
              "       [0.31944516],\n",
              "       [0.7759124 ],\n",
              "       [0.12805301],\n",
              "       [0.41165543],\n",
              "       [0.35177556],\n",
              "       [0.1518353 ],\n",
              "       [0.78591233],\n",
              "       [0.77938557],\n",
              "       [0.34836656],\n",
              "       [0.25015154],\n",
              "       [0.81149834],\n",
              "       [0.6562546 ],\n",
              "       [0.6430919 ],\n",
              "       [0.6078396 ],\n",
              "       [0.6367465 ],\n",
              "       [0.3894799 ],\n",
              "       [0.36725482],\n",
              "       [0.50856054],\n",
              "       [0.7126709 ],\n",
              "       [0.2780641 ],\n",
              "       [0.44472823],\n",
              "       [0.42728755],\n",
              "       [0.50022095],\n",
              "       [0.20820327],\n",
              "       [0.25576112],\n",
              "       [0.33848858],\n",
              "       [0.24222516],\n",
              "       [0.309256  ],\n",
              "       [0.64659256],\n",
              "       [0.11791006],\n",
              "       [0.18849765],\n",
              "       [0.26014552],\n",
              "       [0.4488498 ],\n",
              "       [0.14634846],\n",
              "       [0.60210574],\n",
              "       [0.16870572],\n",
              "       [0.520383  ],\n",
              "       [0.21770132],\n",
              "       [0.17179273],\n",
              "       [0.656443  ],\n",
              "       [0.2825503 ],\n",
              "       [0.33070663],\n",
              "       [0.251825  ],\n",
              "       [0.20770662],\n",
              "       [0.7792678 ],\n",
              "       [0.43281522],\n",
              "       [0.25313413],\n",
              "       [0.75585467],\n",
              "       [0.68681943],\n",
              "       [0.70744795],\n",
              "       [0.8767616 ],\n",
              "       [0.8379458 ],\n",
              "       [0.2675198 ],\n",
              "       [0.28696272],\n",
              "       [0.12605642],\n",
              "       [0.5177589 ],\n",
              "       [0.6684615 ],\n",
              "       [0.5088329 ],\n",
              "       [0.42265245],\n",
              "       [0.28921688],\n",
              "       [0.49175474],\n",
              "       [0.45666847],\n",
              "       [0.45492753],\n",
              "       [0.30402574],\n",
              "       [0.300955  ],\n",
              "       [0.23173533],\n",
              "       [0.23004125],\n",
              "       [0.518689  ],\n",
              "       [0.7471522 ],\n",
              "       [0.21507429],\n",
              "       [0.7796919 ],\n",
              "       [0.6326184 ],\n",
              "       [0.23262422],\n",
              "       [0.27688742],\n",
              "       [0.20857798],\n",
              "       [0.7085082 ],\n",
              "       [0.5485865 ],\n",
              "       [0.3759979 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_preds=tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx3NjhggoY20",
        "outputId": "0cc1cd41-be48-4fe5-d788-5b520b1e4d9a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results=calculate_results(y_true=val_labels,\n",
        "                  y_pred=model_6_preds)"
      ],
      "metadata": {
        "id": "SUaDolUGoi1x"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04jMSzwToqhb",
        "outputId": "b82ea3a3-a5b8-4b15-97a8-d39207aee72c"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.52755905511812,\n",
              " 'precision': 0.7960691940776511,\n",
              " 'recall': 0.7952755905511811,\n",
              " 'f1-score': 0.7940558055501543}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKnM52waouVz",
        "outputId": "652e4fa7-be44-4c15-fc97-c530ee3fa2db"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create moled using the sequential api\n",
        "model_6=tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64,activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "], name='mode_6_use')\n",
        "\n",
        "#Complie\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_6.summary()"
      ],
      "metadata": {
        "id": "qBIk9FMvove3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34375b29-bc7b-4d96-ad19-957d7f1e34d3"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mode_6_use\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train a classifier on top of pretrianed embeddings\n",
        "history_model_6=model_6.fit(train_sentences,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_sentences, val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                   experiment_name=\"tf_hub_sentnece_encoder\")])"
      ],
      "metadata": {
        "id": "4pfFbmOklTgu",
        "outputId": "2c9fe191-8bae-4bff-94bc-54a181b2aa9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentnece_encoder/20230617-042806\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 16ms/step - loss: 0.5068 - accuracy: 0.7892 - val_loss: 0.4488 - val_accuracy: 0.8058\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.4147 - accuracy: 0.8164 - val_loss: 0.4439 - val_accuracy: 0.8058\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.4018 - accuracy: 0.8225 - val_loss: 0.4373 - val_accuracy: 0.8058\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 26ms/step - loss: 0.3932 - accuracy: 0.8244 - val_loss: 0.4298 - val_accuracy: 0.8150\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.3869 - accuracy: 0.8305 - val_loss: 0.4310 - val_accuracy: 0.8031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions\n",
        "model_6_pred_probs=model_6.predict(val_sentences)\n",
        "model_6_pred_probs"
      ],
      "metadata": {
        "id": "RTJTfrMhlazT",
        "outputId": "4d9af6ef-943e-4b56-bf9e-fddac930a23b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.21460137],\n",
              "       [0.80408376],\n",
              "       [0.99036473],\n",
              "       [0.21725105],\n",
              "       [0.81787544],\n",
              "       [0.79465646],\n",
              "       [0.98576593],\n",
              "       [0.9825598 ],\n",
              "       [0.96188533],\n",
              "       [0.11204107],\n",
              "       [0.7053587 ],\n",
              "       [0.5560671 ],\n",
              "       [0.20420058],\n",
              "       [0.6305109 ],\n",
              "       [0.3312177 ],\n",
              "       [0.03024562],\n",
              "       [0.4294214 ],\n",
              "       [0.69035375],\n",
              "       [0.45694584],\n",
              "       [0.35547858],\n",
              "       [0.94014686],\n",
              "       [0.15828341],\n",
              "       [0.4892266 ],\n",
              "       [0.0290686 ],\n",
              "       [0.907792  ],\n",
              "       [0.9780467 ],\n",
              "       [0.05924843],\n",
              "       [0.12007301],\n",
              "       [0.13013509],\n",
              "       [0.3931055 ],\n",
              "       [0.5243415 ],\n",
              "       [0.945002  ],\n",
              "       [0.43649933],\n",
              "       [0.3826821 ],\n",
              "       [0.5989344 ],\n",
              "       [0.12010672],\n",
              "       [0.9851944 ],\n",
              "       [0.05802093],\n",
              "       [0.03859064],\n",
              "       [0.9900628 ],\n",
              "       [0.0757704 ],\n",
              "       [0.31174463],\n",
              "       [0.5198171 ],\n",
              "       [0.6231258 ],\n",
              "       [0.2487756 ],\n",
              "       [0.9748583 ],\n",
              "       [0.45864642],\n",
              "       [0.974287  ],\n",
              "       [0.7174363 ],\n",
              "       [0.8988781 ],\n",
              "       [0.06610862],\n",
              "       [0.73674685],\n",
              "       [0.21500081],\n",
              "       [0.05610743],\n",
              "       [0.12148453],\n",
              "       [0.03976947],\n",
              "       [0.15506731],\n",
              "       [0.90790397],\n",
              "       [0.13462722],\n",
              "       [0.05927817],\n",
              "       [0.0879828 ],\n",
              "       [0.98163694],\n",
              "       [0.9797688 ],\n",
              "       [0.09055679],\n",
              "       [0.94672036],\n",
              "       [0.97135675],\n",
              "       [0.7767473 ],\n",
              "       [0.19453387],\n",
              "       [0.07642486],\n",
              "       [0.53215855],\n",
              "       [0.12674254],\n",
              "       [0.09168041],\n",
              "       [0.79871374],\n",
              "       [0.06079949],\n",
              "       [0.0283689 ],\n",
              "       [0.48730767],\n",
              "       [0.19377664],\n",
              "       [0.32446218],\n",
              "       [0.06561716],\n",
              "       [0.7763174 ],\n",
              "       [0.81825775],\n",
              "       [0.6035023 ],\n",
              "       [0.94431067],\n",
              "       [0.10448021],\n",
              "       [0.7199491 ],\n",
              "       [0.72307444],\n",
              "       [0.0893014 ],\n",
              "       [0.17985506],\n",
              "       [0.9897996 ],\n",
              "       [0.91456723],\n",
              "       [0.997145  ],\n",
              "       [0.03842969],\n",
              "       [0.10694353],\n",
              "       [0.02437978],\n",
              "       [0.9704062 ],\n",
              "       [0.78042436],\n",
              "       [0.9758639 ],\n",
              "       [0.91173106],\n",
              "       [0.9839803 ],\n",
              "       [0.95276576],\n",
              "       [0.95895135],\n",
              "       [0.1900708 ],\n",
              "       [0.20527402],\n",
              "       [0.9919991 ],\n",
              "       [0.9840904 ],\n",
              "       [0.03986995],\n",
              "       [0.8887527 ],\n",
              "       [0.803164  ],\n",
              "       [0.15010157],\n",
              "       [0.86719453],\n",
              "       [0.13812862],\n",
              "       [0.0569911 ],\n",
              "       [0.2987949 ],\n",
              "       [0.34600472],\n",
              "       [0.2122733 ],\n",
              "       [0.26589856],\n",
              "       [0.52193713],\n",
              "       [0.65421176],\n",
              "       [0.802152  ],\n",
              "       [0.83237964],\n",
              "       [0.94251543],\n",
              "       [0.15562801],\n",
              "       [0.6666843 ],\n",
              "       [0.8470287 ],\n",
              "       [0.61881965],\n",
              "       [0.5121778 ],\n",
              "       [0.19142944],\n",
              "       [0.1106691 ],\n",
              "       [0.15369645],\n",
              "       [0.40864184],\n",
              "       [0.12427688],\n",
              "       [0.95596355],\n",
              "       [0.9713741 ],\n",
              "       [0.97777116],\n",
              "       [0.80828047],\n",
              "       [0.24938123],\n",
              "       [0.9693496 ],\n",
              "       [0.5048227 ],\n",
              "       [0.5622329 ],\n",
              "       [0.15722945],\n",
              "       [0.9794158 ],\n",
              "       [0.17106861],\n",
              "       [0.5965871 ],\n",
              "       [0.5284604 ],\n",
              "       [0.8280045 ],\n",
              "       [0.49965632],\n",
              "       [0.04301592],\n",
              "       [0.10250866],\n",
              "       [0.15888983],\n",
              "       [0.940355  ],\n",
              "       [0.37944776],\n",
              "       [0.06485943],\n",
              "       [0.6227333 ],\n",
              "       [0.06741532],\n",
              "       [0.5127727 ],\n",
              "       [0.862961  ],\n",
              "       [0.70746684],\n",
              "       [0.0739485 ],\n",
              "       [0.9560397 ],\n",
              "       [0.22652432],\n",
              "       [0.92436063],\n",
              "       [0.09178991],\n",
              "       [0.24061784],\n",
              "       [0.95601314],\n",
              "       [0.07037346],\n",
              "       [0.05136167],\n",
              "       [0.99535996],\n",
              "       [0.22237764],\n",
              "       [0.9313651 ],\n",
              "       [0.17865172],\n",
              "       [0.9868732 ],\n",
              "       [0.4911164 ],\n",
              "       [0.9746361 ],\n",
              "       [0.06199078],\n",
              "       [0.9560953 ],\n",
              "       [0.03807978],\n",
              "       [0.89072675],\n",
              "       [0.59682935],\n",
              "       [0.6909182 ],\n",
              "       [0.9957398 ],\n",
              "       [0.06701631],\n",
              "       [0.68846554],\n",
              "       [0.41628453],\n",
              "       [0.89747745],\n",
              "       [0.93778723],\n",
              "       [0.34613076],\n",
              "       [0.16980675],\n",
              "       [0.9830747 ],\n",
              "       [0.37951106],\n",
              "       [0.10402316],\n",
              "       [0.42266515],\n",
              "       [0.96480256],\n",
              "       [0.08304913],\n",
              "       [0.17317188],\n",
              "       [0.12321345],\n",
              "       [0.09517298],\n",
              "       [0.1248366 ],\n",
              "       [0.2651654 ],\n",
              "       [0.09002879],\n",
              "       [0.06359159],\n",
              "       [0.18912889],\n",
              "       [0.9671303 ],\n",
              "       [0.8687576 ],\n",
              "       [0.25653535],\n",
              "       [0.12059878],\n",
              "       [0.9874937 ],\n",
              "       [0.3435188 ],\n",
              "       [0.86627984],\n",
              "       [0.9368501 ],\n",
              "       [0.8425937 ],\n",
              "       [0.04284725],\n",
              "       [0.9773926 ],\n",
              "       [0.07088883],\n",
              "       [0.11778897],\n",
              "       [0.03166774],\n",
              "       [0.04811606],\n",
              "       [0.91598   ],\n",
              "       [0.944568  ],\n",
              "       [0.74700725],\n",
              "       [0.06603463],\n",
              "       [0.6032606 ],\n",
              "       [0.06717644],\n",
              "       [0.11679409],\n",
              "       [0.22604413],\n",
              "       [0.9906025 ],\n",
              "       [0.15234368],\n",
              "       [0.26957202],\n",
              "       [0.96920645],\n",
              "       [0.7031045 ],\n",
              "       [0.31883428],\n",
              "       [0.857448  ],\n",
              "       [0.18650085],\n",
              "       [0.95767933],\n",
              "       [0.05630032],\n",
              "       [0.4597    ],\n",
              "       [0.60649353],\n",
              "       [0.4234921 ],\n",
              "       [0.6487913 ],\n",
              "       [0.9828591 ],\n",
              "       [0.04636021],\n",
              "       [0.72975063],\n",
              "       [0.30853686],\n",
              "       [0.98304856],\n",
              "       [0.9446491 ],\n",
              "       [0.04570227],\n",
              "       [0.2093364 ],\n",
              "       [0.9376015 ],\n",
              "       [0.23678279],\n",
              "       [0.1131808 ],\n",
              "       [0.7881781 ],\n",
              "       [0.12461276],\n",
              "       [0.856424  ],\n",
              "       [0.04230265],\n",
              "       [0.6484164 ],\n",
              "       [0.9223319 ],\n",
              "       [0.22544509],\n",
              "       [0.82632667],\n",
              "       [0.9954483 ],\n",
              "       [0.422541  ],\n",
              "       [0.13744622],\n",
              "       [0.9586657 ],\n",
              "       [0.1207523 ],\n",
              "       [0.20876345],\n",
              "       [0.9638758 ],\n",
              "       [0.9162653 ],\n",
              "       [0.7756441 ],\n",
              "       [0.9437304 ],\n",
              "       [0.10006215],\n",
              "       [0.16304308],\n",
              "       [0.09267878],\n",
              "       [0.12531671],\n",
              "       [0.4223382 ],\n",
              "       [0.9235547 ],\n",
              "       [0.11350422],\n",
              "       [0.43888834],\n",
              "       [0.95729953],\n",
              "       [0.16050269],\n",
              "       [0.08508775],\n",
              "       [0.98526925],\n",
              "       [0.522629  ],\n",
              "       [0.11995585],\n",
              "       [0.13191767],\n",
              "       [0.9775557 ],\n",
              "       [0.46171534],\n",
              "       [0.22369306],\n",
              "       [0.7227983 ],\n",
              "       [0.81621283],\n",
              "       [0.19816507],\n",
              "       [0.8361526 ],\n",
              "       [0.04669131],\n",
              "       [0.8752784 ],\n",
              "       [0.6211274 ],\n",
              "       [0.35493237],\n",
              "       [0.76353437],\n",
              "       [0.05950931],\n",
              "       [0.908311  ],\n",
              "       [0.32340595],\n",
              "       [0.98738503],\n",
              "       [0.08322339],\n",
              "       [0.5746235 ],\n",
              "       [0.39467674],\n",
              "       [0.14678544],\n",
              "       [0.08511544],\n",
              "       [0.7882087 ],\n",
              "       [0.27570134],\n",
              "       [0.2172584 ],\n",
              "       [0.10333122],\n",
              "       [0.7758849 ],\n",
              "       [0.04835659],\n",
              "       [0.02990312],\n",
              "       [0.14238507],\n",
              "       [0.9701398 ],\n",
              "       [0.76039916],\n",
              "       [0.25463066],\n",
              "       [0.9729898 ],\n",
              "       [0.08077982],\n",
              "       [0.94823635],\n",
              "       [0.7486147 ],\n",
              "       [0.02930669],\n",
              "       [0.3027196 ],\n",
              "       [0.09375704],\n",
              "       [0.15020175],\n",
              "       [0.9792687 ],\n",
              "       [0.07167217],\n",
              "       [0.80484   ],\n",
              "       [0.07032824],\n",
              "       [0.2105043 ],\n",
              "       [0.8884863 ],\n",
              "       [0.06522848],\n",
              "       [0.87796015],\n",
              "       [0.85947233],\n",
              "       [0.1259361 ],\n",
              "       [0.950793  ],\n",
              "       [0.24674585],\n",
              "       [0.20288232],\n",
              "       [0.6416086 ],\n",
              "       [0.05763626],\n",
              "       [0.47256237],\n",
              "       [0.550066  ],\n",
              "       [0.58242965],\n",
              "       [0.12685229],\n",
              "       [0.21066204],\n",
              "       [0.9298946 ],\n",
              "       [0.9746482 ],\n",
              "       [0.788282  ],\n",
              "       [0.2229583 ],\n",
              "       [0.3654965 ],\n",
              "       [0.12137228],\n",
              "       [0.07565466],\n",
              "       [0.18493024],\n",
              "       [0.21751755],\n",
              "       [0.46741232],\n",
              "       [0.09016493],\n",
              "       [0.08241126],\n",
              "       [0.5898006 ],\n",
              "       [0.04103679],\n",
              "       [0.97037965],\n",
              "       [0.97154385],\n",
              "       [0.84945554],\n",
              "       [0.7483386 ],\n",
              "       [0.41392642],\n",
              "       [0.07973863],\n",
              "       [0.96620387],\n",
              "       [0.6183516 ],\n",
              "       [0.51825404],\n",
              "       [0.05220596],\n",
              "       [0.20076244],\n",
              "       [0.07989591],\n",
              "       [0.20609425],\n",
              "       [0.034547  ],\n",
              "       [0.7814196 ],\n",
              "       [0.04018736],\n",
              "       [0.16310154],\n",
              "       [0.21680139],\n",
              "       [0.07604976],\n",
              "       [0.08258347],\n",
              "       [0.14183155],\n",
              "       [0.1310739 ],\n",
              "       [0.16134323],\n",
              "       [0.48189956],\n",
              "       [0.96507794],\n",
              "       [0.8052558 ],\n",
              "       [0.12922788],\n",
              "       [0.21376446],\n",
              "       [0.6775274 ],\n",
              "       [0.9653185 ],\n",
              "       [0.4863772 ],\n",
              "       [0.3654649 ],\n",
              "       [0.99328125],\n",
              "       [0.26876554],\n",
              "       [0.12450363],\n",
              "       [0.46055865],\n",
              "       [0.05551013],\n",
              "       [0.86285967],\n",
              "       [0.76922363],\n",
              "       [0.9926466 ],\n",
              "       [0.16114292],\n",
              "       [0.7404446 ],\n",
              "       [0.31780964],\n",
              "       [0.49519047],\n",
              "       [0.9753872 ],\n",
              "       [0.17232694],\n",
              "       [0.70810235],\n",
              "       [0.9309655 ],\n",
              "       [0.09079151],\n",
              "       [0.96038043],\n",
              "       [0.26992795],\n",
              "       [0.7744768 ],\n",
              "       [0.05346933],\n",
              "       [0.28484622],\n",
              "       [0.9018653 ],\n",
              "       [0.04119698],\n",
              "       [0.08680059],\n",
              "       [0.5457642 ],\n",
              "       [0.96512836],\n",
              "       [0.7839828 ],\n",
              "       [0.3246531 ],\n",
              "       [0.9621136 ],\n",
              "       [0.19768567],\n",
              "       [0.10262655],\n",
              "       [0.9722802 ],\n",
              "       [0.90435296],\n",
              "       [0.80411136],\n",
              "       [0.79723644],\n",
              "       [0.04365337],\n",
              "       [0.63880175],\n",
              "       [0.15500371],\n",
              "       [0.88502055],\n",
              "       [0.52623826],\n",
              "       [0.92588085],\n",
              "       [0.08857937],\n",
              "       [0.06740799],\n",
              "       [0.13619003],\n",
              "       [0.64240193],\n",
              "       [0.37381425],\n",
              "       [0.35085618],\n",
              "       [0.53498405],\n",
              "       [0.40001878],\n",
              "       [0.9874396 ],\n",
              "       [0.7772771 ],\n",
              "       [0.70884764],\n",
              "       [0.78476214],\n",
              "       [0.3386883 ],\n",
              "       [0.11226919],\n",
              "       [0.18870154],\n",
              "       [0.80726874],\n",
              "       [0.05511255],\n",
              "       [0.05299964],\n",
              "       [0.24669933],\n",
              "       [0.21837626],\n",
              "       [0.04513144],\n",
              "       [0.90576816],\n",
              "       [0.94434756],\n",
              "       [0.88175416],\n",
              "       [0.974584  ],\n",
              "       [0.9883813 ],\n",
              "       [0.07018866],\n",
              "       [0.20549731],\n",
              "       [0.5219749 ],\n",
              "       [0.8994203 ],\n",
              "       [0.9844919 ],\n",
              "       [0.07991582],\n",
              "       [0.13394853],\n",
              "       [0.47387332],\n",
              "       [0.9915712 ],\n",
              "       [0.95762104],\n",
              "       [0.2241525 ],\n",
              "       [0.22810945],\n",
              "       [0.9433999 ],\n",
              "       [0.03423743],\n",
              "       [0.20024864],\n",
              "       [0.92401016],\n",
              "       [0.6203909 ],\n",
              "       [0.3352415 ],\n",
              "       [0.8139541 ],\n",
              "       [0.6838877 ],\n",
              "       [0.876311  ],\n",
              "       [0.98424214],\n",
              "       [0.09370957],\n",
              "       [0.066153  ],\n",
              "       [0.20197758],\n",
              "       [0.08151993],\n",
              "       [0.44944382],\n",
              "       [0.90831923],\n",
              "       [0.0431041 ],\n",
              "       [0.73023903],\n",
              "       [0.07202259],\n",
              "       [0.09659645],\n",
              "       [0.38428214],\n",
              "       [0.5047532 ],\n",
              "       [0.39823613],\n",
              "       [0.9740819 ],\n",
              "       [0.22549461],\n",
              "       [0.08801273],\n",
              "       [0.14609653],\n",
              "       [0.15334359],\n",
              "       [0.5620432 ],\n",
              "       [0.89024466],\n",
              "       [0.1168808 ],\n",
              "       [0.9020518 ],\n",
              "       [0.9744689 ],\n",
              "       [0.0569176 ],\n",
              "       [0.46200815],\n",
              "       [0.8271878 ],\n",
              "       [0.23611248],\n",
              "       [0.73640674],\n",
              "       [0.09846231],\n",
              "       [0.96931016],\n",
              "       [0.22570077],\n",
              "       [0.18262784],\n",
              "       [0.13567561],\n",
              "       [0.06440903],\n",
              "       [0.21081561],\n",
              "       [0.73843205],\n",
              "       [0.9627185 ],\n",
              "       [0.18048339],\n",
              "       [0.9809269 ],\n",
              "       [0.74211794],\n",
              "       [0.67909205],\n",
              "       [0.9858662 ],\n",
              "       [0.5177397 ],\n",
              "       [0.5117545 ],\n",
              "       [0.89032036],\n",
              "       [0.9728088 ],\n",
              "       [0.06601083],\n",
              "       [0.2057595 ],\n",
              "       [0.06818675],\n",
              "       [0.25095436],\n",
              "       [0.46292824],\n",
              "       [0.9432593 ],\n",
              "       [0.7999109 ],\n",
              "       [0.9703691 ],\n",
              "       [0.09430136],\n",
              "       [0.03998469],\n",
              "       [0.89686865],\n",
              "       [0.10051791],\n",
              "       [0.07340886],\n",
              "       [0.0592498 ],\n",
              "       [0.14788789],\n",
              "       [0.50368696],\n",
              "       [0.28755912],\n",
              "       [0.60786104],\n",
              "       [0.24103135],\n",
              "       [0.16104311],\n",
              "       [0.14620373],\n",
              "       [0.21799736],\n",
              "       [0.4047029 ],\n",
              "       [0.96324944],\n",
              "       [0.8297275 ],\n",
              "       [0.78103405],\n",
              "       [0.9440464 ],\n",
              "       [0.96297944],\n",
              "       [0.06127163],\n",
              "       [0.88195693],\n",
              "       [0.07784671],\n",
              "       [0.9848818 ],\n",
              "       [0.06064613],\n",
              "       [0.26737475],\n",
              "       [0.2732632 ],\n",
              "       [0.04752352],\n",
              "       [0.19745225],\n",
              "       [0.32768503],\n",
              "       [0.96470433],\n",
              "       [0.88488847],\n",
              "       [0.87021625],\n",
              "       [0.08222035],\n",
              "       [0.7688884 ],\n",
              "       [0.7891886 ],\n",
              "       [0.08192197],\n",
              "       [0.27204165],\n",
              "       [0.88007486],\n",
              "       [0.74689114],\n",
              "       [0.9888672 ],\n",
              "       [0.31197304],\n",
              "       [0.17155078],\n",
              "       [0.7038247 ],\n",
              "       [0.10650675],\n",
              "       [0.8045207 ],\n",
              "       [0.93893874],\n",
              "       [0.28199056],\n",
              "       [0.06900712],\n",
              "       [0.06666181],\n",
              "       [0.959267  ],\n",
              "       [0.23643751],\n",
              "       [0.06730995],\n",
              "       [0.9761345 ],\n",
              "       [0.17819427],\n",
              "       [0.11733251],\n",
              "       [0.7567229 ],\n",
              "       [0.02713358],\n",
              "       [0.30745074],\n",
              "       [0.3902218 ],\n",
              "       [0.654979  ],\n",
              "       [0.01359878],\n",
              "       [0.34547418],\n",
              "       [0.96743494],\n",
              "       [0.1380055 ],\n",
              "       [0.9561308 ],\n",
              "       [0.98768616],\n",
              "       [0.06061639],\n",
              "       [0.06275035],\n",
              "       [0.05336469],\n",
              "       [0.9579448 ],\n",
              "       [0.5404845 ],\n",
              "       [0.98610467],\n",
              "       [0.09692597],\n",
              "       [0.36802974],\n",
              "       [0.09323945],\n",
              "       [0.06315856],\n",
              "       [0.83791906],\n",
              "       [0.1518158 ],\n",
              "       [0.94691944],\n",
              "       [0.08805852],\n",
              "       [0.2536467 ],\n",
              "       [0.9861346 ],\n",
              "       [0.3628931 ],\n",
              "       [0.07298084],\n",
              "       [0.47166187],\n",
              "       [0.0434937 ],\n",
              "       [0.62829   ],\n",
              "       [0.98735213],\n",
              "       [0.07013699],\n",
              "       [0.99116737],\n",
              "       [0.315783  ],\n",
              "       [0.8439436 ],\n",
              "       [0.15206279],\n",
              "       [0.49939734],\n",
              "       [0.38520467],\n",
              "       [0.9014394 ],\n",
              "       [0.03453221],\n",
              "       [0.6090319 ],\n",
              "       [0.9460219 ],\n",
              "       [0.72199243],\n",
              "       [0.74154276],\n",
              "       [0.93416286],\n",
              "       [0.06979582],\n",
              "       [0.7838984 ],\n",
              "       [0.11745434],\n",
              "       [0.8023666 ],\n",
              "       [0.23744868],\n",
              "       [0.9476034 ],\n",
              "       [0.4374306 ],\n",
              "       [0.67450994],\n",
              "       [0.21619299],\n",
              "       [0.05751747],\n",
              "       [0.7317246 ],\n",
              "       [0.13622838],\n",
              "       [0.16960306],\n",
              "       [0.63590163],\n",
              "       [0.97700536],\n",
              "       [0.9928727 ],\n",
              "       [0.07472331],\n",
              "       [0.06625942],\n",
              "       [0.0713961 ],\n",
              "       [0.15968217],\n",
              "       [0.33296293],\n",
              "       [0.06583643],\n",
              "       [0.98210514],\n",
              "       [0.13143894],\n",
              "       [0.54945976],\n",
              "       [0.10201637],\n",
              "       [0.12619527],\n",
              "       [0.88435006],\n",
              "       [0.13019815],\n",
              "       [0.08867396],\n",
              "       [0.25868744],\n",
              "       [0.09544583],\n",
              "       [0.5106099 ],\n",
              "       [0.98737925],\n",
              "       [0.60364085],\n",
              "       [0.05251213],\n",
              "       [0.18740605],\n",
              "       [0.13027082],\n",
              "       [0.04045061],\n",
              "       [0.95975804],\n",
              "       [0.23938861],\n",
              "       [0.7674911 ],\n",
              "       [0.44337866],\n",
              "       [0.1505514 ],\n",
              "       [0.41243485],\n",
              "       [0.35520515],\n",
              "       [0.06428796],\n",
              "       [0.14332777],\n",
              "       [0.8810862 ],\n",
              "       [0.16608809],\n",
              "       [0.9504009 ],\n",
              "       [0.06095322],\n",
              "       [0.19643548],\n",
              "       [0.25095436],\n",
              "       [0.04074254],\n",
              "       [0.86085284],\n",
              "       [0.9665318 ],\n",
              "       [0.30579096],\n",
              "       [0.08424413],\n",
              "       [0.979908  ],\n",
              "       [0.8141213 ],\n",
              "       [0.89147455],\n",
              "       [0.69564366],\n",
              "       [0.8392241 ],\n",
              "       [0.12085724],\n",
              "       [0.22393881],\n",
              "       [0.30363643],\n",
              "       [0.8263842 ],\n",
              "       [0.08418261],\n",
              "       [0.46690336],\n",
              "       [0.21419924],\n",
              "       [0.40521458],\n",
              "       [0.08759299],\n",
              "       [0.0841158 ],\n",
              "       [0.13947557],\n",
              "       [0.25991336],\n",
              "       [0.30777496],\n",
              "       [0.59027547],\n",
              "       [0.0221184 ],\n",
              "       [0.1064488 ],\n",
              "       [0.20582142],\n",
              "       [0.27309057],\n",
              "       [0.02345329],\n",
              "       [0.7324686 ],\n",
              "       [0.03404424],\n",
              "       [0.6797318 ],\n",
              "       [0.14936444],\n",
              "       [0.2648853 ],\n",
              "       [0.91883045],\n",
              "       [0.07350758],\n",
              "       [0.37442458],\n",
              "       [0.09468794],\n",
              "       [0.07332222],\n",
              "       [0.970511  ],\n",
              "       [0.2640856 ],\n",
              "       [0.2367905 ],\n",
              "       [0.90106297],\n",
              "       [0.9667312 ],\n",
              "       [0.91115177],\n",
              "       [0.99297464],\n",
              "       [0.97400475],\n",
              "       [0.20252389],\n",
              "       [0.18187068],\n",
              "       [0.05704226],\n",
              "       [0.7546061 ],\n",
              "       [0.9131369 ],\n",
              "       [0.60286903],\n",
              "       [0.43334413],\n",
              "       [0.05739985],\n",
              "       [0.47506052],\n",
              "       [0.47277844],\n",
              "       [0.11219809],\n",
              "       [0.22640905],\n",
              "       [0.14825124],\n",
              "       [0.09308397],\n",
              "       [0.2005206 ],\n",
              "       [0.4779761 ],\n",
              "       [0.92270476],\n",
              "       [0.0968819 ],\n",
              "       [0.9396409 ],\n",
              "       [0.7320457 ],\n",
              "       [0.08301689],\n",
              "       [0.14046536],\n",
              "       [0.11115471],\n",
              "       [0.9113644 ],\n",
              "       [0.7608648 ],\n",
              "       [0.11253798]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_preds=tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds"
      ],
      "metadata": {
        "id": "PxblPieZlczA",
        "outputId": "34269779-a99e-4681-be0a-feb15e1e21de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
              "       1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results=calculate_results(y_true=val_labels,\n",
        "                  y_pred=model_6_preds)"
      ],
      "metadata": {
        "id": "1SDDbZUulfzN"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "id": "TMDrz2PHnNDl",
        "outputId": "190be91c-3bce-4266-fc51-ce9c1459eae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.31496062992126,\n",
              " 'precision': 0.8029099795624137,\n",
              " 'recall': 0.8031496062992126,\n",
              " 'f1-score': 0.8028289227004518}"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7 : TF Hub pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer learning really helps whe we dont have a large dataset. We need to see how the model performs on the large dataset"
      ],
      "metadata": {
        "id": "gZGZuUOQli0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create subsets of 10% of the training data\\\n",
        "\n",
        "train_10_percent= train_data_shuffled[[\"text\",\"target\"]].sample(frac=0.1, random_state=42)\n",
        "train_sentences_10_percent=train_10_percent['text'].to_list()\n",
        "train_labels_10_percent=train_10_percent['target'].to_list()\n",
        "len(train_sentences_10_percent),len(train_labels_10_percent)"
      ],
      "metadata": {
        "id": "oxzFTWSFmPBA",
        "outputId": "0e559cfe-124a-47b9-80cb-2d2861a7217a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(761, 761)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_10_percent['target'].value_counts()"
      ],
      "metadata": {
        "id": "rgyEsCKSnKf4",
        "outputId": "21d4b45b-704e-4370-ec7f-a855977a99d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    413\n",
              "1    348\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's build a model same as model 6.\n",
        "#To recreate a model similar to previous model we created, you can use the tf.keras.models.clone_model() method\n",
        "\n",
        "model_7=tf.keras.models.clone_model(model_6)\n",
        "\n",
        "#Compile the model\n",
        "model_7.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history_model_7=model_7.fit(train_sentences_10_percent,\n",
        "                            train_labels_10_percent,\n",
        "                            validation_data=(val_sentences, val_labels),\n",
        "                            epochs=5,\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                   experiment_name='model_7_10_perc_data')])"
      ],
      "metadata": {
        "id": "wwYXsG_znYoO",
        "outputId": "33133c6a-0730-45b2-ea7c-70ea247f8ca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7_10_perc_data/20230617-043836\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 4s 44ms/step - loss: 0.6696 - accuracy: 0.6662 - val_loss: 0.6313 - val_accuracy: 0.7638\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.5981 - accuracy: 0.7648 - val_loss: 0.5509 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.5226 - accuracy: 0.7911 - val_loss: 0.4828 - val_accuracy: 0.8071\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.4662 - accuracy: 0.7924 - val_loss: 0.4395 - val_accuracy: 0.8150\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.4293 - accuracy: 0.8173 - val_loss: 0.4093 - val_accuracy: 0.8189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_pred_probs=model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "id": "nBxa-xlzpbj1",
        "outputId": "ffdd772e-be4e-43b0-bab6-7dab24a75abe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24974789],\n",
              "       [0.797586  ],\n",
              "       [0.91611284],\n",
              "       [0.32423982],\n",
              "       [0.80769235],\n",
              "       [0.838408  ],\n",
              "       [0.9087085 ],\n",
              "       [0.9509621 ],\n",
              "       [0.8295075 ],\n",
              "       [0.0930922 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_preds=tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds"
      ],
      "metadata": {
        "id": "WrxfL0Ahp0Jp",
        "outputId": "7dd3344d-efc7-4c5e-9cd9-20879c5135d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_results=calculate_results(y_true=val_labels,\n",
        "                                  y_pred=model_7_preds)"
      ],
      "metadata": {
        "id": "Wliq98i5p_Dk"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_results"
      ],
      "metadata": {
        "id": "08ZUp0SoqK_P",
        "outputId": "15ce49c5-3879-451b-e0f0-cb894feefffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.88976377952756,\n",
              " 'precision': 0.8189540577687426,\n",
              " 'recall': 0.8188976377952756,\n",
              " 'f1-score': 0.8183542498323134}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "id": "8O0SOdTMqMyR",
        "outputId": "df1e9445-b65e-4104-8dc7-80063e52f620",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 7 outperforms the performance of model_6.\n",
        "\n",
        "Some of the validation data is present inside the training data. That's why we are getting more accuracy on model 7 with less data than the model6 with more data.\n",
        "\n",
        "Do not make data splits which leaks data from validation /test sets into the training set"
      ],
      "metadata": {
        "id": "TabBp1R9qN-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Makin a better dataset split (with no data leakge)\n",
        "train_10_percent_split= int(0.1*len(train_sentences))\n",
        "train_sentences_10_percent=train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent=train_labels[:train_10_percent_split]"
      ],
      "metadata": {
        "id": "YqcjYq2Erm-q"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "metadata": {
        "id": "rqZtaDjAsX7c",
        "outputId": "5e42a94c-7551-43b1-dc36-5d6e6537822e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's build a model same as model 6.\n",
        "#To recreate a model similar to previous model we created, you can use the tf.keras.models.clone_model() method\n",
        "\n",
        "model_7=tf.keras.models.clone_model(model_6)\n",
        "\n",
        "#Compile the model\n",
        "model_7.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history_model_7=model_7.fit(train_sentences_10_percent,\n",
        "                            train_labels_10_percent,\n",
        "                            validation_data=(val_sentences, val_labels),\n",
        "                            epochs=5,\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                   experiment_name='model_7_10_perc_data_correct_split')])"
      ],
      "metadata": {
        "id": "EnITsEIBtD0-",
        "outputId": "967233db-6e92-49d9-c71b-03aa180ab31c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7_10_perc_data_correct_split/20230617-045613\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 48ms/step - loss: 0.6691 - accuracy: 0.6745 - val_loss: 0.6449 - val_accuracy: 0.7415\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.5936 - accuracy: 0.8058 - val_loss: 0.5848 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.5176 - accuracy: 0.8277 - val_loss: 0.5326 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.4570 - accuracy: 0.8263 - val_loss: 0.5005 - val_accuracy: 0.7848\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.4177 - accuracy: 0.8350 - val_loss: 0.4930 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_pred_probs=model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "id": "Wb5lYhqkwvl9",
        "outputId": "5cca8ce8-af57-42fb-f63a-b01d6e9cfd7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17918198],\n",
              "       [0.5934161 ],\n",
              "       [0.9107275 ],\n",
              "       [0.37906504],\n",
              "       [0.5505305 ],\n",
              "       [0.7125918 ],\n",
              "       [0.8928143 ],\n",
              "       [0.8016301 ],\n",
              "       [0.8311622 ],\n",
              "       [0.14826852]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_preds=tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds"
      ],
      "metadata": {
        "id": "duIW21n4wz9n",
        "outputId": "06a6d82d-4be8-4655-a690-ae4f75b36fa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_results=calculate_results(y_true=val_labels,\n",
        "                                  y_pred=model_7_preds)"
      ],
      "metadata": {
        "id": "liOq0Efuw1KB"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare the perf of each of our models\n",
        "all_model_results=pd.DataFrame({\"0_baseline\":baseline_results,\n",
        "                                \"1_simple_dense\":model_1_results,\n",
        "                                \"2_LSTM\": model_2_results,\n",
        "                                \"3_GRU\": model_3_results,\n",
        "                                \"4_bidirectional\":model_4_results,\n",
        "                                \"5_conv1d\":model_5_results,\n",
        "                                \"6_tf_hub_USE_encoder\":model_6_results,\n",
        "                                \"7_tf_hub_USE_encoder_10_ercent\":model_7_results})\n"
      ],
      "metadata": {
        "id": "HdL8ySmntYjg"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results"
      ],
      "metadata": {
        "id": "8ukj8putvTPE",
        "outputId": "fa2f2589-7201-4e38-df6d-ec9c93572efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0_baseline  1_simple_dense     2_LSTM      3_GRU  4_bidirectional  \\\n",
              "accuracy    79.265092       78.740157  77.427822  77.559055        77.821522   \n",
              "precision    0.811139        0.795289   0.775989   0.783585         0.779415   \n",
              "recall       0.792651        0.787402   0.774278   0.775591         0.778215   \n",
              "f1-score     0.786219        0.783476   0.772231   0.771180         0.776506   \n",
              "\n",
              "            5_conv1d  6_tf_hub_USE_encoder  7_tf_hub_USE_encoder_10_ercent  \n",
              "accuracy   75.590551             80.314961                       77.952756  \n",
              "precision   0.755936              0.802910                        0.781951  \n",
              "recall      0.755906              0.803150                        0.779528  \n",
              "f1-score    0.754565              0.802829                        0.777273  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f61df22-9073-4f55-be0d-c4be52ddb59f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0_baseline</th>\n",
              "      <th>1_simple_dense</th>\n",
              "      <th>2_LSTM</th>\n",
              "      <th>3_GRU</th>\n",
              "      <th>4_bidirectional</th>\n",
              "      <th>5_conv1d</th>\n",
              "      <th>6_tf_hub_USE_encoder</th>\n",
              "      <th>7_tf_hub_USE_encoder_10_ercent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>78.740157</td>\n",
              "      <td>77.427822</td>\n",
              "      <td>77.559055</td>\n",
              "      <td>77.821522</td>\n",
              "      <td>75.590551</td>\n",
              "      <td>80.314961</td>\n",
              "      <td>77.952756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.795289</td>\n",
              "      <td>0.775989</td>\n",
              "      <td>0.783585</td>\n",
              "      <td>0.779415</td>\n",
              "      <td>0.755936</td>\n",
              "      <td>0.802910</td>\n",
              "      <td>0.781951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.755906</td>\n",
              "      <td>0.803150</td>\n",
              "      <td>0.779528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.786219</td>\n",
              "      <td>0.783476</td>\n",
              "      <td>0.772231</td>\n",
              "      <td>0.771180</td>\n",
              "      <td>0.776506</td>\n",
              "      <td>0.754565</td>\n",
              "      <td>0.802829</td>\n",
              "      <td>0.777273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f61df22-9073-4f55-be0d-c4be52ddb59f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f61df22-9073-4f55-be0d-c4be52ddb59f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f61df22-9073-4f55-be0d-c4be52ddb59f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results=all_model_results.transpose()"
      ],
      "metadata": {
        "id": "flM0RGQ8vpHX"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results"
      ],
      "metadata": {
        "id": "KEs9q5n2vrqE",
        "outputId": "8b804277-6375-4be5-fd13-3d698fbba0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 accuracy  precision    recall  f1-score\n",
              "0_baseline                      79.265092   0.811139  0.792651  0.786219\n",
              "1_simple_dense                  78.740157   0.795289  0.787402  0.783476\n",
              "2_LSTM                          77.427822   0.775989  0.774278  0.772231\n",
              "3_GRU                           77.559055   0.783585  0.775591  0.771180\n",
              "4_bidirectional                 77.821522   0.779415  0.778215  0.776506\n",
              "5_conv1d                        75.590551   0.755936  0.755906  0.754565\n",
              "6_tf_hub_USE_encoder            80.314961   0.802910  0.803150  0.802829\n",
              "7_tf_hub_USE_encoder_10_ercent  77.952756   0.781951  0.779528  0.777273"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c6d0078-7f6f-4f62-9c60-8f56c77207a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>78.740157</td>\n",
              "      <td>0.795289</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.783476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_LSTM</th>\n",
              "      <td>77.427822</td>\n",
              "      <td>0.775989</td>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.772231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_GRU</th>\n",
              "      <td>77.559055</td>\n",
              "      <td>0.783585</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.771180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.779415</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.776506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>75.590551</td>\n",
              "      <td>0.755936</td>\n",
              "      <td>0.755906</td>\n",
              "      <td>0.754565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_USE_encoder</th>\n",
              "      <td>80.314961</td>\n",
              "      <td>0.802910</td>\n",
              "      <td>0.803150</td>\n",
              "      <td>0.802829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_USE_encoder_10_ercent</th>\n",
              "      <td>77.952756</td>\n",
              "      <td>0.781951</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.777273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c6d0078-7f6f-4f62-9c60-8f56c77207a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c6d0078-7f6f-4f62-9c60-8f56c77207a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c6d0078-7f6f-4f62-9c60-8f56c77207a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduce the accuracy to the same scale as other metrics"
      ],
      "metadata": {
        "id": "6qc7mzeVvuAi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_i3xGd8owTr2"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results.accuracy=all_model_results.accuracy/100"
      ],
      "metadata": {
        "id": "7R6k95ZWv3jj"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results"
      ],
      "metadata": {
        "id": "w1J3gFLswAhU",
        "outputId": "0299067f-c1cf-4dc9-9ee1-7e8b07343fd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                accuracy  precision    recall  f1-score\n",
              "0_baseline                      0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense                  0.787402   0.795289  0.787402  0.783476\n",
              "2_LSTM                          0.774278   0.775989  0.774278  0.772231\n",
              "3_GRU                           0.775591   0.783585  0.775591  0.771180\n",
              "4_bidirectional                 0.778215   0.779415  0.778215  0.776506\n",
              "5_conv1d                        0.755906   0.755936  0.755906  0.754565\n",
              "6_tf_hub_USE_encoder            0.803150   0.802910  0.803150  0.802829\n",
              "7_tf_hub_USE_encoder_10_ercent  0.779528   0.781951  0.779528  0.777273"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04f6ca57-12a6-40e7-847c-9acb3a4ef7dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.795289</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.783476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_LSTM</th>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.775989</td>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.772231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_GRU</th>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.783585</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.771180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.779415</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.776506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.755906</td>\n",
              "      <td>0.755936</td>\n",
              "      <td>0.755906</td>\n",
              "      <td>0.754565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_USE_encoder</th>\n",
              "      <td>0.803150</td>\n",
              "      <td>0.802910</td>\n",
              "      <td>0.803150</td>\n",
              "      <td>0.802829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_USE_encoder_10_ercent</th>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.781951</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.777273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04f6ca57-12a6-40e7-847c-9acb3a4ef7dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04f6ca57-12a6-40e7-847c-9acb3a4ef7dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04f6ca57-12a6-40e7-847c-9acb3a4ef7dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0));"
      ],
      "metadata": {
        "id": "esYeAuTXwB7B",
        "outputId": "adabc814-3501-4258-9181-927e467988b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sort model results by f-1 score\n",
        "all_model_results.sort_values('f1-score', ascending=False)[\"f1-score\"].plot(kind='bar', figsize=(10,7))"
      ],
      "metadata": {
        "id": "H85m5QeiwTPR",
        "outputId": "f38451cc-7bf9-4436-beea-928046159ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 179
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading a saved model\n",
        "\n",
        "There are 2 main formats to save a model in TF\n",
        "* HDF5\n",
        "* SavedModel Format"
      ],
      "metadata": {
        "id": "_eomfkYdxdwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model_6\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "metadata": {
        "id": "eAEJGrUpy1Qe"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "SJ0WPW4zz_Zh"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the model back in hdf5\n",
        "model_6_reloaded= tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                             custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "metadata": {
        "id": "dHxbVu8Yzprc"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How does the loaded model perform\n",
        "model_6_reloaded.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "D_VdaNeq0dLr",
        "outputId": "43b61d90-6cd4-42bf-e02a-0f75a884d61a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 11ms/step - loss: 0.4310 - accuracy: 0.8031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4310455620288849, 0.8031495809555054]"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "id": "mNhpgmuH0seC",
        "outputId": "e55dd999-4641-421d-e999-f259f416e445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.31496062992126,\n",
              " 'precision': 0.8029099795624137,\n",
              " 'recall': 0.8031496062992126,\n",
              " 'f1-score': 0.8028289227004518}"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save to SavedModel Format\n",
        "model_6.save(\"model_6_savedModel_format\")"
      ],
      "metadata": {
        "id": "tpULPO050y1_",
        "outputId": "6d1e1e52-7e4d-430d-f4b8-9226d9493c8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_reloaded_savedmodel= tf.keras.models.load_model(\"model_6_savedModel_format\")"
      ],
      "metadata": {
        "id": "jXfhvZyB1BNX"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate SavedModel Format\n",
        "model_6_reloaded_savedmodel.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "lyBaUd1Y1Trq",
        "outputId": "62eb02a6-d1c0-4cfd-b64b-5b769bbf84a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 20ms/step - loss: 0.4310 - accuracy: 0.8031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4310455322265625, 0.8031495809555054]"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* If our best model still isn't perfect...what examples is it getting wrongs....and what examples is it getting the most wrong\n",
        "\n",
        "E.g. if a sample should have a label of 0 but our model predicts a prediction probab of 0.99 (eally close to 1) and vice versa."
      ],
      "metadata": {
        "id": "LKqMj3a01g2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download a pretrained model from google storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip"
      ],
      "metadata": {
        "id": "EttihI0x2uXN",
        "outputId": "56b042cf-e505-46b2-bfbb-94642d26a3f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-17 05:38:12--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.12.128, 172.217.194.128, 172.253.118.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.12.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M  22.7MB/s    in 54s     \n",
            "\n",
            "2023-06-17 05:39:06 (17.1 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "metadata": {
        "id": "VNpIM3pv3G8V",
        "outputId": "0127e103-b8e7-4dbb-e100-31f2b649582f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained= tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "gsIbQqGY3MGc",
        "outputId": "d1900f71-e7e4-4205-eaa8-a139f67a35ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 11ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions with the loaded model\n",
        "model_6_pretrained_pred_probs=model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretraind_preds=tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretraind_preds[:10]"
      ],
      "metadata": {
        "id": "vL4yYdEZ3nBl",
        "outputId": "bd0edaec-bc24-496d-f5bd-dd836150c4f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dataframe with Validation sentences, validation labels, and best performing model predictions\n",
        "\n",
        "val_df=pd.DataFrame({\"text\":val_sentences,\n",
        "                     \"target\": val_labels,\n",
        "                     \"pred\": model_6_pretraind_preds,\n",
        "                     \"pred_probs\":tf.squeeze(model_6_pred_probs)})"
      ],
      "metadata": {
        "id": "VY_ihdr635cA"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.head()"
      ],
      "metadata": {
        "id": "WkpOYHg64VZu",
        "outputId": "7ecfa86c-91f3-4acc-8271-145e00467e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_probs\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0    0.214601\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0    0.804084\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0    0.990365\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0    0.217251\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0    0.817875"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c50a0fb-c6df-498d-a31e-5acb6c82116d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.214601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.804084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.990365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.217251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.817875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c50a0fb-c6df-498d-a31e-5acb6c82116d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c50a0fb-c6df-498d-a31e-5acb6c82116d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c50a0fb-c6df-498d-a31e-5acb6c82116d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_wrong=val_df[val_df['target']!=val_df['pred']].sort_values('pred_probs',ascending=False)"
      ],
      "metadata": {
        "id": "GC_zqVUn4kv3"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_wrong"
      ],
      "metadata": {
        "id": "IPqFq8TW4948",
        "outputId": "7b064063-6e23-4f90-999f-78f10595a575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
              "..                                                 ...     ...   ...   \n",
              "408  @willienelson We need help! Horses will die!Pl...       1   0.0   \n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
              "\n",
              "     pred_probs  \n",
              "31     0.945002  \n",
              "759    0.911364  \n",
              "628    0.901439  \n",
              "49     0.898878  \n",
              "109    0.867195  \n",
              "..          ...  \n",
              "408    0.053469  \n",
              "244    0.045702  \n",
              "411    0.041197  \n",
              "38     0.038591  \n",
              "23     0.029069  \n",
              "\n",
              "[140 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cf48b3e-8714-47c0-89d6-3d73ce5a5c64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.945002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.911364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.901439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.898878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.867195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>@willienelson We need help! Horses will die!Pl...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cf48b3e-8714-47c0-89d6-3d73ce5a5c64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cf48b3e-8714-47c0-89d6-3d73ce5a5c64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cf48b3e-8714-47c0-89d6-3d73ce5a5c64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kqo-f9dy5NqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}