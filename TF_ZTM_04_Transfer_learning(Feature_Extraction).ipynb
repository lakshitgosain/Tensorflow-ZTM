{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPLnxqMXkRQojYLuCNYGD0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshitgosain/Tensorflow-ZTM/blob/main/TF_ZTM_04_Transfer_learning(Feature_Extraction).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can Leverage an existing Architecture proven to provide good results on different Datasets\n",
        "* We can leverage a working network architecture which has already learned patterns on similar data to our own"
      ],
      "metadata": {
        "id": "wwb2W7Vs6gif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJh6_yEX8BNi",
        "outputId": "a5fe63b6-9d45-4065-f97b-18295b67602a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-30 16:04:24--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.31.128, 142.251.111.128, 142.251.163.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.31.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   162MB/s    in 1.0s    \n",
            "\n",
            "2023-05-30 16:04:25 (162 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref=zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "x929vrECxf1J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How many images in each folder\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsmB7wtpxoPP",
        "outputId": "9d53835f-c40d-4044-904b-f4a6511f220f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in 10_food_classes_10_percent\n",
            "There are 10 directories and 0 images in 10_food_classes_10_percent/train\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/sushi\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/ice_cream\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/chicken_curry\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/fried_rice\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/hamburger\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/chicken_wings\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/ramen\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/pizza\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/grilled_salmon\n",
            "There are 0 directories and 75 images in 10_food_classes_10_percent/train/steak\n",
            "There are 10 directories and 0 images in 10_food_classes_10_percent/test\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/sushi\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/ice_cream\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/chicken_curry\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/fried_rice\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/hamburger\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/chicken_wings\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/ramen\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/pizza\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/grilled_salmon\n",
            "There are 0 directories and 250 images in 10_food_classes_10_percent/test/steak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating dataloaders (prepare the data)\n",
        "\n",
        "We'll use the ImageDataGenerator class to load in out images in batches"
      ],
      "metadata": {
        "id": "s0aFvw5rykMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "IMAGE_SHAPE= (224,224)\n",
        "BATCH_SIZE=32\n",
        "EPOCHS=5\n",
        "\n",
        "train_dir=\"10_food_classes_10_percent/train/\"\n",
        "test_dir=\"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen=ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen=ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training Images\")\n",
        "\n",
        "train_data_10_percent=train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMAGE_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode='categorical')\n",
        "\n",
        "print(\"Testing Images:\")\n",
        "test_data=test_datagen.flow_from_directory(test_dir,\n",
        "                                           target_size=IMAGE_SHAPE,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyXeLYHRy_iP",
        "outputId": "baad8edf-9a82-4524-841f-cd7bcf43f26b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Images\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing Images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup callbacks (things to run whilst our model trains)\n",
        "\n",
        "Callbacks are extra functionality that you can add to your models to be performed during or after training.\n",
        "Some of the mose populat callbacks\n",
        "\n",
        "* Tracking Experiments with the TensorBoard callback\n",
        "* Model Checkpointing with ModelCheckpoint Callback\n",
        "* Stopping the model from trainin(before it overfits) with the EarlyStopping Callback"
      ],
      "metadata": {
        "id": "xzSHyN0g0DYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Tensorboard Callback (Functionlized because we need to create a new one for each model)\n",
        " \n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name,experiment_name):\n",
        "  log_dir=dir_name + \"/\"+ experiment_name + \"/\"+ datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "  tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard Log files to {log_dir}\")\n",
        "\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "YCyBA9bw2MxW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using Tensorflow Hub\n",
        "\n",
        "https://paperswithcode.com/ to know which model performs how well on images , text etc\n",
        "\n",
        "We found the following feature vector model link:\n",
        "https://tfhub.dev/tensorflow.efficientnet/b0/feature-vector/1"
      ],
      "metadata": {
        "id": "KwsZH-Sa4B_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet 50 V2 feature vector\n",
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "# Original: EfficientNetB0 feature vector (version 1)\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n"
      ],
      "metadata": {
        "id": "W_LdHrjx_4xZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "KdK2OSZL7JsK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "  \n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in output layer,\n",
        "      should be equal to number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature\n",
        "    extractor layer and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False, # freeze the underlying patterns\n",
        "                                           name='feature_extraction_layer',\n",
        "                                           input_shape=IMAGE_SHAPE+(3,)) # define the input image shape\n",
        "  \n",
        "  # Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "    feature_extractor_layer, # use the feature extraction layer as the base\n",
        "    layers.Dense(num_classes, activation='softmax', name='output_layer') # create our own output layer      \n",
        "  ])\n",
        "\n",
        "  return model\n",
        "     "
      ],
      "metadata": {
        "id": "ZZjAYjw__FsF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model=create_model(resnet_url,\n",
        "                          num_classes=train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "id": "4dw7ShEQ_JDn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pevw0UDqAKa4",
        "outputId": "802957ad-f831-4b78-fd80-4c0de2b58fe0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (K  (None, 2048)             23564800  \n",
            " erasLayer)                                                      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile Model\n",
        "resnet_model.compile(loss='categorical_crossentropy',\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PMAL3FdLAYdL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_history=resnet_model.fit(train_data_10_percent,\n",
        "                    \n",
        "                                epochs=5,\n",
        "                                steps_per_epoch=len(train_data_10_percent),\n",
        "                                validation_data=test_data,\n",
        "                                validation_steps=len(test_data),\n",
        "                                callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub',\n",
        "                                                                       experiment_name='resnet50v2')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfvVcpM4AtdH",
        "outputId": "737bc615-34bb-41f7-845d-c3346308ef55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard Log files to tensorflow_hub/resnet50v2/20230530-161835\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4897 - accuracy: 0.8653"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create a function to plot loss curves\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  returns separate loss curves for training and validation metrics\n",
        "  \"\"\"\n",
        "  loss=history.history['loss']\n",
        "  val_loss=history.history['val_loss']\n",
        "\n",
        "  accuracy=history.history['accuracy']\n",
        "  val_accuracy=history.history['val_accuracy']\n",
        "\n",
        "  epochs=range(len(history.history['loss']))\n",
        "\n",
        "  plt.plot(epochs, loss, label='training loss')\n",
        "  plt.plot(epochs, val_loss, label='validation loss')\n",
        "  plt.title('loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  #Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='validation accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "daKDzXlWEScQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(resnet_history)"
      ],
      "metadata": {
        "id": "FAPqcH5EIegH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing efficientNet v0"
      ],
      "metadata": {
        "id": "FZ61kLmyIgZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model=create_model(model_url=efficientnet_url,\n",
        "                                num_classes=train_data_10_percent.num_classes)\n",
        "\n",
        "efficientnet_model.compile(loss='categorical_crossentropy',\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "#Fit EfficientNet Model to 10% of training Data\n",
        "efficientnet_history=efficientnet_model.fit(train_data_10_percent,\n",
        "                                            epochs=5,\n",
        "                                            steps_per_epoch=len(train_data_10_percent),\n",
        "                                            validation_data=test_data,\n",
        "                                            validation_steps=len(test_data),\n",
        "                                            callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub',\n",
        "                                                                                   experiment_name='efficientnet_model')])"
      ],
      "metadata": {
        "id": "58voU1eaJE-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model.summary()"
      ],
      "metadata": {
        "id": "2Bn5jLkIbtnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different types of transfer learning\n",
        "\n",
        "* \"As is\" transfer learning - using an existing model with no changes what so ever.\n",
        "* Feature Extraction Transfer learning- usr the patterns of an existing model ( E.g. EfficientNet v0 trained on ImageNet) and adjust the output layer for your problem\n",
        "* Fine Tuning Transfer learning - use the pre-learned models of an existing model and fine tune many or all of the underlying layers\n"
      ],
      "metadata": {
        "id": "vimbB28Tc5rC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HmMnHgNwd9XS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}